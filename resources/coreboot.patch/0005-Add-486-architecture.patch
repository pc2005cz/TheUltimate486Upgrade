From bbb6224b467cf13cf66ef4083dba08348b1757c2 Mon Sep 17 00:00:00 2001
From: Petr Cvek <petrcvekcz@gmail.com>
Date: Thu, 19 Sep 2024 04:52:40 +0200
Subject: [PATCH 05/26] Add 486 architecture

some files may be same as original x86, but many are modified to have disabled:

microcode updates
SMP
x86-64
TSC (you cannot do precise timing loops, PIT is unused)
SDRAM
MTRR
---
 src/arch/486/Kconfig                        |  306 ++++
 src/arch/486/Makefile.inc                   |  298 ++++
 src/arch/486/acpi.c                         |   20 +
 src/arch/486/acpi/debug.asl                 |  158 ++
 src/arch/486/acpi/globutil.asl              |  100 ++
 src/arch/486/acpi/post.asl                  |   17 +
 src/arch/486/acpi/statdef.asl               |   74 +
 src/arch/486/acpi_bert_storage.c            |  599 ++++++++
 src/arch/486/acpi_s3.c                      |   34 +
 src/arch/486/assembly_entry.S               |   70 +
 src/arch/486/boot.c                         |   78 +
 src/arch/486/bootblock.ld                   |  117 ++
 src/arch/486/bootblock_normal.c             |   33 +
 src/arch/486/breakpoint.c                   |  299 ++++
 src/arch/486/c_start.S                      |  246 +++
 src/arch/486/car.ld                         |  110 ++
 src/arch/486/cf9_reset.c                    |   51 +
 src/arch/486/cpu.c                          |  337 ++++
 src/arch/486/cpu_common.c                   |  205 +++
 src/arch/486/ebda.c                         |   64 +
 src/arch/486/exception.c                    |  660 ++++++++
 src/arch/486/exit_car.S                     |  437 ++++++
 src/arch/486/gdt_init.S                     |   72 +
 src/arch/486/id.S                           |   24 +
 src/arch/486/idt.S                          |  216 +++
 src/arch/486/include/arch/bert_storage.h    |  137 ++
 src/arch/486/include/arch/boot/boot.h       |   16 +
 src/arch/486/include/arch/bootblock.h       |   10 +
 src/arch/486/include/arch/breakpoint.h      |   58 +
 src/arch/486/include/arch/byteorder.h       |    8 +
 src/arch/486/include/arch/cache.h           |   25 +
 src/arch/486/include/arch/cbconfig.h        |   15 +
 src/arch/486/include/arch/cpu.h             |  316 ++++
 src/arch/486/include/arch/cpuid.h           |   95 ++
 src/arch/486/include/arch/exception.h       |   14 +
 src/arch/486/include/arch/header.ld         |    8 +
 src/arch/486/include/arch/hlt.h             |   12 +
 src/arch/486/include/arch/interrupt.h       |   18 +
 src/arch/486/include/arch/io.h              |  106 ++
 src/arch/486/include/arch/memlayout.h       |   12 +
 src/arch/486/include/arch/memory_clear.h    |   10 +
 src/arch/486/include/arch/mmio.h            |   48 +
 src/arch/486/include/arch/null_breakpoint.h |   21 +
 src/arch/486/include/arch/pci_io_cfg.h      |  117 ++
 src/arch/486/include/arch/pci_ops.h         |    8 +
 src/arch/486/include/arch/pirq_routing.h    |   49 +
 src/arch/486/include/arch/ram_segs.h        |   14 +
 src/arch/486/include/arch/registers.h       |   95 ++
 src/arch/486/include/arch/rom_segs.h        |   17 +
 src/arch/486/include/arch/romstage.h        |   32 +
 src/arch/486/include/arch/smp/atomic.h      |   70 +
 src/arch/486/include/arch/smp/mpspec.h      |  267 ++++
 src/arch/486/include/arch/smp/spinlock.h    |   70 +
 src/arch/486/include/arch/stages.h          |    6 +
 src/arch/486/include/arch/symbols.h         |   30 +
 src/arch/486/include/cf9_reset.h            |   27 +
 src/arch/486/include/mode_switch.h          |   69 +
 src/arch/486/include/smm.h                  |   20 +
 src/arch/486/memcpy.c                       |  117 ++
 src/arch/486/memlayout.ld                   |   42 +
 src/arch/486/memmove_32.c                   |  202 +++
 src/arch/486/memset.c                       |   74 +
 src/arch/486/mmap_boot.c                    |   34 +
 src/arch/486/mpspec.c                       |  506 ++++++
 src/arch/486/null_breakpoint.c              |   73 +
 src/arch/486/pirq_routing.c                 |  208 +++
 src/arch/486/post.c                         |   15 +
 src/arch/486/postcar.c                      |   53 +
 src/arch/486/postcar_loader.c               |  153 ++
 src/arch/486/romstage.c                     |   16 +
 src/arch/486/smbios.c                       | 1528 +++++++++++++++++++
 src/arch/486/smbios_defaults.c              |  164 ++
 src/arch/486/tables.c                       |  226 +++
 src/arch/486/thread.c                       |   45 +
 src/arch/486/thread_switch.S                |   46 +
 src/arch/486/timestamp.c                    |   21 +
 src/arch/486/verstage.c                     |   10 +
 src/arch/486/wakeup.S                       |  106 ++
 src/arch/486/walkcbfs.S                     |  121 ++
 src/cpu/486/486.c                           |   59 +
 src/cpu/486/Kconfig                         |   53 +
 src/cpu/486/Makefile.inc                    |   32 +
 src/cpu/486/bootblock.c                     |   69 +
 src/cpu/486/cache_as_ram.S                  |  684 +++++++++
 src/cpu/486/delay_pit.c                     |   85 ++
 src/cpu/486/entry16.S                       |  267 ++++
 src/cpu/486/entry32.S                       |   75 +
 src/cpu/486/exit_car.S                      |  105 ++
 src/cpu/486/name.c                          |   33 +
 src/cpu/486/reset16.S                       |   14 +
 src/cpu/486/romstage.c                      |   69 +
 src/cpu/486/sp_init.c                       | 1040 +++++++++++++
 src/include/cpu/486/bist.h                  |   17 +
 src/include/cpu/486/cache.h                 |   60 +
 src/include/cpu/486/cr.h                    |  132 ++
 src/include/cpu/486/gdt.h                   |   18 +
 src/include/cpu/486/legacy_save_state.h     |   48 +
 src/include/cpu/486/name.h                  |    8 +
 src/include/cpu/486/post_code.h             |   60 +
 src/include/cpu/486/save_state.h            |   34 +
 src/include/cpu/486/smi_deprecated.h        |   12 +
 src/include/cpu/486/smm.h                   |  201 +++
 src/include/cpu/486/sp_init.h               |   94 ++
 103 files changed, 13474 insertions(+)
 create mode 100644 src/arch/486/Kconfig
 create mode 100644 src/arch/486/Makefile.inc
 create mode 100644 src/arch/486/acpi.c
 create mode 100644 src/arch/486/acpi/debug.asl
 create mode 100644 src/arch/486/acpi/globutil.asl
 create mode 100644 src/arch/486/acpi/post.asl
 create mode 100644 src/arch/486/acpi/statdef.asl
 create mode 100644 src/arch/486/acpi_bert_storage.c
 create mode 100644 src/arch/486/acpi_s3.c
 create mode 100644 src/arch/486/assembly_entry.S
 create mode 100644 src/arch/486/boot.c
 create mode 100644 src/arch/486/bootblock.ld
 create mode 100644 src/arch/486/bootblock_normal.c
 create mode 100644 src/arch/486/breakpoint.c
 create mode 100644 src/arch/486/c_start.S
 create mode 100644 src/arch/486/car.ld
 create mode 100644 src/arch/486/cf9_reset.c
 create mode 100644 src/arch/486/cpu.c
 create mode 100644 src/arch/486/cpu_common.c
 create mode 100644 src/arch/486/ebda.c
 create mode 100644 src/arch/486/exception.c
 create mode 100644 src/arch/486/exit_car.S
 create mode 100644 src/arch/486/gdt_init.S
 create mode 100644 src/arch/486/id.S
 create mode 100644 src/arch/486/idt.S
 create mode 100644 src/arch/486/include/arch/bert_storage.h
 create mode 100644 src/arch/486/include/arch/boot/boot.h
 create mode 100644 src/arch/486/include/arch/bootblock.h
 create mode 100644 src/arch/486/include/arch/breakpoint.h
 create mode 100644 src/arch/486/include/arch/byteorder.h
 create mode 100644 src/arch/486/include/arch/cache.h
 create mode 100644 src/arch/486/include/arch/cbconfig.h
 create mode 100644 src/arch/486/include/arch/cpu.h
 create mode 100644 src/arch/486/include/arch/cpuid.h
 create mode 100644 src/arch/486/include/arch/exception.h
 create mode 100644 src/arch/486/include/arch/header.ld
 create mode 100644 src/arch/486/include/arch/hlt.h
 create mode 100644 src/arch/486/include/arch/interrupt.h
 create mode 100644 src/arch/486/include/arch/io.h
 create mode 100644 src/arch/486/include/arch/memlayout.h
 create mode 100644 src/arch/486/include/arch/memory_clear.h
 create mode 100644 src/arch/486/include/arch/mmio.h
 create mode 100644 src/arch/486/include/arch/null_breakpoint.h
 create mode 100644 src/arch/486/include/arch/pci_io_cfg.h
 create mode 100644 src/arch/486/include/arch/pci_ops.h
 create mode 100644 src/arch/486/include/arch/pirq_routing.h
 create mode 100644 src/arch/486/include/arch/ram_segs.h
 create mode 100644 src/arch/486/include/arch/registers.h
 create mode 100644 src/arch/486/include/arch/rom_segs.h
 create mode 100644 src/arch/486/include/arch/romstage.h
 create mode 100644 src/arch/486/include/arch/smp/atomic.h
 create mode 100644 src/arch/486/include/arch/smp/mpspec.h
 create mode 100644 src/arch/486/include/arch/smp/spinlock.h
 create mode 100644 src/arch/486/include/arch/stages.h
 create mode 100644 src/arch/486/include/arch/symbols.h
 create mode 100644 src/arch/486/include/cf9_reset.h
 create mode 100644 src/arch/486/include/mode_switch.h
 create mode 100644 src/arch/486/include/smm.h
 create mode 100644 src/arch/486/memcpy.c
 create mode 100644 src/arch/486/memlayout.ld
 create mode 100644 src/arch/486/memmove_32.c
 create mode 100644 src/arch/486/memset.c
 create mode 100644 src/arch/486/mmap_boot.c
 create mode 100644 src/arch/486/mpspec.c
 create mode 100644 src/arch/486/null_breakpoint.c
 create mode 100644 src/arch/486/pirq_routing.c
 create mode 100644 src/arch/486/post.c
 create mode 100644 src/arch/486/postcar.c
 create mode 100644 src/arch/486/postcar_loader.c
 create mode 100644 src/arch/486/romstage.c
 create mode 100644 src/arch/486/smbios.c
 create mode 100644 src/arch/486/smbios_defaults.c
 create mode 100644 src/arch/486/tables.c
 create mode 100644 src/arch/486/thread.c
 create mode 100644 src/arch/486/thread_switch.S
 create mode 100644 src/arch/486/timestamp.c
 create mode 100644 src/arch/486/verstage.c
 create mode 100644 src/arch/486/wakeup.S
 create mode 100644 src/arch/486/walkcbfs.S
 create mode 100644 src/cpu/486/486.c
 create mode 100644 src/cpu/486/Kconfig
 create mode 100644 src/cpu/486/Makefile.inc
 create mode 100644 src/cpu/486/bootblock.c
 create mode 100644 src/cpu/486/cache_as_ram.S
 create mode 100644 src/cpu/486/delay_pit.c
 create mode 100644 src/cpu/486/entry16.S
 create mode 100644 src/cpu/486/entry32.S
 create mode 100644 src/cpu/486/exit_car.S
 create mode 100644 src/cpu/486/name.c
 create mode 100644 src/cpu/486/reset16.S
 create mode 100644 src/cpu/486/romstage.c
 create mode 100644 src/cpu/486/sp_init.c
 create mode 100644 src/include/cpu/486/bist.h
 create mode 100644 src/include/cpu/486/cache.h
 create mode 100644 src/include/cpu/486/cr.h
 create mode 100644 src/include/cpu/486/gdt.h
 create mode 100644 src/include/cpu/486/legacy_save_state.h
 create mode 100644 src/include/cpu/486/name.h
 create mode 100644 src/include/cpu/486/post_code.h
 create mode 100644 src/include/cpu/486/save_state.h
 create mode 100644 src/include/cpu/486/smi_deprecated.h
 create mode 100644 src/include/cpu/486/smm.h
 create mode 100644 src/include/cpu/486/sp_init.h

diff --git a/src/arch/486/Kconfig b/src/arch/486/Kconfig
new file mode 100644
index 0000000000..e81043a4b9
--- /dev/null
+++ b/src/arch/486/Kconfig
@@ -0,0 +1,306 @@
+## SPDX-License-Identifier: GPL-2.0-only
+
+config ARCH_486
+	bool
+	select PCI
+	select RELOCATABLE_MODULES
+	select HAVE_ASAN_IN_RAMSTAGE
+
+if ARCH_486
+
+# stage selectors for x86
+
+config ARCH_BOOTBLOCK_X86_32
+	bool
+
+config ARCH_VERSTAGE_X86_32
+	bool
+
+config ARCH_ROMSTAGE_X86_32
+	bool
+
+config ARCH_POSTCAR_X86_32
+	bool
+	default ARCH_ROMSTAGE_X86_32 && POSTCAR_STAGE
+
+config ARCH_RAMSTAGE_X86_32
+	bool
+
+config ARCH_ALL_STAGES_X86_32
+	bool
+	default !ARCH_ALL_STAGES_X86_64
+	select ARCH_BOOTBLOCK_X86_32
+	select ARCH_VERSTAGE_X86_32 if !VBOOT_STARTS_BEFORE_BOOTBLOCK
+	select ARCH_ROMSTAGE_X86_32
+	select ARCH_RAMSTAGE_X86_32
+	select ARCH_SUPPORTS_CLANG
+
+# stage selectors for x64
+
+config USE_MARCH_486
+	def_bool n
+	help
+	  Allow a platform or processor to select to be compiled using
+	  the '-march=i486' option instead of the typical '-march=i686'
+
+
+config RESET_VECTOR_IN_RAM
+	bool
+	depends on ARCH_486
+	select NO_XIP_EARLY_STAGES
+	help
+	  Select this option if the x86 processor's reset vector is in
+	  preinitialized DRAM instead of the traditional 0xfffffff0 location.
+
+# Aligns 16bit entry code in bootblock so that hyper-threading CPUs
+# can boot AP CPUs to enable their shared caches.
+config SIPI_VECTOR_IN_ROM
+	bool
+	default n
+	depends on ARCH_486
+
+# Traditionally BIOS region on SPI flash boot media was memory mapped right below
+# 4G and it was the last region in the IFD. This way translation between CPU
+# address space to flash address was trivial. However some IFDs on newer SoCs
+# have BIOS region sandwiched between descriptor and other regions. Turning on
+# X86_CUSTOM_BOOTMEDIA disables X86_TOP4G_BOOTMEDIA_MAP which allows the
+# soc code to provide custom mmap_boot.c.
+config X86_CUSTOM_BOOTMEDIA
+	bool
+
+config X86_TOP4G_BOOTMEDIA_MAP
+	bool
+	depends on !X86_CUSTOM_BOOTMEDIA
+	default y
+
+config PRERAM_CBMEM_CONSOLE_SIZE
+	hex
+	default 0xc00
+	help
+	  Increase this value if preram cbmem console is getting truncated
+
+config CBFS_MCACHE_SIZE
+	hex
+	depends on !NO_CBFS_MCACHE
+	default 0x4000
+	help
+	  Increase this value if you see CBFS mcache overflow warnings. Do NOT
+	  change this value for vboot RW updates!
+
+config PC80_SYSTEM
+	bool
+	default y if ARCH_486
+
+config BOOTBLOCK_DEBUG_SPINLOOP
+	bool
+	default n
+	help
+	  Add a spin (JMP .) in bootblock_crt0.S during early bootblock to wait
+	  for a JTAG debugger to break into the execution sequence.
+
+config HAVE_CMOS_DEFAULT
+	def_bool n
+	depends on HAVE_OPTION_TABLE
+
+config CMOS_DEFAULT_FILE
+	string
+	default "src/mainboard/\$(MAINBOARDDIR)/cmos.default"
+	depends on HAVE_CMOS_DEFAULT
+
+config HPET_MIN_TICKS
+	hex
+
+config C_ENV_BOOTBLOCK_SIZE
+	hex
+	default 0x40000 if !FIXED_BOOTBLOCK_SIZE
+	help
+	   This is only the default maximum of bootblock size for linking
+	   purposes. Platforms may provide different limit and need to
+	   specify this when FIXED_BOOTBLOCK_SIZE is selected.
+
+config FIXED_BOOTBLOCK_SIZE
+	bool
+
+# Default address romstage is to be linked at
+config ROMSTAGE_ADDR
+	hex
+	default 0x2000000
+
+# Default address verstage is to be linked at
+config VERSTAGE_ADDR
+	hex
+	default 0x2000000
+
+# Use the post CAR infrastructure for tearing down cache-as-ram
+# from a program loaded in RAM and subsequently loading ramstage.
+config POSTCAR_STAGE
+	def_bool y
+	depends on ARCH_486
+	depends on !RESET_VECTOR_IN_RAM
+
+config VERSTAGE_DEBUG_SPINLOOP
+	bool
+	default n
+	help
+	  Add a spin (JMP .) in assembly_entry.S during early verstage to wait
+	  for a JTAG debugger to break into the execution sequence.
+
+config ROMSTAGE_DEBUG_SPINLOOP
+	bool
+	default n
+	help
+	  Add a spin (JMP .) in assembly_entry.S during early romstage to wait
+	  for a JTAG debugger to break into the execution sequence.
+
+choice
+	prompt "Bootblock behaviour"
+	default BOOTBLOCK_SIMPLE
+	depends on !VBOOT
+
+config BOOTBLOCK_SIMPLE
+	bool "Always load fallback"
+
+config BOOTBLOCK_NORMAL
+	select CONFIGURABLE_CBFS_PREFIX
+	bool "Switch to normal if CMOS says so"
+
+endchoice
+
+config SKIP_MAX_REBOOT_CNT_CLEAR
+	bool "Do not clear reboot count after successful boot"
+	depends on BOOTBLOCK_NORMAL
+	help
+	  Do not clear the reboot count immediately after successful boot.
+	  Set to allow the payload to control normal/fallback image recovery.
+	  Note that it is the responsibility of the payload to reset the
+	  normal boot bit to 1 after each successful boot.
+
+config ACPI_BERT
+	bool
+	depends on HAVE_ACPI_TABLES
+	help
+	  Build an ACPI Boot Error Record Table.
+
+config COLLECT_TIMESTAMPS_NO_TSC
+	bool
+	default n
+	depends on COLLECT_TIMESTAMPS
+	help
+	  Use a non-TSC platform-dependent source for timestamps.
+
+config COLLECT_TIMESTAMPS_TSC
+	bool
+	default y if !COLLECT_TIMESTAMPS_NO_TSC
+	default n
+	depends on COLLECT_TIMESTAMPS
+	help
+	  Use the TSC as the timestamp source.
+
+config PAGING_IN_CACHE_AS_RAM
+	bool
+	default n
+	depends on ARCH_486
+	help
+	  Chipsets scan select this option to preallocate area in cache-as-ram
+	  for storing paging data structures. PAE paging is currently the
+	  only thing being supported.
+
+config NUM_CAR_PAGE_TABLE_PAGES
+	int
+	default 5
+	depends on PAGING_IN_CACHE_AS_RAM
+	help
+	  The number of 4KiB pages that should be pre-allocated for page tables.
+
+# Provide the interrupt handlers to every stage. Not all
+# stages may take advantage.
+config IDT_IN_EVERY_STAGE
+	bool
+	default n
+	depends on ARCH_486
+
+config HAVE_CF9_RESET
+	bool
+
+config HAVE_CF9_RESET_PREPARE
+	bool
+	depends on HAVE_CF9_RESET
+
+config PIRQ_ROUTE
+	bool
+	default n
+
+config MAX_PIRQ_LINKS
+	int
+	default 4
+	depends on PIRQ_ROUTE
+	help
+	  This variable specifies the number of PIRQ interrupt links which are
+	  routable. On most chipsets, this is 4, INTA through INTD. Some
+	  chipsets offer more than four links, commonly up to INTH. They may
+	  also have a separate link for ATA or IOAPIC interrupts. When the PIRQ
+	  table specifies links greater than 4, pirq_route_irqs will not
+	  function properly, unless this variable is correctly set.
+
+config MAX_ACPI_TABLE_SIZE_KB
+	int
+	default 144
+	help
+	  Set the maximum size of all ACPI tables in KiB.
+
+config MEMLAYOUT_LD_FILE
+	string
+	default "src/arch/486/memlayout.ld"
+
+config DEBUG_HW_BREAKPOINTS
+	bool
+	default y
+	help
+	  Enable support for hardware data and instruction breakpoints through
+	  the x86 debug registers
+
+config DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES
+	bool
+	default y
+	depends on DEBUG_HW_BREAKPOINTS && IDT_IN_EVERY_STAGE
+
+config DEBUG_NULL_DEREF_BREAKPOINTS
+	bool
+	default y
+	depends on DEBUG_HW_BREAKPOINTS
+	help
+	  Enable support for catching null dereferences and instruction execution
+
+config DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES
+	bool
+	default y
+	depends on DEBUG_NULL_DEREF_BREAKPOINTS && DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES
+
+config DEBUG_NULL_DEREF_HALT
+	bool
+	default n
+	depends on DEBUG_NULL_DEREF_BREAKPOINTS
+	help
+	  When enabled null dereferences and instruction fetches will halt execution.
+	  Otherwise an error will be printed.
+
+# Some EC need an "EC firmware pointer" (a data structure hinting the address
+# of its firmware blobs) being put at a fixed position. Its space
+# (__section__(".ecfw_ptr")) should be reserved if it lies in the range of a
+# stage. Different EC may have different format and/or value for it. The actual
+# address of EC firmware pointer should be provided in the Kconfig of the EC
+# requiring it, and its value could be filled by linking a read-only global
+# data object to the section above.
+
+config ECFW_PTR_ADDR
+	hex
+	help
+	   Address of reserved space for EC firmware pointer, which should not
+	   overlap other data such as reset vector or FIT pointer if present.
+
+config ECFW_PTR_SIZE
+	int
+	help
+	   Size of reserved space for EC firmware pointer
+
+endif
diff --git a/src/arch/486/Makefile.inc b/src/arch/486/Makefile.inc
new file mode 100644
index 0000000000..cc108d5ad7
--- /dev/null
+++ b/src/arch/486/Makefile.inc
@@ -0,0 +1,298 @@
+## SPDX-License-Identifier: GPL-2.0-only
+
+ifeq ($(CONFIG_POSTCAR_STAGE),y)
+$(eval $(call init_standard_toolchain,postcar))
+endif
+
+################################################################################
+# i386 specific tools
+NVRAMTOOL:=$(objutil)/nvramtool/nvramtool
+
+OPTION_TABLE_H:=
+ifeq ($(CONFIG_HAVE_OPTION_TABLE),y)
+
+CMOS_LAYOUT_FILE := $(top)/$(call strip_quotes,$(CONFIG_CMOS_LAYOUT_FILE))
+
+cbfs-files-y += cmos_layout.bin
+cmos_layout.bin-file = $(obj)/cmos_layout.bin
+cmos_layout.bin-type = cmos_layout
+
+$(obj)/cmos_layout.bin: $(NVRAMTOOL) $(CMOS_LAYOUT_FILE)
+	@printf "    OPTION     $(subst $(obj)/,,$(@))\n"
+	$(NVRAMTOOL) -y $(CMOS_LAYOUT_FILE) -L $@
+
+OPTION_TABLE_H:=$(obj)/option_table.h
+
+$(OPTION_TABLE_H): $(NVRAMTOOL) $(CMOS_LAYOUT_FILE)
+	@printf "    OPTION     $(subst $(obj)/,,$(@))\n"
+	$(NVRAMTOOL) -y $(CMOS_LAYOUT_FILE) -H $@
+endif # CONFIG_HAVE_OPTION_TABLE
+
+stripped_vgabios_id = $(call strip_quotes,$(CONFIG_VGA_BIOS_ID))
+cbfs-files-$(CONFIG_VGA_BIOS) += pci$(stripped_vgabios_id).rom
+pci$(stripped_vgabios_id).rom-file := $(call strip_quotes,$(CONFIG_VGA_BIOS_FILE))
+pci$(stripped_vgabios_id).rom-type := optionrom
+
+stripped_second_vbios_id = $(call strip_quotes,$(CONFIG_VGA_BIOS_SECOND_ID))
+cbfs-files-$(CONFIG_VGA_BIOS_SECOND) += pci$(stripped_second_vbios_id).rom
+pci$(stripped_second_vbios_id).rom-file := $(call strip_quotes,$(CONFIG_VGA_BIOS_SECOND_FILE))
+pci$(stripped_second_vbios_id).rom-type := optionrom
+
+stripped_vgabios_dgpu_id = $(call strip_quotes,$(CONFIG_VGA_BIOS_DGPU_ID))
+cbfs-files-$(CONFIG_VGA_BIOS_DGPU) += pci$(stripped_vgabios_dgpu_id).rom
+pci$(stripped_vgabios_dgpu_id).rom-file := $(call strip_quotes,$(CONFIG_VGA_BIOS_DGPU_FILE))
+pci$(stripped_vgabios_dgpu_id).rom-type := optionrom
+
+###############################################################################
+# common support for early assembly includes
+###############################################################################
+
+define early_x86_stage
+# $1 stage name
+# $2 oformat
+
+# The '.' include path is needed for the generated assembly.inc file.
+$(1)-S-ccopts += -I.
+
+$$(objcbfs)/$(1).debug: $$$$($(1)-libs) $$$$($(1)-objs)
+	@printf "    LINK       $$(subst $$(obj)/,,$$(@))\n"
+	$$(LD_$(1)) $$(LDFLAGS_$(1)) -o $$@ -L$$(obj) $$(COMPILER_RT_FLAGS_$(1)) --whole-archive --start-group $$(filter-out %.ld,$$($(1)-objs)) $$($(1)-libs) --no-whole-archive $$(COMPILER_RT_$(1)) --end-group -T $(call src-to-obj,$(1),$(CONFIG_MEMLAYOUT_LD_FILE)) --oformat $(2)
+	-LANG=C LC_ALL= $$(OBJCOPY_$(1)) --only-section .illegal_globals $$(@) $$(objcbfs)/$(1)_null.offenders >/dev/null 2>&1
+	if [ -z "$$$$($$(NM_$(1)) $$(objcbfs)/$(1)_null.offenders 2>&1 | grep 'no symbols')" ];then \
+		echo "Forbidden global variables in $(1):"; \
+		$$(NM_$(1)) $$(objcbfs)/$(1)_null.offenders; false; \
+	fi
+endef
+
+###############################################################################
+# bootblock
+###############################################################################
+
+ifeq ($(CONFIG_ARCH_BOOTBLOCK_X86_32)$(CONFIG_ARCH_BOOTBLOCK_X86_64),y)
+
+bootblock-y += boot.c
+bootblock-$(CONFIG_DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) += breakpoint.c
+bootblock-y += post.c
+bootblock-y += cpu_common.c
+bootblock-$(CONFIG_IDT_IN_EVERY_STAGE) += exception.c
+bootblock-$(CONFIG_IDT_IN_EVERY_STAGE) += idt.S
+bootblock-y += memcpy.c
+bootblock-y += memset.c
+bootblock-$(CONFIG_ARCH_BOOTBLOCK_X86_32) += memmove_32.c
+bootblock-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+bootblock-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) += null_breakpoint.c
+bootblock-$(CONFIG_BOOTBLOCK_NORMAL) += bootblock_normal.c
+bootblock-y += gdt_init.S
+bootblock-y += id.S
+bootblock-$(CONFIG_HAVE_CF9_RESET) += cf9_reset.c
+bootblock-y += bootblock.ld
+bootblock-y += car.ld
+
+$(call src-to-obj,bootblock,$(dir)/id.S): $(obj)/build.h
+
+$(eval $(call early_x86_stage,bootblock,elf32-i386))
+
+ifeq ($(CONFIG_BOOTBLOCK_IN_CBFS),y)
+add_bootblock = \
+	$(CBFSTOOL) $(1) add -f $(2) -n bootblock -t bootblock $(TXTIBB) \
+	-b -$(call file-size,$(2)) \
+	$(cbfs-autogen-attributes) $(TS_OPTIONS) $(CBFSTOOL_ADD_CMD_OPTIONS)
+endif
+
+# $(call src-to-obj,bootblock,$(dir)/walkcbfs.S): $(obj)/fmap_config.h
+# bootblock-y += walkcbfs.S
+
+endif # CONFIG_ARCH_BOOTBLOCK_X86_32 / CONFIG_ARCH_BOOTBLOCK_X86_64
+
+###############################################################################
+# verstage
+###############################################################################
+
+ifeq ($(CONFIG_ARCH_VERSTAGE_X86_32)$(CONFIG_ARCH_VERSTAGE_X86_64),y)
+
+verstage-$(CONFIG_VBOOT_SEPARATE_VERSTAGE) += assembly_entry.S
+verstage-y += boot.c
+verstage-$(CONFIG_DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) += breakpoint.c
+verstage-y += post.c
+verstage-$(CONFIG_VBOOT_SEPARATE_VERSTAGE) += gdt_init.S
+verstage-$(CONFIG_IDT_IN_EVERY_STAGE) += exception.c
+verstage-$(CONFIG_IDT_IN_EVERY_STAGE) += idt.S
+verstage-$(CONFIG_HAVE_CF9_RESET) += cf9_reset.c
+
+verstage-y += cpu_common.c
+verstage-y += memset.c
+verstage-y += memcpy.c
+verstage-$(CONFIG_ARCH_VERSTAGE_X86_32) += memmove_32.c
+verstage-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+verstage-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) += null_breakpoint.c
+# If verstage is a separate stage it means there's no need
+# for a chipset-specific car_stage_entry() so use the generic one
+# which just calls verstage().
+verstage-$(CONFIG_VBOOT_SEPARATE_VERSTAGE) += verstage.c
+
+verstage-$(CONFIG_COLLECT_TIMESTAMPS_TSC) += timestamp.c
+
+verstage-y += car.ld
+
+verstage-libs ?=
+
+$(eval $(call early_x86_stage,verstage,elf32-i386))
+
+endif # CONFIG_ARCH_VERSTAGE_X86_32 / CONFIG_ARCH_VERSTAGE_X86_64
+
+###############################################################################
+# romstage
+###############################################################################
+
+ifeq ($(CONFIG_ARCH_ROMSTAGE_X86_32)$(CONFIG_ARCH_ROMSTAGE_X86_64),y)
+
+romstage-y += assembly_entry.S
+romstage-y += romstage.c
+romstage-y += boot.c
+romstage-$(CONFIG_DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) += breakpoint.c
+romstage-y += post.c
+romstage-y += gdt_init.S
+romstage-y += cpu_common.c
+romstage-$(CONFIG_IDT_IN_EVERY_STAGE) += exception.c
+romstage-$(CONFIG_IDT_IN_EVERY_STAGE) += idt.S
+romstage-y += memcpy.c
+romstage-$(CONFIG_ARCH_ROMSTAGE_X86_32) += memmove_32.c
+romstage-y += memset.c
+romstage-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+romstage-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) += null_breakpoint.c
+romstage-y += postcar_loader.c
+romstage-$(CONFIG_COLLECT_TIMESTAMPS_TSC) += timestamp.c
+romstage-$(CONFIG_HAVE_CF9_RESET) += cf9_reset.c
+romstage-$(CONFIG_COOP_MULTITASKING) += thread.c
+romstage-$(CONFIG_COOP_MULTITASKING) += thread_switch.S
+romstage-y += car.ld
+
+romstage-srcs += $(wildcard $(src)/mainboard/$(MAINBOARDDIR)/romstage.c)
+romstage-libs ?=
+
+$(eval $(call early_x86_stage,romstage,elf32-i386))
+
+# Compiling crt0 with -g seems to trigger https://sourceware.org/bugzilla/show_bug.cgi?id=6428
+romstage-S-ccopts += -g0
+
+endif # CONFIG_ARCH_ROMSTAGE_X86_32 / CONFIG_ARCH_ROMSTAGE_X86_64
+
+###############################################################################
+# postcar
+###############################################################################
+
+$(eval $(call create_class_compiler,postcar,x86_32))
+postcar-generic-ccopts += -D__POSTCAR__
+
+postcar-y += boot.c
+postcar-$(CONFIG_DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) += breakpoint.c
+postcar-y += post.c
+postcar-y += gdt_init.S
+postcar-y += cpu_common.c
+postcar-$(CONFIG_IDT_IN_EVERY_STAGE) += exception.c
+postcar-$(CONFIG_IDT_IN_EVERY_STAGE) += idt.S
+postcar-y += exit_car.S
+postcar-y += memcpy.c
+postcar-$(CONFIG_ARCH_POSTCAR_X86_32) += memmove_32.c
+postcar-y += memset.c
+postcar-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+postcar-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) += null_breakpoint.c
+postcar-y += postcar.c
+postcar-$(CONFIG_COLLECT_TIMESTAMPS_TSC) += timestamp.c
+postcar-$(CONFIG_HAVE_CF9_RESET) += cf9_reset.c
+
+LDFLAGS_postcar += -Map $(objcbfs)/postcar.map
+
+$(objcbfs)/postcar.debug: $$(postcar-objs)
+	@printf "    LINK       $(subst $(obj)/,,$(@))\n"
+	$(LD_postcar) $(LDFLAGS_postcar) -o $@ -L$(obj) $(COMPILER_RT_FLAGS_postcar) --whole-archive --start-group $(filter-out %.ld,$^) --no-whole-archive $(COMPILER_RT_postcar) --end-group -T $(call src-to-obj,postcar,$(CONFIG_MEMLAYOUT_LD_FILE))
+
+$(objcbfs)/postcar.elf: $(objcbfs)/postcar.debug.rmod
+	cp $< $@
+
+# Add postcar to CBFS
+cbfs-files-$(CONFIG_POSTCAR_STAGE)  += $(CONFIG_CBFS_PREFIX)/postcar
+$(CONFIG_CBFS_PREFIX)/postcar-file := $(objcbfs)/postcar.elf
+$(CONFIG_CBFS_PREFIX)/postcar-type := stage
+$(CONFIG_CBFS_PREFIX)/postcar-compression := none
+
+###############################################################################
+# ramstage
+###############################################################################
+
+ifeq ($(CONFIG_ARCH_RAMSTAGE_X86_32)$(CONFIG_ARCH_RAMSTAGE_X86_64),y)
+
+ramstage-y += acpi.c
+ramstage-$(CONFIG_HAVE_ACPI_RESUME) += acpi_s3.c
+ramstage-$(CONFIG_ACPI_BERT) += acpi_bert_storage.c
+ramstage-y += boot.c
+ramstage-y += post.c
+ramstage-y += c_start.S
+# ramstage-y += c_exit.S
+ramstage-y += cpu.c
+ramstage-y += cpu_common.c
+ramstage-$(CONFIG_DEBUG_HW_BREAKPOINTS) += breakpoint.c
+ramstage-y += ebda.c
+ramstage-y += exception.c
+ramstage-y += idt.S
+ramstage-$(CONFIG_IOAPIC) += ioapic.c
+ramstage-y += memcpy.c
+ramstage-$(CONFIG_ARCH_RAMSTAGE_X86_32) += memmove_32.c
+ramstage-$(CONFIG_ARCH_RAMSTAGE_X86_64) += memmove_64.S
+ramstage-y += memset.c
+ramstage-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+ramstage-$(CONFIG_GENERATE_MP_TABLE) += mpspec.c
+ramstage-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS) += null_breakpoint.c
+ramstage-$(CONFIG_GENERATE_PIRQ_TABLE) += pirq_routing.c
+ramstage-$(CONFIG_GENERATE_SMBIOS_TABLES) += smbios.c
+ramstage-$(CONFIG_GENERATE_SMBIOS_TABLES) += smbios_defaults.c
+ramstage-y += tables.c
+ramstage-$(CONFIG_COOP_MULTITASKING) += thread.c
+ramstage-$(CONFIG_COOP_MULTITASKING) += thread_switch.S
+ramstage-$(CONFIG_COLLECT_TIMESTAMPS_TSC) += timestamp.c
+ramstage-$(CONFIG_HAVE_ACPI_RESUME) += wakeup.S
+ramstage-$(CONFIG_HAVE_CF9_RESET) += cf9_reset.c
+
+rmodules_x86_32-y += memcpy.c
+rmodules_x86_32-y += memmove_32.c
+rmodules_x86_32-y += memset.c
+
+target-objcopy=-O elf32-i386 -B i386
+LD_MACHINE =-m elf_i386
+
+ramstage-srcs += $(wildcard src/mainboard/$(MAINBOARDDIR)/mainboard.c)
+ifeq ($(CONFIG_GENERATE_MP_TABLE),y)
+ifneq ($(wildcard src/mainboard/$(MAINBOARDDIR)/mptable.c),)
+ramstage-srcs += src/mainboard/$(MAINBOARDDIR)/mptable.c
+endif
+endif
+ifeq ($(CONFIG_GENERATE_PIRQ_TABLE),y)
+ramstage-srcs += src/mainboard/$(MAINBOARDDIR)/irq_tables.c
+endif
+
+ramstage-libs ?=
+
+# The rmodule_link definition creates an elf file with .rmod extension.
+$(objcbfs)/ramstage.elf: $(objcbfs)/ramstage.debug.rmod
+	cp $< $@
+
+$(objcbfs)/ramstage.debug: $(objgenerated)/ramstage.o $(call src-to-obj,ramstage,$(CONFIG_MEMLAYOUT_LD_FILE))
+	@printf "    CC	 $(subst $(obj)/,,$(@))\n"
+	$(LD_ramstage) $(CPPFLAGS) $(LDFLAGS_ramstage) -o $@ -L$(obj) $< -T $(call src-to-obj,ramstage,$(CONFIG_MEMLAYOUT_LD_FILE))
+
+$(objgenerated)/ramstage.o: $$(ramstage-objs) $(COMPILER_RT_ramstage) $$(ramstage-libs)
+	@printf "    CC	 $(subst $(obj)/,,$(@))\n"
+	$(LD_ramstage) $(LD_MACHINE) -r -o $@ $(COMPILER_RT_FLAGS_ramstage) --whole-archive --start-group $(filter-out %.ld,$(ramstage-objs)) $(ramstage-libs) --no-whole-archive $(COMPILER_RT_ramstage) --end-group
+
+endif # CONFIG_ARCH_RAMSTAGE_X86_32 / CONFIG_ARCH_RAMSTAGE_X86_64
+
+smm-$(CONFIG_DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) += breakpoint.c
+smm-$(CONFIG_IDT_IN_EVERY_STAGE) += exception.c
+smm-$(CONFIG_IDT_IN_EVERY_STAGE) += idt.S
+smm-y += memcpy.c
+smm-$(CONFIG_ARCH_RAMSTAGE_X86_32) += memmove_32.c
+smm-y += memset.c
+smm-$(CONFIG_X86_TOP4G_BOOTMEDIA_MAP) += mmap_boot.c
+smm-$(CONFIG_DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) += null_breakpoint.c
+
+smm-srcs += $(wildcard src/mainboard/$(MAINBOARDDIR)/smihandler.c)
diff --git a/src/arch/486/acpi.c b/src/arch/486/acpi.c
new file mode 100644
index 0000000000..0ff0ded9bf
--- /dev/null
+++ b/src/arch/486/acpi.c
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <acpi/acpi.h>
+#include <cf9_reset.h>
+
+void arch_fill_fadt(acpi_fadt_t *fadt)
+{
+	if (CONFIG(HAVE_CF9_RESET)) {
+		fadt->reset_reg.space_id = ACPI_ADDRESS_SPACE_IO;
+		fadt->reset_reg.bit_width = 8;
+		fadt->reset_reg.bit_offset = 0;
+		fadt->reset_reg.access_size = ACPI_ACCESS_SIZE_BYTE_ACCESS;
+		fadt->reset_reg.addrl = RST_CNT;
+		fadt->reset_reg.addrh = 0;
+
+		fadt->reset_value = RST_CPU | SYS_RST;
+
+		fadt->flags |= ACPI_FADT_RESET_REGISTER;
+	}
+}
diff --git a/src/arch/486/acpi/debug.asl b/src/arch/486/acpi/debug.asl
new file mode 100644
index 0000000000..589b874a76
--- /dev/null
+++ b/src/arch/486/acpi/debug.asl
@@ -0,0 +1,158 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+/*
+* 0x3F8: DEBCOM_BASE
+*
+* CREG: DEBCOM_REGION
+* CUAR: DEBCOM_UART
+* CDAT: DEBCOM_DATA
+* CDLM: DEBCOM_DLM
+* DLCR: DEBCOM_LCR
+* CMCR: DEBCOM_MCR
+* CLSR: DEBCOM_LSR
+*
+* DEBUG_INIT	DINI
+*/
+
+OperationRegion(CREG, SystemIO, 0x3F8, 8)
+	Field(CREG, ByteAcc, NoLock, Preserve)
+{
+	CDAT, 8,
+	CDLM, 8,, 8, DLCR, 8, CMCR, 8, CLSR, 8
+}
+
+/*
+* DINI
+* Initialize the COM port to 115,200 8-N-1
+*/
+Method(DINI)
+{
+	DLCR = 0x83
+	CDAT = 1	/* 115200 baud (low) */
+	CDLM = 0	/* 115200 baud (high) */
+	DLCR = 3	/* word=8 stop=1 parity=none */
+	CMCR = 3	/* DTR=1 RTS=1 Out2=Off Loop=Off */
+	CDLM = 0	/* turn off interrupts */
+}
+
+/*
+* THRE
+* Wait for COM port transmitter holding register to go empty
+*/
+Method(THRE)
+{
+	local0 = CLSR & 0x20
+	while (local0 == 0) {
+		local0 = CLSR & 0x20
+	}
+}
+
+/*
+* OUTX
+* Send a single raw character
+*/
+Method(OUTX, 1)
+{
+	THRE()
+	CDAT = Arg0
+}
+
+/*
+* OUTC
+* Send a single character, expanding LF into CR/LF
+*/
+Method(OUTC, 1)
+{
+	if (Arg0 == 0x0a) {
+		OUTX(0x0d)
+	}
+	OUTX(Arg0)
+}
+
+/*
+* DBGN
+* Send a single hex nibble
+*/
+Method(DBGN, 1)
+{
+	Local0 = Arg0 & 0x0f
+	if (Local0 < 10) {
+		Local0 += 0x30
+	} else {
+		Local0 += 0x37
+	}
+	OUTC(Local0)
+}
+
+/*
+* DBGB
+* Send a hex byte
+*/
+Method(DBGB, 1)
+{
+	Local0 = Arg0 >> 4
+	DBGN(Local0)
+	DBGN(Arg0)
+}
+
+/*
+* DBGW
+* Send a hex word
+*/
+Method(DBGW, 1)
+{
+	Local0 = Arg0 >> 8
+	DBGB(Local0)
+	DBGB(Arg0)
+}
+
+/*
+* DBGD
+* Send a hex Dword
+*/
+Method(DBGD, 1)
+{
+	Local0 = Arg0 >> 16
+	DBGW(Local0)
+	DBGW(Arg0)
+}
+
+/*
+* DBGO
+* Send either a string or an integer
+*/
+Method(DBGO, 1)
+{
+	/* DINI() */
+	if (ObjectType(Arg0) == 1) {
+		if (Arg0 > 0xffff) {
+			DBGD(Arg0)
+		} else {
+			if (Arg0 > 0xff) {
+				DBGW(Arg0)
+			} else {
+				DBGB(Arg0)
+			}
+		}
+	} else {
+		Name(BDBG, Buffer(80) {})
+		BDBG = Arg0
+		Local1 = 0
+		while (1) {
+			Local0 = GETC(BDBG, Local1)
+			if (Local0 == 0) {
+				return (0)
+			}
+			OUTC(Local0)
+			Local1++
+		}
+	}
+	return (0)
+}
+
+/* Get a char from a string */
+Method(GETC, 2)
+{
+	CreateByteField(Arg0, Arg1, DBGC)
+	return (DBGC)
+}
diff --git a/src/arch/486/acpi/globutil.asl b/src/arch/486/acpi/globutil.asl
new file mode 100644
index 0000000000..8f530f4bd5
--- /dev/null
+++ b/src/arch/486/acpi/globutil.asl
@@ -0,0 +1,100 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+/*
+Scope(\_SB) {
+	#include "globutil.asl"
+}
+*/
+
+/* string compare functions */
+Method(MIN, 2)
+{
+	if (Arg0 < Arg1) {
+		Return(Arg0)
+	} else {
+		Return(Arg1)
+	}
+}
+
+Method(SLEN, 1)
+{
+	Local0 = Arg0
+	Return(Sizeof(Local0))
+}
+
+Method(S2BF, 1, Serialized)
+{
+	Local0 = SLEN(Arg0) + 1
+	Name(BUFF, Buffer(Local0) {})
+	BUFF = Arg0
+	Return(BUFF)
+}
+
+/* Strong string compare.  Checks both length and content */
+Method(SCMP, 2)
+{
+	Local0 = S2BF(Arg0)
+	Local1 = S2BF(Arg1)
+	Local4 = 0
+	Local5 = SLEN(Arg0)
+	Local6 = SLEN(Arg1)
+	Local7 = MIN(Local5, Local6)
+
+	While(Local4 < Local7) {
+		Local2 = Derefof(Local0[Local4])
+		Local3 = Derefof(Local1[Local4])
+		if (Local2 > Local3) {
+			Return(1)
+		} else {
+			if (Local2 < Local3) {
+				Return(Ones)
+			}
+		}
+		Local4++
+	}
+	if (Local4 < Local5) {
+		Return(1)
+	} else {
+		if (Local4 < Local6) {
+			Return(Ones)
+		} else {
+			Return(Zero)
+		}
+	}
+}
+
+/* Weak string compare.  Checks to find Arg1 at beginning of Arg0.
+* Fails if length(Arg0) < length(Arg1).  Returns 0 on Fail, 1 on
+* Pass.
+*/
+Method(WCMP, 2)
+{
+	Local0 = S2BF(Arg0)
+	Local1 = S2BF(Arg1)
+	if (SLEN(Arg0) < SLEN(Arg1)) {
+		Return(0)
+	}
+	Local2 = 0
+	Local3 = SLEN(Arg1)
+
+	While(Local2 < Local3) {
+		if (Derefof(Local0[Local2]) != Derefof(Local1[Local2])) {
+			Return(0)
+		}
+		Local2++
+	}
+	Return(1)
+}
+
+/* ARG0 = IRQ Number(0-15)
+* Returns Bit Map
+*/
+Method(I2BM, 1)
+{
+	Local0 = 0
+	if (ARG0 != 0) {
+		Local1 = 1
+		Local0 = Local1 << ARG0
+	}
+	Return(Local0)
+}
diff --git a/src/arch/486/acpi/post.asl b/src/arch/486/acpi/post.asl
new file mode 100644
index 0000000000..dbdc68110f
--- /dev/null
+++ b/src/arch/486/acpi/post.asl
@@ -0,0 +1,17 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#if CONFIG(POST_IO)
+
+/* POST code support, typically on port 80 */
+OperationRegion (POST, SystemIO, CONFIG_POST_IO_PORT, 1)
+Field (POST, ByteAcc, Lock, Preserve)
+{
+	DBG0, 8
+}
+
+#else
+
+/* Dummy placeholder to avoid issues */
+Name (DBG0, 0)
+
+#endif
diff --git a/src/arch/486/acpi/statdef.asl b/src/arch/486/acpi/statdef.asl
new file mode 100644
index 0000000000..d1734bdf0b
--- /dev/null
+++ b/src/arch/486/acpi/statdef.asl
@@ -0,0 +1,74 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+
+/* Status and notification definitions */
+
+#define STA_MISSING			    0x00
+#define STA_PRESENT			    0x01
+#define	STA_ENABLED			    0x03
+#define STA_DISABLED		    0x09
+#define	STA_INVISIBLE		    0x0B
+#define	STA_UNAVAILABLE		    0x0D
+#define	STA_VISIBLE			    0x0F
+
+/* SMBus status codes */
+#define SMB_OK                  0x00
+#define SMB_UnknownFail         0x07
+#define SMB_DevAddrNAK          0x10
+#define SMB_DeviceError         0x11
+#define SMB_DevCmdDenied        0x12
+#define SMB_UnknownErr          0x13
+#define SMB_DevAccDenied        0x17
+#define SMB_Timeout             0x18
+#define SMB_HstUnsuppProtocol   0x19
+#define SMB_Busy                0x1A
+#define SMB_PktChkError         0x1F
+
+/* Device Object Notification Values */
+#define	NOTIFY_BUS_CHECK		0x00
+#define	NOTIFY_DEVICE_CHECK		0x01
+#define	NOTIFY_DEVICE_WAKE		0x02
+#define	NOTIFY_EJECT_REQUEST	0x03
+#define	NOTIFY_DEVICE_CHECK_JR	0x04
+#define	NOTIFY_FREQUENCY_ERROR	0x05
+#define	NOTIFY_BUS_MODE			0x06
+#define	NOTIFY_POWER_FAULT		0x07
+#define	NOTIFY_CAPABILITIES		0x08
+#define	NOTIFY_PLD_CHECK		0x09
+#define	NOTIFY_SLIT_UPDATE		0x0B
+
+/* Battery Device Notification Values */
+#define	NOTIFY_BAT_STATUSCHG	0x80
+#define	NOTIFY_BAT_INFOCHG	0x81
+#define	NOTIFY_BAT_MAINTDATA    0x82
+
+/* Power Source Object Notification Values */
+#define	NOTIFY_PWR_STATUSCHG	0x80
+
+/* Thermal Zone Object Notification Values */
+#define	NOTIFY_TZ_STATUSCHG	    0x80
+#define	NOTIFY_TZ_TRIPPTCHG	    0x81
+#define	NOTIFY_TZ_DEVLISTCHG	0x82
+#define	NOTIFY_TZ_RELTBLCHG	0x83
+
+/* Power Button Notification Values */
+#define	NOTIFY_POWER_BUTTON		0x80
+
+/* Sleep Button Notification Values */
+#define	NOTIFY_SLEEP_BUTTON		0x80
+
+/* Lid Notification Values */
+#define	NOTIFY_LID_STATUSCHG	0x80
+
+/* Processor Device Notification Values */
+#define	NOTIFY_CPU_PPCCHG	0x80
+#define	NOTIFY_CPU_CSTATECHG	0x81
+#define	NOTIFY_CPU_THROTLCHG    0x82
+
+/* User Presence Device Notification Values */
+#define	NOTIFY_USR_PRESNCECHG	0x80
+
+/* Battery Device Notification Values */
+#define	NOTIFY_ALS_ILLUMCHG	0x80
+#define	NOTIFY_ALS_COLORTMPCHG	0x81
+#define	NOTIFY_ALS_RESPCHG      0x82
diff --git a/src/arch/486/acpi_bert_storage.c b/src/arch/486/acpi_bert_storage.c
new file mode 100644
index 0000000000..5a58e52fe2
--- /dev/null
+++ b/src/arch/486/acpi_bert_storage.c
@@ -0,0 +1,599 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <bootstate.h>
+#include <cbmem.h>
+#include <console/console.h>
+#include <cpu/486/name.h>
+#include <acpi/acpi.h>
+#include <arch/bert_storage.h>
+#include <string.h>
+#include <types.h>
+
+/* BERT region management:  Allow the chipset to determine the specific
+ * location of the BERT region.  We find that base and size, then manage
+ * the allocation of error information within it.
+ *
+ * Use simple static variables for managing the BERT region.  This is a thin
+ * implementation; it is only created and consumed by coreboot, and only in
+ * a single stage, and we don't want its information to survive reboot or
+ * resume cycles.  If the requirements change, consider using IMD to help
+ * manage the space.
+ */
+static bool bert_region_broken;
+static void *bert_region_base;
+static size_t bert_region_size;
+static size_t bert_region_used;
+
+/* Calculate the remaining space in the BERT region.  This knowledge may help
+ * the caller prioritize the information to store.
+ */
+size_t bert_storage_remaining(void)
+{
+	return bert_region_broken ? 0 : bert_region_size - bert_region_used;
+}
+
+bool bert_errors_present(void)
+{
+	return !bert_region_broken && bert_region_used;
+}
+
+void bert_errors_region(void **start, size_t *size)
+{
+	if (bert_region_broken) {
+		*start = NULL;
+		*size = 0;
+		return;
+	}
+
+	/* No metadata, etc. with our region, so this is easy */
+	*start = bert_region_base;
+	*size = bert_region_used;
+}
+
+static void *bert_allocate_storage(size_t size)
+{
+	size_t alloc;
+
+	if (bert_region_broken)
+		return NULL;
+	if (bert_region_used + size > bert_region_size)
+		return NULL;
+
+	alloc = bert_region_used;
+	bert_region_used += size;
+
+	return (void *)((u8 *)bert_region_base + alloc);
+}
+
+/* Generic Error Status:  Each Status represents a unique error event within
+ * the BERT errors region.  Each event may have multiple errors associated
+ * with it.
+ */
+
+/* Find the nth (1-based) Generic Data Structure attached to an Error Status */
+static void *acpi_hest_generic_data_nth(
+		acpi_generic_error_status_t *status, int num)
+{
+	acpi_hest_generic_data_v300_t *ptr;
+	size_t struct_size;
+
+	if (!num || num > bert_entry_count(status))
+		return NULL;
+
+	ptr = (acpi_hest_generic_data_v300_t *)(status + 1);
+	while (--num) {
+		if (ptr->revision == HEST_GENERIC_ENTRY_V300)
+			struct_size = sizeof(acpi_hest_generic_data_v300_t);
+		else
+			struct_size = sizeof(acpi_hest_generic_data_t);
+		ptr = (acpi_hest_generic_data_v300_t *)(
+				(u8 *)ptr
+				+ ptr->data_length
+				+ struct_size);
+	}
+	return ptr;
+}
+
+/* Update data_length for this Error Status, and final Data Entry it contains */
+static void revise_error_sizes(acpi_generic_error_status_t *status, size_t size)
+{
+	acpi_hest_generic_data_v300_t *entry;
+	int entries;
+
+	if (!status)
+		return;
+
+	entries = bert_entry_count(status);
+	entry = acpi_hest_generic_data_nth(status, entries);
+	status->data_length += size;
+	if (entry)
+		entry->data_length += size;
+}
+
+/* Create space for a new BERT Generic Error Status Block, by finding the next
+ * available slot and moving the ending location.  There is nothing to designate
+ * this as another Generic Error Status Block (e.g. no signature); only that it
+ * is within the BERT region.
+ *
+ * It is up to the caller to correctly fill the information, including status
+ * and error severity, and to update/maintain data offsets and lengths as
+ * entries are added.
+ */
+static acpi_generic_error_status_t *new_bert_status(void)
+{
+	acpi_generic_error_status_t *status;
+
+	status = bert_allocate_storage(sizeof(*status));
+
+	if (!status) {
+		printk(BIOS_ERR, "New BERT error entry would exceed available region\n");
+		return NULL;
+	}
+
+	status->error_severity = ACPI_GENERROR_SEV_NONE;
+	return status;
+}
+
+/* Generic Error Data:  Each Generic Error Status may contain zero or more
+ * Generic Error Data structures.  The data structures describe particular
+ * error(s) associated with an event.  The definition for the structure is
+ * found in the ACPI spec, however the data types and any accompanying data
+ * definitions are in the Common Platform Error Record appendix of the UEFI
+ * spec.
+ */
+
+/* Create space for a new BERT Generic Data Entry.  Update the count and
+ * data length in the parent Generic Error Status Block.  Version 0x300 of
+ * the structure is used, and the timestamp is filled and marked precise
+ * (i.e. assumed close enough for reporting).
+ *
+ * It is up to the caller to fill the Section Type field and add the Common
+ * Platform Error Record type data as appropriate.  In addition, the caller
+ * should update the error severity, and may optionally add FRU information
+ * or override any existing information.
+ */
+static acpi_hest_generic_data_v300_t *new_generic_error_entry(
+		acpi_generic_error_status_t *status)
+{
+	acpi_hest_generic_data_v300_t *entry;
+
+	if (bert_entry_count(status) == GENERIC_ERR_STS_ENTRY_COUNT_MAX) {
+		printk(BIOS_ERR, "New BERT error would exceed maximum entries\n");
+		return NULL;
+	}
+
+	entry = bert_allocate_storage(sizeof(*entry));
+	if (!entry) {
+		printk(BIOS_ERR, "New BERT error entry would exceed available region\n");
+		return NULL;
+	}
+
+	entry->revision = HEST_GENERIC_ENTRY_V300;
+
+	entry->timestamp = cper_timestamp(CPER_TIMESTAMP_PRECISE);
+	entry->validation_bits |= ACPI_GENERROR_VALID_TIMESTAMP;
+
+	status->data_length += sizeof(*entry);
+	bert_bump_entry_count(status);
+
+	return entry;
+}
+
+/* Find the size of a CPER error section w/o any add-ons */
+static size_t sizeof_error_section(guid_t *guid)
+{
+	if (!guidcmp(guid, &CPER_SEC_PROC_GENERIC_GUID))
+		return sizeof(cper_proc_generic_error_section_t);
+	else if (!guidcmp(guid, &CPER_SEC_PROC_IA32X64_GUID))
+		return sizeof(cper_ia32x64_proc_error_section_t);
+	else if (!guidcmp(guid, &CPER_SEC_FW_ERR_REC_REF_GUID))
+		return sizeof(cper_fw_err_rec_section_t);
+	/* else if ... sizeof(structures not yet defined) */
+
+	printk(BIOS_ERR, "Requested size of unrecognized CPER GUID\n");
+	return 0;
+}
+
+void *new_cper_fw_error_crashlog(acpi_generic_error_status_t *status, size_t cl_size)
+{
+	void *cl_data = bert_allocate_storage(cl_size);
+	if (!cl_data) {
+		printk(BIOS_ERR, "Crashlog entry (size %zu) would exceed available region\n",
+			cl_size);
+		return NULL;
+	}
+
+	revise_error_sizes(status, cl_size);
+
+	return cl_data;
+}
+
+/* Helper to append an ACPI Generic Error Data Entry per crashlog data */
+acpi_hest_generic_data_v300_t *bert_append_fw_err(acpi_generic_error_status_t *status)
+{
+	acpi_hest_generic_data_v300_t *entry;
+	cper_fw_err_rec_section_t *fw_err;
+
+	entry = bert_append_error_datasection(status, &CPER_SEC_FW_ERR_REC_REF_GUID);
+	if (!entry)
+		return NULL;
+
+	status->block_status |= GENERIC_ERR_STS_UNCORRECTABLE_VALID;
+	status->error_severity = ACPI_GENERROR_SEV_FATAL;
+	entry->error_severity = ACPI_GENERROR_SEV_FATAL;
+
+	fw_err = section_of_acpientry(fw_err, entry);
+
+	fw_err->record_type = CRASHLOG_RECORD_TYPE;
+	fw_err->revision = CRASHLOG_FW_ERR_REV;
+	fw_err->record_id = 0;
+	guidcpy(&fw_err->record_guid, &FW_ERR_RECORD_ID_CRASHLOG_GUID);
+
+	return entry;
+}
+
+/* Append a new ACPI Generic Error Data Entry plus CPER Error Section to an
+ * existing ACPI Generic Error Status Block.  The caller is responsible for
+ * the setting the status and entry severity, as well as populating all fields
+ * of the error section.
+ */
+acpi_hest_generic_data_v300_t *bert_append_error_datasection(
+		acpi_generic_error_status_t *status, guid_t *guid)
+{
+	acpi_hest_generic_data_v300_t *entry;
+	void *sect;
+	size_t sect_size;
+
+	sect_size = sizeof_error_section(guid);
+	if (!sect_size)
+		return NULL; /* Don't allocate structure if bad GUID passed */
+
+	if (sizeof(*entry) + sect_size > bert_storage_remaining())
+		return NULL;
+
+	entry = new_generic_error_entry(status);
+	if (!entry)
+		return NULL;
+
+	/* error section immediately follows the Generic Error Data Entry */
+	sect = bert_allocate_storage(sect_size);
+	if (!sect)
+		return NULL;
+
+	revise_error_sizes(status, sect_size);
+
+	guidcpy(&entry->section_type, guid);
+	return entry;
+}
+
+/* Helper to append an ACPI Generic Error Data Entry plus a CPER Processor
+ * Generic Error Section.  As many fields are populated as possible for the
+ * caller.
+ */
+acpi_hest_generic_data_v300_t *bert_append_genproc(
+		acpi_generic_error_status_t *status)
+{
+	acpi_hest_generic_data_v300_t *entry;
+	cper_proc_generic_error_section_t *ges;
+
+	entry = bert_append_error_datasection(status,
+					&CPER_SEC_PROC_GENERIC_GUID);
+	if (!entry)
+		return NULL;
+
+	status->block_status |= GENERIC_ERR_STS_UNCORRECTABLE_VALID;
+	status->error_severity = ACPI_GENERROR_SEV_FATAL;
+
+	entry->error_severity = ACPI_GENERROR_SEV_FATAL;
+
+	ges = section_of_acpientry(ges, entry);
+
+	ges->proc_type = GENPROC_PROCTYPE_IA32X64;
+	ges->validation |= GENPROC_VALID_PROC_TYPE;
+
+	ges->cpu_version = cpuid_eax(1);
+	ges->validation |= GENPROC_VALID_CPU_VERSION;
+
+	fill_processor_name(ges->cpu_brand_string);
+	ges->validation |= GENPROC_VALID_CPU_BRAND;
+
+	ges->proc_id = lapicid();
+	ges->validation |= GENPROC_VALID_CPU_ID;
+
+	return entry;
+}
+
+/* Add a new IA32/X64 Processor Context Structure (Table 261), following any
+ * other contexts, to an existing Processor Error Section (Table 255).  Contexts
+ * may only be added after the entire Processor Error Info array has been
+ * created.
+ *
+ * This function fills only the minimal amount of information required to parse
+ * or step through the contexts.  The type is filled and PROC_CONTEXT_INFO_NUM
+ * is updated.
+ *
+ * type is one of:
+ *   CPER_IA32X64_CTX_UNCL
+ *   CPER_IA32X64_CTX_MSR
+ *   CPER_IA32X64_CTX_32BIT_EX
+ *   CPER_IA32X64_CTX_64BIT_EX
+ *   CPER_IA32X64_CTX_FXSAVE
+ *   CPER_IA32X64_CTX_32BIT_DBG
+ *   CPER_IA32X64_CTX_64BIT_DBG
+ *   CPER_IA32X64_CTX_MEMMAPPED
+ * num is the number of bytes eventually used to fill the context's register
+ *   array, e.g. 4 MSRs * sizeof(msr_t)
+ *
+ * status and entry data_length values are updated.
+ */
+cper_ia32x64_context_t *new_cper_ia32x64_ctx(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err, int type, int num)
+{
+	size_t size;
+	cper_ia32x64_context_t *ctx;
+	static const char * const ctx_names[] = {
+			"Unclassified Data",
+			"MSR Registers",
+			"32-bit Mode Execution",
+			"64-bit Mode Execution",
+			"FXSAVE",
+			"32-bit Mode Debug",
+			"64-bit Mode Debug",
+			"Memory Mapped"
+	};
+
+	if (type > CPER_IA32X64_CTX_MEMMAPPED)
+		return NULL;
+
+	if (cper_ia32x64_proc_num_ctxs(x86err) == I32X64SEC_VALID_CTXNUM_MAX) {
+		printk(BIOS_ERR, "New IA32X64 %s context entry would exceed max allowable contexts\n",
+				ctx_names[type]);
+		return NULL;
+	}
+
+	size = cper_ia32x64_ctx_sz_bytype(type, num);
+	ctx = bert_allocate_storage(size);
+	if (!ctx) {
+		printk(BIOS_ERR, "New IA32X64 %s context entry would exceed available region\n",
+				ctx_names[type]);
+		return NULL;
+	}
+
+	revise_error_sizes(status, size);
+
+	ctx->type = type;
+	ctx->array_size = num;
+	cper_bump_ia32x64_ctx_count(x86err);
+
+	return ctx;
+}
+
+/* Add a new IA32/X64 Processor Error Information Structure (Table 256),
+ * following any other errors, to an existing Processor Error Section
+ * (Table 255).  All error structures must be added before any contexts are
+ * added.
+ *
+ * This function fills only the minimal amount of information required to parse
+ * or step through the errors.  The type is filled and PROC_ERR_INFO_NUM is
+ * updated.
+ */
+cper_ia32x64_proc_error_info_t *new_cper_ia32x64_check(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err,
+		enum cper_x86_check_type type)
+{
+	cper_ia32x64_proc_error_info_t *check;
+	static const char * const check_names[] = {
+			"cache",
+			"TLB",
+			"bus",
+			"MS"
+	};
+	const guid_t check_guids[] = {
+			X86_PROCESSOR_CACHE_CHK_ERROR_GUID,
+			X86_PROCESSOR_TLB_CHK_ERROR_GUID,
+			X86_PROCESSOR_BUS_CHK_ERROR_GUID,
+			X86_PROCESSOR_MS_CHK_ERROR_GUID
+	};
+
+	if (type > X86_PROCESSOR_CHK_MAX)
+		return NULL;
+
+	if (cper_ia32x64_proc_num_chks(x86err) == I32X64SEC_VALID_ERRNUM_MAX) {
+		printk(BIOS_ERR, "New IA32X64 %s check entry would exceed max allowable errors\n",
+				check_names[type]);
+		return NULL;
+	}
+
+	check = bert_allocate_storage(sizeof(*check));
+	if (!check) {
+		printk(BIOS_ERR, "New IA32X64 %s check entry would exceed available region\n",
+				check_names[type]);
+		return NULL;
+	}
+
+	revise_error_sizes(status, sizeof(*check));
+
+	guidcpy(&check->type, &check_guids[type]);
+	cper_bump_ia32x64_chk_count(x86err);
+
+	return check;
+}
+
+/* Helper to append an ACPI Generic Error Data Entry plus a CPER IA32/X64
+ * Processor Error Section.  As many fields are populated as possible for the
+ * caller.
+ */
+acpi_hest_generic_data_v300_t *bert_append_ia32x64(
+					acpi_generic_error_status_t *status)
+{
+	acpi_hest_generic_data_v300_t *entry;
+	cper_ia32x64_proc_error_section_t *ipe;
+	struct cpuid_result id;
+
+	entry = bert_append_error_datasection(status,
+					&CPER_SEC_PROC_IA32X64_GUID);
+	if (!entry)
+		return NULL;
+
+	status->block_status |= GENERIC_ERR_STS_UNCORRECTABLE_VALID;
+	status->error_severity = ACPI_GENERROR_SEV_FATAL;
+
+	entry->error_severity = ACPI_GENERROR_SEV_FATAL;
+
+	ipe = section_of_acpientry(ipe, entry);
+
+	ipe->apicid = lapicid();
+	ipe->validation |= I32X64SEC_VALID_LAPIC;
+
+	id = cpuid(1);
+	ipe->cpuid[0] = id.eax;
+	ipe->cpuid[1] = id.ebx;
+	ipe->cpuid[2] = id.ecx;
+	ipe->cpuid[3] = id.edx;
+	ipe->validation |= I32X64SEC_VALID_CPUID;
+
+	return entry;
+}
+
+static const char * const generic_error_types[] = {
+	"PROCESSOR_GENERIC",
+	"PROCESSOR_SPECIFIC_X86",
+	"PROCESSOR_SPECIFIC_ARM",
+	"PLATFORM_MEMORY",
+	"PLATFORM_MEMORY2",
+	"PCIE",
+	"FW_ERROR_RECORD",
+	"PCI_PCIX_BUS",
+	"PCI_DEVICE",
+	"DMAR_GENERIC",
+	"DIRECTED_IO_DMAR",
+	"IOMMU_DMAR",
+	"UNRECOGNIZED"
+};
+
+static const char *generic_error_name(guid_t *guid)
+{
+	if (!guidcmp(guid, &CPER_SEC_PROC_GENERIC_GUID))
+		return generic_error_types[0];
+	if (!guidcmp(guid, &CPER_SEC_PROC_IA32X64_GUID))
+		return generic_error_types[1];
+	if (!guidcmp(guid, &CPER_SEC_PROC_ARM_GUID))
+		return generic_error_types[2];
+	if (!guidcmp(guid, &CPER_SEC_PLATFORM_MEM_GUID))
+		return generic_error_types[3];
+	if (!guidcmp(guid, &CPER_SEC_PLATFORM_MEM2_GUID))
+		return generic_error_types[4];
+	if (!guidcmp(guid, &CPER_SEC_PCIE_GUID))
+		return generic_error_types[5];
+	if (!guidcmp(guid, &CPER_SEC_FW_ERR_REC_REF_GUID))
+		return generic_error_types[6];
+	if (!guidcmp(guid, &CPER_SEC_PCI_X_BUS_GUID))
+		return generic_error_types[7];
+	if (!guidcmp(guid, &CPER_SEC_PCI_DEV_GUID))
+		return generic_error_types[8];
+	if (!guidcmp(guid, &CPER_SEC_DMAR_GENERIC_GUID))
+		return generic_error_types[9];
+	if (!guidcmp(guid, &CPER_SEC_DMAR_VT_GUID))
+		return generic_error_types[10];
+	if (!guidcmp(guid, &CPER_SEC_DMAR_IOMMU_GUID))
+		return generic_error_types[11];
+	return generic_error_types[12];
+}
+
+/* Add a new event to the BERT region.  An event consists of an ACPI Error
+ * Status Block, a Generic Error Data Entry, and an associated CPER Error
+ * Section.
+ */
+acpi_generic_error_status_t *bert_new_event(guid_t *guid)
+{
+	size_t size;
+	acpi_generic_error_status_t *status;
+	acpi_hest_generic_data_v300_t *entry, *r;
+
+	size = sizeof(*status);
+	size += sizeof(*entry);
+	size += sizeof_error_section(guid);
+
+	if (size > bert_storage_remaining()) {
+		printk(BIOS_ERR, "Not enough BERT region space to add event for type %s\n",
+				generic_error_name(guid));
+		return NULL;
+	}
+
+	status = new_bert_status();
+	if (!status)
+		return NULL;
+
+	if (!guidcmp(guid, &CPER_SEC_PROC_GENERIC_GUID))
+		r = bert_append_genproc(status);
+	else if (!guidcmp(guid, &CPER_SEC_PROC_GENERIC_GUID))
+		r = bert_append_ia32x64(status);
+	else if (!guidcmp(guid, &CPER_SEC_FW_ERR_REC_REF_GUID))
+		r = bert_append_fw_err(status);
+	/* else if other types not implemented */
+	else
+		r = NULL;
+
+	if (r)
+		return status;
+	return NULL;
+}
+
+/* Helper to add an MSR context to an existing IA32/X64-type error entry */
+cper_ia32x64_context_t *cper_new_ia32x64_context_msr(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err, u32 addr, int num)
+{
+	cper_ia32x64_context_t *ctx;
+	int i;
+	msr_t *dest;
+
+	ctx = new_cper_ia32x64_ctx(status, x86err, CPER_IA32X64_CTX_MSR, num);
+	if (!ctx)
+		return NULL;
+
+	/* already filled ctx->type = CPER_IA32X64_CTX_MSR; */
+	ctx->msr_addr = addr;
+	ctx->array_size = num * sizeof(msr_t);
+
+	dest = (msr_t *)((u8 *)(ctx + 1)); /* point to the Register Array */
+
+	for (i = 0 ; i < num ; i++)
+		*(dest + i) = rdmsr(addr + i);
+	return ctx;
+}
+
+static void bert_reserved_region(void **start, size_t *size)
+{
+	if (!CONFIG(ACPI_BERT)) {
+		*start = NULL;
+		*size = 0;
+	} else {
+		*start = cbmem_add(CBMEM_ID_ACPI_BERT, CONFIG_ACPI_BERT_SIZE);
+		*size = CONFIG_ACPI_BERT_SIZE;
+	}
+	printk(BIOS_INFO, "Reserved BERT region base: %p, size: 0x%zx\n", *start, *size);
+}
+
+static void bert_storage_setup(void *unused)
+{
+	/* Always start with a blank bert region.  Make sure nothing is
+	 * maintained across reboots or resumes.
+	 */
+	bert_region_broken = false;
+	bert_region_used = 0;
+
+	bert_reserved_region(&bert_region_base, &bert_region_size);
+
+	if (!bert_region_base || !bert_region_size) {
+		printk(BIOS_ERR, "Bug: Can't find/add BERT storage area\n");
+		bert_region_broken = true;
+		return;
+	}
+
+	memset(bert_region_base, 0, bert_region_size);
+}
+
+BOOT_STATE_INIT_ENTRY(BS_PRE_DEVICE, BS_ON_EXIT, bert_storage_setup, NULL);
diff --git a/src/arch/486/acpi_s3.c b/src/arch/486/acpi_s3.c
new file mode 100644
index 0000000000..ec1fafcd3c
--- /dev/null
+++ b/src/arch/486/acpi_s3.c
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <console/console.h>
+#include <string.h>
+#include <acpi/acpi.h>
+#include <arch/cpu.h>
+#include <commonlib/helpers.h>
+#include <fallback.h>
+#include <timestamp.h>
+
+#define WAKEUP_BASE 0x600
+
+asmlinkage void (*acpi_do_wakeup)(uintptr_t vector) = (void *)WAKEUP_BASE;
+
+extern unsigned char __wakeup;
+extern unsigned int __wakeup_size;
+
+void __noreturn acpi_resume(void *wake_vec)
+{
+	/* Call mainboard resume handler first, if defined. */
+	mainboard_suspend_resume();
+
+	/* Copy wakeup trampoline in place. */
+	memcpy((void *)WAKEUP_BASE, &__wakeup, __wakeup_size);
+
+	set_boot_successful();
+
+	timestamp_add_now(TS_ACPI_WAKE_JUMP);
+
+	post_code(POST_OS_RESUME);
+	acpi_do_wakeup((uintptr_t)wake_vec);
+
+	die("Failed the jump to wakeup vector\n");
+}
diff --git a/src/arch/486/assembly_entry.S b/src/arch/486/assembly_entry.S
new file mode 100644
index 0000000000..7f4cd5d34f
--- /dev/null
+++ b/src/arch/486/assembly_entry.S
@@ -0,0 +1,70 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+/*
+ * This path is for stages that are post bootblock. The gdt is reloaded
+ * to accommodate platforms that are executing out of CAR. In order to
+ * continue with C code execution one needs to set stack pointer and
+ * clear .bss variables that are stage specific.
+ */
+
+#if CONFIG(RESET_VECTOR_IN_RAM)
+	#define _STACK_TOP _eearlyram_stack
+#else
+	#define _STACK_TOP _ecar_stack
+#endif
+
+#if ENV_X86_64
+.code64
+#else
+.code32
+#endif
+
+.section ".text._start", "ax", @progbits
+.global _start
+_start:
+	/* Migrate GDT to this text segment */
+#if ENV_X86_64
+	call	gdt_init64
+#else
+	call	gdt_init
+#endif
+
+/*rdtsc*/
+	/* reset stack pointer to CAR/EARLYRAM stack */
+	mov	$_STACK_TOP, %esp
+
+	/* clear .bss section as it is not shared */
+#if ENV_SEPARATE_BSS
+	cld
+	xor	%eax, %eax
+	movl	$(_ebss), %ecx
+	movl	$(_bss), %edi
+	sub	%edi, %ecx
+	shrl	$2, %ecx
+	rep	stosl
+#endif
+
+#if ((ENV_SEPARATE_VERSTAGE && CONFIG(VERSTAGE_DEBUG_SPINLOOP)) \
+	|| (ENV_ROMSTAGE && CONFIG(ROMSTAGE_DEBUG_SPINLOOP)))
+
+	/* Wait for a JTAG debugger to break in and set EBX non-zero */
+	xor	%ebx, %ebx
+
+debug_spinloop:
+	cmp	$0, %ebx
+	jz	debug_spinloop
+#endif
+
+	andl	$0xfffffff0, %esp
+#if CONFIG(IDT_IN_EVERY_STAGE)
+	call	exception_init
+#endif
+
+#if CONFIG(ASAN_IN_ROMSTAGE)
+	call	asan_init
+#endif
+	call	car_stage_entry
+
+	/* Expect to never return. */
+1:
+	jmp	1b
diff --git a/src/arch/486/boot.c b/src/arch/486/boot.c
new file mode 100644
index 0000000000..d31732361d
--- /dev/null
+++ b/src/arch/486/boot.c
@@ -0,0 +1,78 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/boot/boot.h>
+#include <arch/cpu.h>
+#include <commonlib/helpers.h>
+#include <console/console.h>
+#include <program_loading.h>
+#include <ip_checksum.h>
+#include <symbols.h>
+#include <assert.h>
+
+int payload_arch_usable_ram_quirk(uint64_t start, uint64_t size)
+{
+	if (start < 1 * MiB && (start + size) <= 1 * MiB) {
+		printk(BIOS_DEBUG,
+			"Payload being loaded at 0x%08llx below 1MiB without region being marked as RAM usable.\n", start);
+		return 1;
+	}
+
+	return 0;
+}
+
+void arch_prog_run(struct prog *prog)
+{
+#if ENV_RAMSTAGE && ENV_X86_64
+	const uint32_t arg = pointer_to_uint32_safe(prog_entry_arg(prog));
+	const uint32_t entry = pointer_to_uint32_safe(prog_entry(prog));
+
+	/* On x86 coreboot payloads expect to be called in protected mode */
+	protected_mode_jump(entry, arg);
+#else
+#if ENV_X86_64
+	void (*doit)(void *arg);
+#else
+	/* Ensure the argument is pushed on the stack. */
+	asmlinkage void (*doit)(void *arg);
+#endif
+
+	#if ENV_ROMSTAGE
+	#if 0
+	u8 * dptr = (u8 *)prog;
+	printk(BIOS_DEBUG, "PROG dump:\n");
+	for (unsigned idx=0;idx<28;idx++) {
+		if ((idx % 16) == 0) {
+			printk(BIOS_DEBUG, "%p: ", &dptr[idx]);
+		}
+		printk(BIOS_DEBUG, "%02hhx ", dptr[idx]);
+		if ((idx % 16) == 15) {
+			printk(BIOS_DEBUG, "\n");
+		}
+	}
+	printk(BIOS_DEBUG, "\n");
+
+	dptr = (u8 *)prog_entry(prog);
+	printk(BIOS_DEBUG, "doit dump:\n");
+	for (unsigned idx=0;idx<0x100;idx++) {
+		if ((idx % 16) == 0) {
+			printk(BIOS_DEBUG, "%p: ", &dptr[idx]);
+		}
+		printk(BIOS_DEBUG, "%02hhx ", dptr[idx]);
+		if ((idx % 16) == 15) {
+			printk(BIOS_DEBUG, "\n");
+		}
+	}
+	printk(BIOS_DEBUG, "\n");
+
+	#endif
+	#endif
+
+	doit = prog_entry(prog);
+
+	printk(BIOS_DEBUG, "DOIT prog:%p doit:%p arg %p\n",
+		prog, doit, prog_entry_arg(prog)
+	);
+
+	doit(prog_entry_arg(prog));
+#endif
+}
diff --git a/src/arch/486/bootblock.ld b/src/arch/486/bootblock.ld
new file mode 100644
index 0000000000..1126c84b9b
--- /dev/null
+++ b/src/arch/486/bootblock.ld
@@ -0,0 +1,117 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+gdtptr_offset = gdtptr & 0xffff;
+nullidt_offset = nullidt & 0xffff;
+
+/* Symbol _start16bit must be aligned to 4kB to start AP CPUs with
+ * Startup IPI message without RAM.
+ */
+#if CONFIG(SIPI_VECTOR_IN_ROM)
+_bogus = ASSERT((_start16bit & 0xfff) == 0, "Symbol _start16bit is not at 4 KiB boundary");
+ap_sipi_vector_in_rom = (_start16bit >> 12) & 0xff;
+#endif
+
+SECTIONS {
+
+#if CONFIG(FIXED_BOOTBLOCK_SIZE)
+	. = _ebootblock - CONFIG_C_ENV_BOOTBLOCK_SIZE;
+#else
+	. = BOOTBLOCK_TOP - PROGRAM_SZ;
+	. = ALIGN(64);
+#endif
+
+	_bootblock = .;
+
+	INCLUDE "bootblock/lib/program.ld"
+
+	/*
+	 * Allocation reserves extra space here. Alignment requirements
+	 * may cause the total size of a section to change when the start
+	 * address gets applied.
+	 */
+	PROGRAM_SZ = SIZEOF(.text) + 512;
+
+	. = MIN(_ECFW_PTR, MIN(_ID_SECTION, _FIT_POINTER)) - EARLYASM_SZ;
+	. = CONFIG(SIPI_VECTOR_IN_ROM) ? ALIGN(4096) : ALIGN(16);
+	BOOTBLOCK_TOP = .;
+	.init (.) : {
+		*(.init._start);
+		*(.init);
+		*(.init.*);
+	}
+
+	/*
+	 * Allocation reserves extra space here. Alignment requirements
+	 * may cause the total size of a section to change when the start
+	 * address gets applied.
+	 */
+	EARLYASM_SZ = SIZEOF(.init) + (CONFIG(SIPI_VECTOR_IN_ROM) ? 4096 : 16);
+
+	. = _ID_SECTION;
+	.id (.): {
+		KEEP(*(.id));
+	}
+
+	/* Flashrom and FILO have two alternatives for the location of .id section. */
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	_ID_SECTION_END = SIZEOF(.fit_pointer) && SIZEOF(.id) > 0x28 ? 0x000fff80 : _X86_RESET_VECTOR;
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	_ID_SECTION_END = SIZEOF(.fit_pointer) && SIZEOF(.id) > 0x28 ? 0xffffff80 : _X86_RESET_VECTOR;
+#endif
+
+
+	_ID_SECTION = _ID_SECTION_END - SIZEOF(.id);
+
+	. = _ECFW_PTR;
+	.ecfw_ptr (.): {
+		ASSERT((SIZEOF(.ecfw_ptr) == CONFIG_ECFW_PTR_SIZE), "Size of ecfw_ptr is incorrect");
+		KEEP(*(.ecfw_ptr));
+	}
+	_ECFW_PTR = SIZEOF(.ecfw_ptr) ? CONFIG_ECFW_PTR_ADDR : _X86_RESET_VECTOR;
+
+	. = _FIT_POINTER;
+	.fit_pointer (.): {
+		KEEP(*(.fit_pointer));
+	}
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	_FIT_POINTER = SIZEOF(.fit_pointer) ? 0x000fffc0 : _X86_RESET_VECTOR;
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	_FIT_POINTER = SIZEOF(.fit_pointer) ? 0xffffffc0 : _X86_RESET_VECTOR;
+#endif
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	. = 0x000ffff0;
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	. = 0xfffffff0;
+#endif
+	_X86_RESET_VECTOR = .;
+	.reset . : {
+		*(.reset);
+		. = _X86_RESET_VECTOR_FILLING;
+		BYTE(0);
+	}
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	. = 0x000ffffc;
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	. = 0xfffffffc;
+#endif
+	.header_pointer . : {
+		KEEP(*(.header_pointer));
+	}
+	_X86_RESET_VECTOR_FILLING = 15 - SIZEOF(.header_pointer);
+	_ebootblock = .;
+}
+
+/*
+ * Tests _bogus1 and _bogus2 are here to detect case of symbol addresses truncated
+ * to 32 bits and intermediate files reaching size of close to 4 GiB.
+ */
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+_bogus1 = ASSERT(_bootblock & 0x80000000, "_bootblock too low, invalid ld script");
+_bogus2 = ASSERT(_start16bit & 0x80000000, "_start16bit too low, invalid ld script");
+_bogus3 = ASSERT(_start16bit >= 0xffff0000, "_start16bit too low. Please report.");
+_bogus4 = ASSERT(_ebootblock - _bootblock <= CONFIG_C_ENV_BOOTBLOCK_SIZE,
+		 "_bootblock too low, increase C_ENV_BOOTBLOCK_SIZE");
+#endif
diff --git a/src/arch/486/bootblock_normal.c b/src/arch/486/bootblock_normal.c
new file mode 100644
index 0000000000..4bc9b01332
--- /dev/null
+++ b/src/arch/486/bootblock_normal.c
@@ -0,0 +1,33 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cbfs.h>
+#include <fallback.h>
+#include <program_loading.h>
+#include <stddef.h>
+
+static const char *get_fallback(const char *stagelist)
+{
+	while (*stagelist)
+		stagelist++;
+	return ++stagelist;
+}
+
+enum cb_err legacy_romstage_select_and_load(struct prog *romstage)
+{
+	static const char *default_filenames = "normal/romstage\0fallback/romstage";
+	const char *boot_candidate;
+	size_t stages_len;
+
+	boot_candidate = cbfs_map("coreboot-stages", &stages_len);
+	if (!boot_candidate)
+		boot_candidate = default_filenames;
+
+	if (do_normal_boot()) {
+		romstage->name = boot_candidate;
+		if (cbfs_prog_stage_load(romstage) == CB_SUCCESS)
+			return CB_SUCCESS;
+	}
+
+	romstage->name = get_fallback(boot_candidate);
+	return cbfs_prog_stage_load(romstage);
+}
diff --git a/src/arch/486/breakpoint.c b/src/arch/486/breakpoint.c
new file mode 100644
index 0000000000..d3ba783a55
--- /dev/null
+++ b/src/arch/486/breakpoint.c
@@ -0,0 +1,299 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+#include <arch/registers.h>
+#include <arch/breakpoint.h>
+#include <console/console.h>
+#include <types.h>
+
+#define DEBUG_REGISTER_COUNT 4
+
+/* Each enable field is 2 bits and starts at bit 0 */
+#define DEBUG_CTRL_ENABLE_SHIFT(index) (2 * (index))
+#define DEBUG_CTRL_ENABLE_MASK(index) (0x3 << DEBUG_CTRL_ENABLE_SHIFT(index))
+#define DEBUG_CTRL_ENABLE(index, enable) ((enable) << DEBUG_CTRL_ENABLE_SHIFT(index))
+
+/* Each breakpoint has a length and type, each is two bits and start at bit 16 */
+#define DEBUG_CTRL_LT_SHIFT(index) (4 * (index) + 16)
+#define DEBUG_CTRL_LT_MASK(index) (0xf << DEBUG_CTRL_LT_SHIFT(index))
+#define DEBUG_CTRL_LT(index, len, type) ((((len) << 2 | (type))) << DEBUG_CTRL_LT_SHIFT(index))
+
+/* Each field is one bit, starting at bit 0 */
+#define DEBUG_STATUS_BP_HIT_MASK(index) (1 << (index))
+#define DEBUG_STATUS_GET_BP_HIT(index, value) \
+	(((value) & DEBUG_STATUS_BP_HIT_MASK(index)) >> (index))
+
+/* Breakpoint lengths values */
+#define DEBUG_CTRL_LEN_1 0x0
+#define DEBUG_CTRL_LEN_2 0x1
+#define DEBUG_CTRL_LEN_8 0x2
+#define DEBUG_CTRL_LEN_4 0x3
+
+/* Breakpoint enable values */
+#define DEBUG_CTRL_ENABLE_LOCAL 0x1
+#define DEBUG_CTRL_ENABLE_GLOBAL 0x2
+
+/* eflags/rflags bit to continue execution after hitting an instruction breakpoint */
+#define FLAGS_RESUME (1 << 16)
+
+struct breakpoint {
+	bool allocated;
+	enum breakpoint_type type;
+	breakpoint_handler handler;
+};
+
+static struct breakpoint breakpoints[DEBUG_REGISTER_COUNT];
+
+static inline bool debug_write_addr_reg(int index, uintptr_t value)
+{
+	switch (index) {
+	case 0:
+		asm("mov %0, %%dr0" ::"r"(value));
+		break;
+
+	case 1:
+		asm("mov %0, %%dr1" ::"r"(value));
+		break;
+
+	case 2:
+		asm("mov %0, %%dr2" ::"r"(value));
+		break;
+
+	case 3:
+		asm("mov %0, %%dr3" ::"r"(value));
+		break;
+
+	default:
+		return false;
+	}
+
+	return true;
+}
+
+static inline uintptr_t debug_read_status(void)
+{
+	uintptr_t ret = 0;
+
+	asm("mov %%dr6, %0" : "=r"(ret));
+	return ret;
+}
+
+static inline void debug_write_status(uintptr_t value)
+{
+	asm("mov %0, %%dr6" ::"r"(value));
+}
+
+static inline uintptr_t debug_read_control(void)
+{
+	uintptr_t ret = 0;
+
+	asm("mov %%dr7, %0" : "=r"(ret));
+	return ret;
+}
+
+static inline void debug_write_control(uintptr_t value)
+{
+	asm("mov %0, %%dr7" ::"r"(value));
+}
+
+static enum breakpoint_result allocate_breakpoint(struct breakpoint_handle *out_handle,
+						  enum breakpoint_type type)
+{
+	for (int i = 0; i < DEBUG_REGISTER_COUNT; i++) {
+		if (breakpoints[i].allocated)
+			continue;
+
+		breakpoints[i].allocated = true;
+		breakpoints[i].handler = NULL;
+		breakpoints[i].type = type;
+		out_handle->bp = i;
+		return BREAKPOINT_RES_OK;
+	}
+
+	return BREAKPOINT_RES_NONE_AVAILABLE;
+}
+
+static enum breakpoint_result validate_handle(struct breakpoint_handle handle)
+{
+	int bp = handle.bp;
+
+	if (bp < 0 || bp >= DEBUG_REGISTER_COUNT || !breakpoints[bp].allocated)
+		return BREAKPOINT_RES_INVALID_HANDLE;
+
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_create_instruction(struct breakpoint_handle *out_handle,
+						     void *virt_addr)
+{
+	enum breakpoint_result res =
+		allocate_breakpoint(out_handle, BREAKPOINT_TYPE_INSTRUCTION);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	int bp = out_handle->bp;
+	if (!debug_write_addr_reg(bp, (uintptr_t)virt_addr))
+		return BREAKPOINT_RES_INVALID_HANDLE;
+
+	uintptr_t control = debug_read_control();
+	control &= ~DEBUG_CTRL_LT_MASK(bp);
+	control |= DEBUG_CTRL_LT(bp, DEBUG_CTRL_LEN_1, BREAKPOINT_TYPE_INSTRUCTION);
+	debug_write_control(control);
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_create_data(struct breakpoint_handle *out_handle,
+					      void *virt_addr, size_t len, bool write_only)
+{
+	uintptr_t len_value = 0;
+
+	switch (len) {
+	case 1:
+		len_value = DEBUG_CTRL_LEN_1;
+		break;
+
+	case 2:
+		len_value = DEBUG_CTRL_LEN_2;
+		break;
+
+	case 4:
+		len_value = DEBUG_CTRL_LEN_4;
+		break;
+
+	case 8:
+		/* Only supported on 64-bit CPUs */
+		if (!ENV_X86_64)
+			return BREAKPOINT_RES_INVALID_LENGTH;
+		len_value = DEBUG_CTRL_LEN_8;
+		break;
+
+	default:
+		return BREAKPOINT_RES_INVALID_LENGTH;
+	}
+
+	enum breakpoint_type type =
+		write_only ? BREAKPOINT_TYPE_DATA_WRITE : BREAKPOINT_TYPE_DATA_RW;
+	enum breakpoint_result res = allocate_breakpoint(out_handle, type);
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	int bp = out_handle->bp;
+	if (!debug_write_addr_reg(bp, (uintptr_t)virt_addr))
+		return BREAKPOINT_RES_INVALID_HANDLE;
+
+	uintptr_t control = debug_read_control();
+	control &= ~DEBUG_CTRL_LT_MASK(bp);
+	control |= DEBUG_CTRL_LT(bp, len_value, type);
+	debug_write_control(control);
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_remove(struct breakpoint_handle handle)
+{
+	enum breakpoint_result res = validate_handle(handle);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+	breakpoint_enable(handle, false);
+
+	int bp = handle.bp;
+	breakpoints[bp].allocated = false;
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_enable(struct breakpoint_handle handle, bool enabled)
+{
+	enum breakpoint_result res = validate_handle(handle);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	uintptr_t control = debug_read_control();
+	int bp = handle.bp;
+	control &= ~DEBUG_CTRL_ENABLE_MASK(bp);
+	if (enabled)
+		control |= DEBUG_CTRL_ENABLE(bp, DEBUG_CTRL_ENABLE_GLOBAL);
+	debug_write_control(control);
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_get_type(struct breakpoint_handle handle,
+					   enum breakpoint_type *type)
+{
+	enum breakpoint_result res = validate_handle(handle);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	*type = breakpoints[handle.bp].type;
+	return BREAKPOINT_RES_OK;
+}
+
+enum breakpoint_result breakpoint_set_handler(struct breakpoint_handle handle,
+					      breakpoint_handler handler)
+{
+	enum breakpoint_result res = validate_handle(handle);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	breakpoints[handle.bp].handler = handler;
+	return BREAKPOINT_RES_OK;
+}
+
+static enum breakpoint_result is_breakpoint_hit(struct breakpoint_handle handle, bool *out_hit)
+{
+	enum breakpoint_result res = validate_handle(handle);
+
+	if (res != BREAKPOINT_RES_OK)
+		return res;
+
+	uintptr_t status = debug_read_status();
+	*out_hit = DEBUG_STATUS_GET_BP_HIT(handle.bp, status);
+
+	return BREAKPOINT_RES_OK;
+}
+
+int breakpoint_dispatch_handler(struct eregs *info)
+{
+	bool instr_bp_hit = 0;
+
+	for (int i = 0; i < DEBUG_REGISTER_COUNT; i++) {
+		struct breakpoint_handle handle = { i };
+		bool hit = false;
+		enum breakpoint_type type;
+
+		if (is_breakpoint_hit(handle, &hit) != BREAKPOINT_RES_OK || !hit)
+			continue;
+
+		if (breakpoint_get_type(handle, &type) != BREAKPOINT_RES_OK)
+			continue;
+
+		instr_bp_hit |= type == BREAKPOINT_TYPE_INSTRUCTION;
+
+		/* Call the breakpoint handler. */
+		if (breakpoints[handle.bp].handler) {
+			int ret = breakpoints[handle.bp].handler(handle, info);
+			/* A non-zero return value indicates a fatal error. */
+			if (ret)
+				return ret;
+		}
+	}
+
+	/* Clear hit breakpoints. */
+	uintptr_t status = debug_read_status();
+	for (int i = 0; i < DEBUG_REGISTER_COUNT; i++) {
+		status &= ~DEBUG_STATUS_BP_HIT_MASK(i);
+	}
+	debug_write_status(status);
+
+	if (instr_bp_hit) {
+		/* Set the resume flag so the same breakpoint won't be hit immediately. */
+#if ENV_X86_64
+		info->rflags |= FLAGS_RESUME;
+#else
+		info->eflags |= FLAGS_RESUME;
+#endif
+	}
+
+	return 0;
+}
diff --git a/src/arch/486/c_start.S b/src/arch/486/c_start.S
new file mode 100644
index 0000000000..3409a5d17a
--- /dev/null
+++ b/src/arch/486/c_start.S
@@ -0,0 +1,246 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cpu/486/post_code.h>
+#include <arch/ram_segs.h>
+
+/* Place the stack in the bss section. It's not necessary to define it in
+ * the linker script. */
+	.section .bss, "aw", @nobits
+.global _stack
+.global _estack
+.global _stack_size
+
+.align 16
+_stack:
+.space CONFIG_STACK_SIZE
+_estack:
+.set _stack_size, _estack - _stack
+
+	.section ".text._start", "ax", @progbits
+#if ENV_X86_64
+	.code64
+#else
+	.code32
+#endif
+	.globl _start
+_start:
+	cli
+#if ENV_X86_64
+	movabs	$gdtaddr, %rax
+	lgdt	(%rax)
+#else
+	lgdt	%cs:gdtaddr
+	ljmp	$RAM_CODE_SEG, $1f
+#endif
+1:	movl	$RAM_DATA_SEG, %eax
+	movl	%eax, %ds
+	movl	%eax, %es
+	movl	%eax, %ss
+	xor	%eax, %eax /* zero out the gs and fs segment index */
+	movl	%eax, %fs
+	movl	%eax, %gs /* Will be used for cpu_info */
+#if ENV_X86_64
+	mov	$RAM_CODE_SEG64, %ecx
+	call	SetCodeSelector
+#endif
+
+	post_code(POST_ENTRY_C_START)		/* post 13 */
+
+	cld
+
+#if ENV_X86_64
+	mov	%rdi, %rax
+	movabs	%rax, _cbmem_top_ptr
+	movabs	$_stack, %rdi
+#else
+	/* The return argument is at 0(%esp), the calling argument at 4(%esp) */
+	movl	4(%esp), %eax
+	movl	%eax, _cbmem_top_ptr
+	leal	_stack, %edi
+#endif
+
+	/** poison the stack. Code should not count on the
+	 * stack being full of zeros. This stack poisoning
+	 * recently uncovered a bug in the broadcast SIPI
+	 * code.
+	 */
+	movl	$_estack, %ecx
+	subl	%edi, %ecx
+	shrl	$2, %ecx   /* it is 32 bit aligned, right? */
+	movl	$0xDEADBEEF, %eax
+	rep
+	stosl
+
+	/* Set new stack with enforced alignment. */
+	movl	$_estack, %esp
+	andl	$(0xfffffff0), %esp
+
+	/*
+	 *	Now we are finished. Memory is up, data is copied and
+	 *	bss is cleared.   Now we call the main routine and
+	 *	let it do the rest.
+	 */
+	post_code(POST_PRE_HARDWAREMAIN)	/* post 6e */
+
+	andl	$0xFFFFFFF0, %esp
+
+#if CONFIG(ASAN_IN_RAMSTAGE)
+	call asan_init
+#endif
+
+#if CONFIG(GDB_WAIT)
+	call gdb_hw_init
+	call gdb_stub_breakpoint
+#endif
+	call	main
+	/* NOTREACHED */
+.Lhlt:
+	post_code(POST_DEAD_CODE)	/* post ee */
+	hlt
+	jmp	.Lhlt
+
+#if CONFIG(GDB_WAIT)
+
+	.globl gdb_stub_breakpoint
+gdb_stub_breakpoint:
+#if ENV_X86_64
+	pop	%rax	/* Return address */
+	pushfl
+	push	%cs
+	push	%rax	/* Return address */
+	push	$0	/* No error code */
+	push	$32	/* vector 32 is user defined */
+#else
+	popl	%eax	/* Return address */
+	pushfl
+	pushl	%cs
+	pushl	%eax	/* Return address */
+	pushl	$0	/* No error code */
+	pushl	$32	/* vector 32 is user defined */
+#endif
+	jmp	int_hand
+#endif
+
+	.globl gdt, gdt_end
+	.global per_cpu_segment_descriptors, per_cpu_segment_selector
+
+gdtaddr:
+	.word	gdt_end - gdt - 1
+#if ENV_X86_64
+	.quad	gdt
+#else
+	.long	gdt		/* we know the offset */
+#endif
+
+	.data
+
+	/* This is the gdt for GCC part of coreboot.
+	 * It is different from the gdt in ASM part of coreboot
+	 * which is defined in gdt_init.S
+	 *
+	 * When the machine is initially started, we use a very simple
+	 * gdt from ROM (that in gdt_init.S) which only contains those
+	 * entries we need for protected mode.
+	 *
+	 * When we're executing code from RAM, we want to do more complex
+	 * stuff, like initializing PCI option ROMs in real mode, or doing
+	 * a resume from a suspend to RAM.
+	 */
+gdt:
+	/* selgdt 0, unused */
+	.word	0x0000, 0x0000		/* dummy */
+	.byte	0x00, 0x00, 0x00, 0x00
+
+	/* selgdt 8, unused */
+	.word	0x0000, 0x0000		/* dummy */
+	.byte	0x00, 0x00, 0x00, 0x00
+
+	/* selgdt 0x10, flat code segment */
+	.word	0xffff, 0x0000
+	.byte	0x00, 0x9b, 0xcf, 0x00 /* G=1 and 0x0f, So we get 4Gbytes for
+					* limit
+					*/
+
+	/* selgdt 0x18, flat data segment */
+	.word	0xffff, 0x0000
+#if ENV_X86_64
+	.byte	0x00, 0x92, 0xcf, 0x00
+#else
+	.byte	0x00, 0x93, 0xcf, 0x00
+#endif
+
+	/* selgdt 0x20, unused */
+	.word	0x0000, 0x0000		/* dummy */
+	.byte	0x00, 0x00, 0x00, 0x00
+
+	/* The next two entries are used for executing VGA option ROMs */
+
+	/* selgdt 0x28 16 bit 64k code at 0x00000000 */
+	.word	0xffff, 0x0000
+	.byte	0, 0x9a, 0, 0
+
+	/* selgdt 0x30 16 bit 64k data at 0x00000000 */
+	.word	0xffff, 0x0000
+	.byte	0, 0x92, 0, 0
+
+	/* The next two entries are used for ACPI S3 RESUME */
+
+	/* selgdt 0x38, flat data segment 16 bit */
+	.word	0x0000, 0x0000		/* dummy */
+	.byte	0x00, 0x93, 0x8f, 0x00 /* G=1 and 0x0f, So we get 4Gbytes for
+					* limit
+					*/
+
+	/* selgdt 0x40, flat code segment 16 bit */
+	.word	0xffff, 0x0000
+	.byte	0x00, 0x9b, 0x8f, 0x00 /* G=1 and 0x0f, So we get 4Gbytes for
+					* limit
+					*/
+
+#if ENV_X86_64
+	/* selgdt 0x48, flat x64 code segment */
+	.word	0xffff, 0x0000
+	.byte	0x00, 0x9b, 0xaf, 0x00
+#endif
+per_cpu_segment_descriptors:
+	.rept CONFIG_MAX_CPUS
+	/* flat data segment */
+	.word	0xffff, 0x0000
+#if ENV_X86_64
+	.byte	0x00, 0x92, 0xcf, 0x00
+#else
+	.byte	0x00, 0x93, 0xcf, 0x00
+#endif
+	.endr
+gdt_end:
+
+/* Segment selector pointing to the first per_cpu_segment_descriptor. */
+per_cpu_segment_selector:
+	.long	per_cpu_segment_descriptors - gdt
+
+	.section ".text._start", "ax", @progbits
+#if ENV_X86_64
+SetCodeSelector:
+	# save rsp because iret will align it to a 16 byte boundary
+	mov	%rsp, %rdx
+
+	# use iret to jump to a 64-bit offset in a new code segment
+	# iret will pop cs:rip, flags, then ss:rsp
+	mov	%ss, %ax	# need to push ss..
+	push	%rax		# push ss instruction not valid in x64 mode,
+				# so use ax
+	push	%rsp
+	pushfq
+	push	%rcx		# cx is code segment selector from caller
+	movabs	$setCodeSelectorLongJump, %rax
+	push	%rax
+
+	# the iret will continue at next instruction, with the new cs value
+	# loaded
+	iretq
+
+setCodeSelectorLongJump:
+	# restore rsp, it might not have been 16-byte aligned on entry
+	mov	%rdx, %rsp
+	ret
+#endif
diff --git a/src/arch/486/car.ld b/src/arch/486/car.ld
new file mode 100644
index 0000000000..2c686a745f
--- /dev/null
+++ b/src/arch/486/car.ld
@@ -0,0 +1,110 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+/* CACHE_ROM_SIZE defined here. */
+#include <memlayout.h>
+
+/* This file is included inside a SECTIONS block */
+. = CONFIG_DCACHE_RAM_BASE;
+.car.data . (NOLOAD) : {
+	_car_region_start = . ;
+#if CONFIG(PAGING_IN_CACHE_AS_RAM)
+	/* Page table pre-allocation. CONFIG_DCACHE_RAM_BASE should be 4KiB
+	 * aligned when using this option. */
+	REGION(pagetables, ., 4K * CONFIG_NUM_CAR_PAGE_TABLE_PAGES, 4K)
+#endif
+	/* Stack for CAR stages. Since it persists across all stages that
+	 * use CAR it can be reused. The chipset/SoC is expected to provide
+	 * the stack size. */
+	REGION(car_stack, ., CONFIG_DCACHE_BSP_STACK_SIZE, 4)
+	/* The pre-ram cbmem console as well as the timestamp region are fixed
+	 * in size. Therefore place them above the car global section so that
+	 * multiple stages (romstage and verstage) have a consistent
+	 * link address of these shared objects. */
+	PRERAM_CBMEM_CONSOLE(., CONFIG_PRERAM_CBMEM_CONSOLE_SIZE)
+#if CONFIG(PAGING_IN_CACHE_AS_RAM)
+	. = ALIGN(32);
+	/* Page directory pointer table resides here. There are 4 8-byte entries
+	 * totalling 32 bytes that need to be 32-byte aligned. The reason the
+	 * pdpt are not colocated with the rest of the page tables is to reduce
+	 * fragmentation of the CAR space that persists across stages. */
+	REGION(pdpt, ., 32, 32)
+#endif
+
+	TIMESTAMP(., 0x200)
+
+#if !CONFIG(NO_CBFS_MCACHE)
+	CBFS_MCACHE(., CONFIG_CBFS_MCACHE_SIZE)
+#endif
+/*#if !CONFIG(NO_FMAP_CACHE)
+	FMAP_CACHE(., FMAP_SIZE)
+#endif
+*/
+	/* Reserve sizeof(struct ehci_dbg_info). */
+	REGION(car_ehci_dbg_info, ., 80, 1)
+
+	/* _bss and _ebss provide symbols to per-stage
+	 * variables that are not shared like the timestamp and the pre-ram
+	 * cbmem console. This is useful for clearing this area on a per-stage
+	 * basis when more than one stage uses cache-as-ram. */
+
+#if ENV_SEPARATE_BSS
+	. = ALIGN(ARCH_POINTER_ALIGN_SIZE);
+	_bss = .;
+	/* Allow global uninitialized variables for stages without CAR teardown. */
+	*(.bss)
+	*(.bss.*)
+	*(.sbss)
+	*(.sbss.*)
+	/* '*_E' GNAT generated global variables actually are un-initialized
+	 * (filled with zeros) variables which are initialized at
+	 * runtime. Therefore, they can be placed in the _bss region. */
+#if CONFIG(ROMSTAGE_LIBHWBASE)
+	*(.data.hw__*_E)
+#endif
+#if CONFIG(EARLY_GFX_GMA)
+	*(.data.gma*_E)
+	/* libgfxinit uses a boolean variable to track its initialization
+	 * state. Since the initial value is False it can safely be placed in
+	 * the _bss region. */
+	*(.data.hw__gfx__gma__initialized)
+#endif
+	. = ALIGN(ARCH_POINTER_ALIGN_SIZE);
+	_ebss = .;
+	RECORD_SIZE(bss)
+#endif
+
+#if ENV_ROMSTAGE && CONFIG(ASAN_IN_ROMSTAGE)
+	_shadow_size = (_ebss - _car_region_start) >> 3;
+	REGION(asan_shadow, ., _shadow_size, ARCH_POINTER_ALIGN_SIZE)
+#endif
+	_car_unallocated_start = .;
+	_car_region_end = . + CONFIG_DCACHE_RAM_SIZE - (. - _car_region_start);
+}
+
+
+
+/* Global variables are not allowed in romstage
+ * This section is checked during stage creation to ensure
+ * that there are no global variables present
+ */
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+. = 0x000fff00;
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+. = 0xffffff00;
+#endif
+
+.illegal_globals . : {
+	*(.data)
+	*(.data.*)
+}
+
+_bogus = ASSERT((CONFIG_DCACHE_RAM_SIZE == 0) || (SIZEOF(.car.data) <= CONFIG_DCACHE_RAM_SIZE), "Cache as RAM area is too full");
+#if CONFIG(PAGING_IN_CACHE_AS_RAM)
+_bogus2 = ASSERT(_pagetables == ALIGN(_pagetables, 4096), "_pagetables aren't 4KiB aligned");
+#endif
+_bogus3 = ASSERT(CONFIG_DCACHE_BSP_STACK_SIZE > 0x0, "BSP stack size not configured");
+#if CONFIG(NO_XIP_EARLY_STAGES) && (ENV_ROMSTAGE || ENV_VERSTAGE)
+_bogus4 = ASSERT(_eprogram <= _car_region_end, "Stage end too high !");
+/* _bogus5 = ASSERT(_program >= _car_unallocated_start, "Stage start too low!"); */
+#endif
diff --git a/src/arch/486/cf9_reset.c b/src/arch/486/cf9_reset.c
new file mode 100644
index 0000000000..a15465db8c
--- /dev/null
+++ b/src/arch/486/cf9_reset.c
@@ -0,0 +1,51 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/io.h>
+#include <arch/cache.h>
+#include <cf9_reset.h>
+#include <console/console.h>
+#include <halt.h>
+
+/*
+ * A system reset in terms of the CF9 register asserts the INIT#
+ * signal to reset the CPU along the PLTRST# signal to reset other
+ * board components. It is usually the hardest reset type that
+ * does not power cycle the board. Thus, it could be called a
+ * "warm reset".
+ */
+void do_system_reset(void)
+{
+	dcache_clean_all();
+	outb(SYS_RST, RST_CNT);
+	outb(RST_CPU | SYS_RST, RST_CNT);
+}
+
+/*
+ * A full reset in terms of the CF9 register triggers a power cycle
+ * (i.e. S0 -> S5 -> S0 transition). Thus, it could be called a
+ * "cold reset".
+ * Note: Not all x86 implementations comply with this definition,
+ *       some may require additional configuration to power cycle.
+ */
+void do_full_reset(void)
+{
+	dcache_clean_all();
+	outb(FULL_RST | SYS_RST, RST_CNT);
+	outb(FULL_RST | RST_CPU | SYS_RST, RST_CNT);
+}
+
+void system_reset(void)
+{
+	printk(BIOS_INFO, "%s() called!\n", __func__);
+	cf9_reset_prepare();
+	do_system_reset();
+	halt();
+}
+
+void full_reset(void)
+{
+	printk(BIOS_INFO, "%s() called!\n", __func__);
+	cf9_reset_prepare();
+	do_full_reset();
+	halt();
+}
diff --git a/src/arch/486/cpu.c b/src/arch/486/cpu.c
new file mode 100644
index 0000000000..1e7edde389
--- /dev/null
+++ b/src/arch/486/cpu.c
@@ -0,0 +1,337 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <bootstate.h>
+#include <boot/coreboot_tables.h>
+#include <console/console.h>
+#include <cpu/cpu.h>
+#include <post.h>
+#include <string.h>
+#include <cpu/486/gdt.h>
+#include <device/path.h>
+#include <device/device.h>
+#include <smp/spinlock.h>
+
+#if ENV_X86_32
+/* Standard macro to see if a specific flag is changeable */
+static inline int flag_is_changeable_p(uint32_t flag)
+{
+	uint32_t f1, f2;
+
+	asm(
+		"pushfl\n\t"
+		"pushfl\n\t"
+		"popl %0\n\t"
+		"movl %0,%1\n\t"
+		"xorl %2,%0\n\t"
+		"pushl %0\n\t"
+		"popfl\n\t"
+		"pushfl\n\t"
+		"popl %0\n\t"
+		"popfl\n\t"
+		: "=&r" (f1), "=&r" (f2)
+		: "ir" (flag));
+	return ((f1^f2) & flag) != 0;
+}
+
+/*
+ * Cyrix CPUs without cpuid or with cpuid not yet enabled can be detected
+ * by the fact that they preserve the flags across the division of 5/2.
+ * PII and PPro exhibit this behavior too, but they have cpuid available.
+ */
+
+/*
+ * Perform the Cyrix 5/2 test. A Cyrix won't change
+ * the flags, while other 486 chips will.
+ */
+static inline int test_cyrix_52div(void)
+{
+	unsigned int test;
+
+	__asm__ __volatile__(
+	     "sahf\n\t"		/* clear flags (%eax = 0x0005) */
+	     "div %b2\n\t"	/* divide 5 by 2 */
+	     "lahf"		/* store flags into %ah */
+	     : "=a" (test)
+	     : "0" (5), "q" (2)
+	     : "cc");
+
+	/* AH is 0x02 on Cyrix after the divide.. */
+	return (unsigned char)(test >> 8) == 0x02;
+}
+
+/*
+ *	Detect a NexGen CPU running without BIOS hypercode new enough
+ *	to have CPUID. (Thanks to Herbert Oppmann)
+ */
+
+static int deep_magic_nexgen_probe(void)
+{
+	int ret;
+
+	__asm__ __volatile__ (
+		"	movw	$0x5555, %%ax\n"
+		"	xorw	%%dx,%%dx\n"
+		"	movw	$2, %%cx\n"
+		"	divw	%%cx\n"
+		"	movl	$0, %%eax\n"
+		"	jnz	1f\n"
+		"	movl	$1, %%eax\n"
+		"1:\n"
+		: "=a" (ret) : : "cx", "dx");
+	return  ret;
+}
+#endif
+
+/* List of CPU vendor strings along with their normalized
+ * id values.
+ */
+static struct {
+	int vendor;
+	const char *name;
+} x86_vendors[] = {
+	{ X86_VENDOR_INTEL,     "GenuineIntel", },
+	{ X86_VENDOR_CYRIX,     "CyrixInstead", },
+	{ X86_VENDOR_AMD,       "AuthenticAMD", },
+	{ X86_VENDOR_UMC,       "UMC UMC UMC ", },
+	{ X86_VENDOR_NEXGEN,    "NexGenDriven", },
+	{ X86_VENDOR_CENTAUR,   "CentaurHauls", },
+	{ X86_VENDOR_RISE,      "RiseRiseRise", },
+	{ X86_VENDOR_TRANSMETA, "GenuineTMx86", },
+	{ X86_VENDOR_TRANSMETA, "TransmetaCPU", },
+	{ X86_VENDOR_NSC,       "Geode by NSC", },
+	{ X86_VENDOR_SIS,       "SiS SiS SiS ", },
+	{ X86_VENDOR_HYGON,     "HygonGenuine", },
+};
+
+static const char *const x86_vendor_name[] = {
+	[X86_VENDOR_INTEL]     = "Intel",
+	[X86_VENDOR_CYRIX]     = "Cyrix",
+	[X86_VENDOR_AMD]       = "AMD",
+	[X86_VENDOR_UMC]       = "UMC",
+	[X86_VENDOR_NEXGEN]    = "NexGen",
+	[X86_VENDOR_CENTAUR]   = "Centaur",
+	[X86_VENDOR_RISE]      = "Rise",
+	[X86_VENDOR_TRANSMETA] = "Transmeta",
+	[X86_VENDOR_NSC]       = "NSC",
+	[X86_VENDOR_SIS]       = "SiS",
+	[X86_VENDOR_HYGON]     = "Hygon",
+};
+
+static const char *cpu_vendor_name(int vendor)
+{
+	const char *name;
+	name = "<invalid CPU vendor>";
+	if ((vendor < ARRAY_SIZE(x86_vendor_name)) &&
+		(x86_vendor_name[vendor] != 0))
+		name = x86_vendor_name[vendor];
+	return name;
+}
+
+static void identify_cpu(struct device *cpu)
+{
+	char vendor_name[16];
+	int i;
+
+	vendor_name[0] = '\0'; /* Unset */
+
+#if ENV_X86_32
+	/* Find the id and vendor_name */
+	if (!cpu_have_cpuid()) {
+		/* Its a 486 if we can modify the AC flag */
+		if (flag_is_changeable_p(X86_EFLAGS_AC))
+			cpu->device = 0x00000400; /* 486 */
+		else
+			cpu->device = 0x00000300; /* 386 */
+		if ((cpu->device == 0x00000400) && test_cyrix_52div())
+			memcpy(vendor_name, "CyrixInstead", 13);
+			/* If we ever care we can enable cpuid here */
+		/* Detect NexGen with old hypercode */
+		else if (deep_magic_nexgen_probe())
+			memcpy(vendor_name, "NexGenDriven", 13);
+	}
+#endif
+	if (cpu_have_cpuid()) {
+		int  cpuid_level;
+		struct cpuid_result result;
+		result = cpuid(0x00000000);
+		cpuid_level     = result.eax;
+		vendor_name[0]  = (result.ebx >>  0) & 0xff;
+		vendor_name[1]  = (result.ebx >>  8) & 0xff;
+		vendor_name[2]  = (result.ebx >> 16) & 0xff;
+		vendor_name[3]  = (result.ebx >> 24) & 0xff;
+		vendor_name[4]  = (result.edx >>  0) & 0xff;
+		vendor_name[5]  = (result.edx >>  8) & 0xff;
+		vendor_name[6]  = (result.edx >> 16) & 0xff;
+		vendor_name[7]  = (result.edx >> 24) & 0xff;
+		vendor_name[8]  = (result.ecx >>  0) & 0xff;
+		vendor_name[9]  = (result.ecx >>  8) & 0xff;
+		vendor_name[10] = (result.ecx >> 16) & 0xff;
+		vendor_name[11] = (result.ecx >> 24) & 0xff;
+		vendor_name[12] = '\0';
+
+		/* Intel-defined flags: level 0x00000001 */
+		if (cpuid_level >= 0x00000001)
+			cpu->device = cpu_get_cpuid();
+		else
+			/* Have CPUID level 0 only unheard of */
+			cpu->device = 0x00000400;
+	}
+	cpu->vendor = X86_VENDOR_UNKNOWN;
+	for (i = 0; i < ARRAY_SIZE(x86_vendors); i++) {
+		if (memcmp(vendor_name, x86_vendors[i].name, 12) == 0) {
+			cpu->vendor = x86_vendors[i].vendor;
+			break;
+		}
+	}
+}
+
+struct cpu_driver *find_cpu_driver(struct device *cpu)
+{
+	struct cpu_driver *driver;
+	for (driver = _cpu_drivers; driver < _ecpu_drivers; driver++) {
+		const struct cpu_device_id *id;
+		for (id = driver->id_table;
+		     id->vendor != X86_VENDOR_INVALID; id++) {
+			if ((cpu->vendor == id->vendor) &&
+			    cpuid_match(cpu->device, id->device, id->device_match_mask))
+				return driver;
+			if (id->vendor == X86_VENDOR_ANY)
+				return driver;
+		}
+	}
+	return NULL;
+}
+
+static void set_cpu_ops(struct device *cpu)
+{
+	struct cpu_driver *driver = find_cpu_driver(cpu);
+
+	printk(BIOS_INFO, "DRIVER %p\n", driver);
+
+	cpu->ops = driver ? driver->ops : NULL;
+}
+
+//NOTICE this code is not called
+void cpu_initialize(void)
+{
+	/* Because we busy wait at the printk spinlock.
+	 * It is important to keep the number of printed messages
+	 * from secondary cpus to a minimum, when debugging is
+	 * disabled.
+	 */
+	struct device *cpu;
+	struct cpu_info *info;
+	struct cpuinfo_x86 c;
+
+	info = cpu_info();
+
+	printk(BIOS_INFO, "Initializing CPU #%zd\n", info->index);
+
+	cpu = info->cpu;
+	if (!cpu)
+		die("CPU: missing CPU device structure");
+
+	if (cpu->initialized)
+		return;
+
+	post_log_path(cpu);
+
+	/* Find what type of CPU we are dealing with */
+	identify_cpu(cpu);
+	printk(BIOS_DEBUG, "CPU: vendor %s device %x\n",
+		cpu_vendor_name(cpu->vendor), cpu->device);
+
+	get_fms(&c, cpu->device);
+
+	printk(BIOS_DEBUG, "CPU: family %02x, model %02x, stepping %02x\n",
+		c.x86, c.x86_model, c.x86_mask);
+
+	/* Lookup the cpu's operations */
+	set_cpu_ops(cpu);
+
+	if (!cpu->ops) {
+		/* mask out the stepping and try again */
+		cpu->device -= c.x86_mask;
+		set_cpu_ops(cpu);
+		cpu->device += c.x86_mask;
+		if (!cpu->ops)
+			die("Unknown cpu");
+		printk(BIOS_DEBUG, "Using generic CPU ops (good)\n");
+	}
+
+	/* Initialize the CPU */
+	if (cpu->ops && cpu->ops->init) {
+		cpu->enabled = 1;
+		cpu->initialized = 1;
+		cpu->ops->init(cpu);
+	}
+	post_log_clear();
+
+	printk(BIOS_INFO, "CPU #%zd initialized\n", info->index);
+}
+
+void lb_arch_add_records(struct lb_header *header)
+{
+	// uint32_t freq_khz;
+	// struct lb_tsc_info *tsc_info;
+//
+	/* Don't advertise a TSC rate unless it's constant. */
+	//vrati frekvenci cpu?
+
+	// if (!tsc_constant_rate())
+	// 	return;
+ //
+	// freq_khz = tsc_freq_mhz() * 1000;
+ //
+	// /* No use exposing a TSC frequency that is zero. */
+	// if (freq_khz == 0)
+	// 	return;
+ //
+	// tsc_info = (void *)lb_new_record(header);
+	// tsc_info->tag = LB_TAG_TSC_INFO;
+	// tsc_info->size = sizeof(*tsc_info);
+	// tsc_info->freq_khz = freq_khz;
+}
+
+void arch_bootstate_coreboot_exit(void)
+{
+	return;
+}
+
+/* cpu_info() looks at address 0 at the base of %gs for a pointer to struct cpu_info */
+static struct per_cpu_segment_data segment_data[CONFIG_MAX_CPUS];
+struct cpu_info cpu_infos[CONFIG_MAX_CPUS];
+
+enum cb_err set_cpu_info(unsigned int index, struct device *cpu)
+{
+	if (index >= ARRAY_SIZE(cpu_infos))
+		return CB_ERR;
+
+	if (!cpu)
+		return CB_ERR;
+
+	const struct cpu_info info = { .cpu = cpu, .index = index};
+	cpu_infos[index] = info;
+	segment_data[index].cpu_info = &cpu_infos[index];
+
+	struct segment_descriptor {
+		uint16_t segment_limit_0_15;
+		uint16_t base_address_0_15;
+		uint8_t base_address_16_23;
+		uint8_t attrs[2];
+		uint8_t base_address_24_31;
+	} *segment_descriptor = (void *)&per_cpu_segment_descriptors;
+
+	segment_descriptor[index].base_address_0_15 = (uintptr_t)&segment_data[index] & 0xffff;
+	segment_descriptor[index].base_address_16_23 = ((uintptr_t)&segment_data[index] >> 16) & 0xff;
+	segment_descriptor[index].base_address_24_31 = ((uintptr_t)&segment_data[index] >> 24) & 0xff;
+
+	const unsigned int cpu_segment = per_cpu_segment_selector + (index << 3);
+
+	__asm__ __volatile__ ("mov %0, %%gs\n"
+		:
+		: "r" (cpu_segment)
+		: );
+
+	return CB_SUCCESS;
+}
diff --git a/src/arch/486/cpu_common.c b/src/arch/486/cpu_common.c
new file mode 100644
index 0000000000..f6d14d0e01
--- /dev/null
+++ b/src/arch/486/cpu_common.c
@@ -0,0 +1,205 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cpu/cpu.h>
+#include <types.h>
+
+#if ENV_X86_32
+/* Standard macro to see if a specific flag is changeable */
+static inline int flag_is_changeable_p(uint32_t flag)
+{
+	uint32_t f1, f2;
+
+	asm(
+		"pushfl\n\t"
+		"pushfl\n\t"
+		"popl %0\n\t"
+		"movl %0,%1\n\t"
+		"xorl %2,%0\n\t"
+		"pushl %0\n\t"
+		"popfl\n\t"
+		"pushfl\n\t"
+		"popl %0\n\t"
+		"popfl\n\t"
+		: "=&r" (f1), "=&r" (f2)
+		: "ir" (flag));
+	return ((f1^f2) & flag) != 0;
+}
+
+/* Probe for the CPUID instruction */
+int cpu_have_cpuid(void)
+{
+	return flag_is_changeable_p(X86_EFLAGS_ID);
+}
+
+#else
+
+int cpu_have_cpuid(void)
+{
+	return 1;
+}
+#endif
+
+int cpu_phys_address_size(void)
+{
+	return 32;
+}
+
+/*
+ * Get processor id using cpuid eax=1
+ * return value in EAX register
+ */
+uint32_t cpu_get_cpuid(void)
+{
+	return cpuid_eax(1);
+}
+
+/*
+ * Get processor feature flag using cpuid eax=1
+ * return value in ECX register
+ */
+uint32_t cpu_get_feature_flags_ecx(void)
+{
+	return cpuid_ecx(1);
+}
+
+/*
+ * Get processor feature flag using cpuid eax=1
+ * return value in EDX register
+ */
+uint32_t cpu_get_feature_flags_edx(void)
+{
+	return cpuid_edx(1);
+}
+
+enum cpu_type cpu_check_deterministic_cache_cpuid_supported(void)
+{
+	if (CONFIG_CPU_486) {
+		return CPUID_TYPE_INVALID;
+	}
+
+	struct cpuid_result res;
+
+	if (cpu_is_intel()) {
+		res = cpuid(0);
+		if (res.eax < 4)
+			return CPUID_COMMAND_UNSUPPORTED;
+		return CPUID_TYPE_INTEL;
+	} else if (cpu_is_amd()) {
+		res = cpuid(0x80000000);
+		if (res.eax < 0x80000001)
+			return CPUID_COMMAND_UNSUPPORTED;
+
+		res = cpuid(0x80000001);
+		if (!(res.ecx & (1 << 22)))
+			return CPUID_COMMAND_UNSUPPORTED;
+
+		return CPUID_TYPE_AMD;
+	} else {
+		return CPUID_TYPE_INVALID;
+	}
+}
+
+static uint32_t cpu_get_cache_info_leaf(void)
+{
+	uint32_t leaf = (cpu_check_deterministic_cache_cpuid_supported() == CPUID_TYPE_AMD) ?
+				DETERMINISTIC_CACHE_PARAMETERS_CPUID_AMD :
+				DETERMINISTIC_CACHE_PARAMETERS_CPUID_IA;
+
+	return leaf;
+}
+
+size_t cpu_get_cache_ways_assoc_info(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->num_ways;
+}
+
+uint8_t cpu_get_cache_type(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->type;
+}
+
+uint8_t cpu_get_cache_level(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->level;
+}
+
+size_t cpu_get_cache_phy_partition_info(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->physical_partitions;
+}
+
+size_t cpu_get_cache_line_size(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->line_size;
+}
+
+size_t cpu_get_cache_sets(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->num_sets;
+}
+
+bool cpu_is_cache_full_assoc(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return false;
+
+	return info->fully_associative;
+}
+
+size_t cpu_get_max_cache_share(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->num_cores_shared;
+}
+
+size_t get_cache_size(const struct cpu_cache_info *info)
+{
+	if (!info)
+		return 0;
+
+	return info->num_ways * info->physical_partitions * info->line_size * info->num_sets;
+}
+
+bool fill_cpu_cache_info(uint8_t level, struct cpu_cache_info *info)
+{
+	if (!info)
+		return false;
+
+	uint32_t leaf = cpu_get_cache_info_leaf();
+	if (!leaf)
+		return false;
+
+	struct cpuid_result cache_info_res = cpuid_ext(leaf, level);
+
+	info->type = CPUID_CACHE_TYPE(cache_info_res);
+	info->level = CPUID_CACHE_LEVEL(cache_info_res);
+	info->num_ways = CPUID_CACHE_WAYS_OF_ASSOC(cache_info_res) + 1;
+	info->num_sets = CPUID_CACHE_NO_OF_SETS(cache_info_res) + 1;
+	info->line_size = CPUID_CACHE_COHER_LINE(cache_info_res) + 1;
+	info->physical_partitions = CPUID_CACHE_PHYS_LINE(cache_info_res) + 1;
+	info->num_cores_shared = CPUID_CACHE_SHARING_CACHE(cache_info_res) + 1;
+	info->fully_associative = CPUID_CACHE_FULL_ASSOC(cache_info_res);
+	info->size = get_cache_size(info);
+
+	return true;
+}
diff --git a/src/arch/486/ebda.c b/src/arch/486/ebda.c
new file mode 100644
index 0000000000..e835fcefef
--- /dev/null
+++ b/src/arch/486/ebda.c
@@ -0,0 +1,64 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <acpi/acpi.h>
+#include <bootstate.h>
+#include <commonlib/endian.h>
+#include <types.h>
+
+#define X86_BDA_SIZE		0x200
+#define X86_BDA_BASE		((void *)0x400)
+#define X86_EBDA_SEGMENT	((void *)0x40e)
+#define X86_EBDA_LOWMEM		((void *)0x413)
+
+#define DEFAULT_EBDA_LOWMEM	(1024 << 10)
+#define DEFAULT_EBDA_SEGMENT	0xF600
+#define DEFAULT_EBDA_SIZE	0x400
+
+
+static void *get_ebda_start(void)
+{
+	return (void *)((uintptr_t)DEFAULT_EBDA_SEGMENT << 4);
+}
+
+/*
+ * EBDA area is representing a 1KB memory area just below
+ * the top of conventional memory (below 1MB)
+ */
+
+static void setup_ebda(u32 low_memory_size, u16 ebda_segment, u16 ebda_size)
+{
+	u16 low_memory_kb;
+	u16 ebda_kb;
+	void *ebda;
+
+	if (!low_memory_size || !ebda_segment || !ebda_size)
+		return;
+
+	low_memory_kb = low_memory_size >> 10;
+	ebda_kb = ebda_size >> 10;
+	ebda = get_ebda_start();
+
+	/* clear BIOS DATA AREA */
+	zero_n(X86_BDA_BASE, X86_BDA_SIZE);
+
+	/* Avoid unaligned write16() since it's undefined behavior */
+	write_le16(X86_EBDA_LOWMEM, low_memory_kb);
+	write_le16(X86_EBDA_SEGMENT, ebda_segment);
+
+	/* Set up EBDA */
+	zero_n(ebda, ebda_size);
+	write_le16(ebda, ebda_kb);
+}
+
+static void setup_default_ebda(void *unused)
+{
+	if (acpi_is_wakeup_s3())
+		return;
+
+	setup_ebda(DEFAULT_EBDA_LOWMEM,
+		   DEFAULT_EBDA_SEGMENT,
+		   DEFAULT_EBDA_SIZE);
+}
+
+/* Ensure EBDA is prepared before Option ROMs. */
+BOOT_STATE_INIT_ENTRY(BS_DEV_INIT, BS_ON_ENTRY, setup_default_ebda, NULL);
diff --git a/src/arch/486/exception.c b/src/arch/486/exception.c
new file mode 100644
index 0000000000..07b3a870c7
--- /dev/null
+++ b/src/arch/486/exception.c
@@ -0,0 +1,660 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+#include <arch/cpu.h>
+#include <arch/breakpoint.h>
+#include <arch/null_breakpoint.h>
+#include <arch/exception.h>
+#include <arch/registers.h>
+#include <commonlib/helpers.h>
+#include <console/console.h>
+#include <console/streams.h>
+#include <cpu/486/cr.h>
+#include <stdint.h>
+#include <string.h>
+
+#if CONFIG(GDB_STUB)
+
+/* BUFMAX defines the maximum number of characters in inbound/outbound buffers.
+ * At least NUM_REGBYTES*2 are needed for register packets
+ */
+#define BUFMAX 400
+enum regnames {
+	EAX = 0, ECX, EDX, EBX, ESP, EBP, ESI, EDI,
+	PC /* also known as eip */,
+	PS /* also known as eflags */,
+	CS, SS, DS, ES, FS, GS,
+	NUM_REGS /* Number of registers. */
+};
+
+static uint32_t gdb_stub_registers[NUM_REGS];
+
+#define GDB_SIG0	 0     /* Signal 0 */
+#define GDB_SIGHUP       1     /* Hangup */
+#define GDB_SIGINT       2     /* Interrupt */
+#define GDB_SIGQUIT      3     /* Quit */
+#define GDB_SIGILL       4     /* Illegal instruction */
+#define GDB_SIGTRAP      5     /* Trace/breakpoint trap */
+#define GDB_SIGABRT      6     /* Aborted */
+#define GDB_SIGEMT       7     /* Emulation trap */
+#define GDB_SIGFPE       8     /* Arithmetic exception */
+#define GDB_SIGKILL      9     /* Killed */
+#define GDB_SIGBUS       10    /* Bus error */
+#define GDB_SIGSEGV      11    /* Segmentation fault */
+#define GDB_SIGSYS       12    /* Bad system call */
+#define GDB_SIGPIPE      13    /* Broken pipe */
+#define GDB_SIGALRM      14    /* Alarm clock */
+#define GDB_SIGTERM      15    /* Terminated */
+#define GDB_SIGURG       16    /* Urgent I/O condition */
+#define GDB_SIGSTOP      17    /* Stopped (signal) */
+#define GDB_SIGTSTP      18    /* Stopped (user) */
+#define GDB_SIGCONT      19    /* Continued */
+#define GDB_SIGCHLD      20    /* Child status changed */
+#define GDB_SIGTTIN      21    /* Stopped (tty input) */
+#define GDB_SIGTTOU      22    /* Stopped (tty output) */
+#define GDB_SIGIO	23    /* I/O possible */
+#define GDB_SIGXCPU      24    /* CPU time limit exceeded */
+#define GDB_SIGXFSZ      25    /* File size limit exceeded */
+#define GDB_SIGVTALRM    26    /* Virtual timer expired */
+#define GDB_SIGPROF      27    /* Profiling timer expired */
+#define GDB_SIGWINCH     28    /* Window size changed */
+#define GDB_SIGLOST      29    /* Resource lost */
+#define GDB_SIGUSR1      30    /* User defined signal 1 */
+#define GDB_SUGUSR2      31    /* User defined signal 2 */
+#define GDB_SIGPWR       32    /* Power fail/restart */
+#define GDB_SIGPOLL      33    /* Pollable event occurred */
+#define GDB_SIGWIND      34    /* SIGWIND */
+#define GDB_SIGPHONE     35    /* SIGPHONE */
+#define GDB_SIGWAITING   36    /* Process's LWPs are blocked */
+#define GDB_SIGLWP       37    /* Signal LWP */
+#define GDB_SIGDANGER    38    /* Swap space dangerously low */
+#define GDB_SIGGRANT     39    /* Monitor mode granted */
+#define GDB_SIGRETRACT   40    /* Need to relinquish monitor mode */
+#define GDB_SIGMSG       41    /* Monitor mode data available */
+#define GDB_SIGSOUND     42    /* Sound completed */
+#define GDB_SIGSAK       43    /* Secure attention */
+#define GDB_SIGPRIO      44    /* SIGPRIO */
+
+#define GDB_SIG33	45    /* Real-time event 33 */
+#define GDB_SIG34	46    /* Real-time event 34 */
+#define GDB_SIG35	47    /* Real-time event 35 */
+#define GDB_SIG36	48    /* Real-time event 36 */
+#define GDB_SIG37	49    /* Real-time event 37 */
+#define GDB_SIG38	50    /* Real-time event 38 */
+#define GDB_SIG39	51    /* Real-time event 39 */
+#define GDB_SIG40	52    /* Real-time event 40 */
+#define GDB_SIG41	53    /* Real-time event 41 */
+#define GDB_SIG42	54    /* Real-time event 42 */
+#define GDB_SIG43	55    /* Real-time event 43 */
+#define GDB_SIG44	56    /* Real-time event 44 */
+#define GDB_SIG45	57    /* Real-time event 45 */
+#define GDB_SIG46	58    /* Real-time event 46 */
+#define GDB_SIG47	59    /* Real-time event 47 */
+#define GDB_SIG48	60    /* Real-time event 48 */
+#define GDB_SIG49	61    /* Real-time event 49 */
+#define GDB_SIG50	62    /* Real-time event 50 */
+#define GDB_SIG51	63    /* Real-time event 51 */
+#define GDB_SIG52	64    /* Real-time event 52 */
+#define GDB_SIG53	65    /* Real-time event 53 */
+#define GDB_SIG54	66    /* Real-time event 54 */
+#define GDB_SIG55	67    /* Real-time event 55 */
+#define GDB_SIG56	68    /* Real-time event 56 */
+#define GDB_SIG57	69    /* Real-time event 57 */
+#define GDB_SIG58	70    /* Real-time event 58 */
+#define GDB_SIG59	71    /* Real-time event 59 */
+#define GDB_SIG60	72    /* Real-time event 60 */
+#define GDB_SIG61	73    /* Real-time event 61 */
+#define GDB_SIG62	74    /* Real-time event 62 */
+#define GDB_SIG63	75    /* Real-time event 63 */
+#define GDB_SIGCANCEL    76    /* LWP internal signal */
+#define GDB_SIG32	77    /* Real-time event 32 */
+#define GDB_SIG64	78    /* Real-time event 64 */
+#define GDB_SIG65	79    /* Real-time event 65 */
+#define GDB_SIG66	80    /* Real-time event 66 */
+#define GDB_SIG67	81    /* Real-time event 67 */
+#define GDB_SIG68	82    /* Real-time event 68 */
+#define GDB_SIG69	83    /* Real-time event 69 */
+#define GDB_SIG70	84    /* Real-time event 70 */
+#define GDB_SIG71	85    /* Real-time event 71 */
+#define GDB_SIG72	86    /* Real-time event 72 */
+#define GDB_SIG73	87    /* Real-time event 73 */
+#define GDB_SIG74	88    /* Real-time event 74 */
+#define GDB_SIG75	89    /* Real-time event 75 */
+#define GDB_SIG76	90    /* Real-time event 76 */
+#define GDB_SIG77	91    /* Real-time event 77 */
+#define GDB_SIG78	92    /* Real-time event 78 */
+#define GDB_SIG79	93    /* Real-time event 79 */
+#define GDB_SIG80	94    /* Real-time event 80 */
+#define GDB_SIG81	95    /* Real-time event 81 */
+#define GDB_SIG82	96    /* Real-time event 82 */
+#define GDB_SIG83	97    /* Real-time event 83 */
+#define GDB_SIG84	98    /* Real-time event 84 */
+#define GDB_SIG85	99    /* Real-time event 85 */
+#define GDB_SIG86       100    /* Real-time event 86 */
+#define GDB_SIG87       101    /* Real-time event 87 */
+#define GDB_SIG88       102    /* Real-time event 88 */
+#define GDB_SIG89       103    /* Real-time event 89 */
+#define GDB_SIG90       104    /* Real-time event 90 */
+#define GDB_SIG91       105    /* Real-time event 91 */
+#define GDB_SIG92       106    /* Real-time event 92 */
+#define GDB_SIG93       107    /* Real-time event 93 */
+#define GDB_SIG94       108    /* Real-time event 94 */
+#define GDB_SIG95       109    /* Real-time event 95 */
+#define GDB_SIG96       110    /* Real-time event 96 */
+#define GDB_SIG97       111    /* Real-time event 97 */
+#define GDB_SIG98       112    /* Real-time event 98 */
+#define GDB_SIG99       113    /* Real-time event 99 */
+#define GDB_SIG100      114    /* Real-time event 100 */
+#define GDB_SIG101      115    /* Real-time event 101 */
+#define GDB_SIG102      116    /* Real-time event 102 */
+#define GDB_SIG103      117    /* Real-time event 103 */
+#define GDB_SIG104      118    /* Real-time event 104 */
+#define GDB_SIG105      119    /* Real-time event 105 */
+#define GDB_SIG106      120    /* Real-time event 106 */
+#define GDB_SIG107      121    /* Real-time event 107 */
+#define GDB_SIG108      122    /* Real-time event 108 */
+#define GDB_SIG109      123    /* Real-time event 109 */
+#define GDB_SIG110      124    /* Real-time event 110 */
+#define GDB_SIG111      125    /* Real-time event 111 */
+#define GDB_SIG112      126    /* Real-time event 112 */
+#define GDB_SIG113      127    /* Real-time event 113 */
+#define GDB_SIG114      128    /* Real-time event 114 */
+#define GDB_SIG115      129    /* Real-time event 115 */
+#define GDB_SIG116      130    /* Real-time event 116 */
+#define GDB_SIG117      131    /* Real-time event 117 */
+#define GDB_SIG118      132    /* Real-time event 118 */
+#define GDB_SIG119      133    /* Real-time event 119 */
+#define GDB_SIG120      134    /* Real-time event 120 */
+#define GDB_SIG121      135    /* Real-time event 121 */
+#define GDB_SIG122      136    /* Real-time event 122 */
+#define GDB_SIG123      137    /* Real-time event 123 */
+#define GDB_SIG124      138    /* Real-time event 124 */
+#define GDB_SIG125      139    /* Real-time event 125 */
+#define GDB_SIG126      140    /* Real-time event 126 */
+#define GDB_SIG127      141    /* Real-time event 127 */
+#define GDB_SIGINFO     142    /* Information request */
+#define GDB_UNKNOWN     143    /* Unknown signal */
+#define GDB_DEFAULT     144    /* error: default signal */
+/* Mach exceptions */
+#define GDB_EXC_BAD_ACCESS     145 /* Could not access memory */
+#define GDB_EXC_BAD_INSTRCTION 146 /* Illegal instruction/operand */
+#define GDB_EXC_ARITHMETIC     147 /* Arithmetic exception */
+#define GDB_EXC_EMULATION      148 /* Emulation instruction */
+#define GDB_EXC_SOFTWARE       149 /* Software generated exception */
+#define GDB_EXC_BREAKPOINT     150 /* Breakpoint */
+
+static unsigned char exception_to_signal[] = {
+	[0]  = GDB_SIGFPE,  /* divide by zero */
+	[1]  = GDB_SIGTRAP, /* debug exception */
+	[2]  = GDB_SIGSEGV, /* NMI Interrupt */
+	[3]  = GDB_SIGTRAP, /* Breakpoint */
+	[4]  = GDB_SIGSEGV, /* into instruction (overflow) */
+	[5]  = GDB_SIGSEGV, /* bound instruction */
+	[6]  = GDB_SIGILL,  /* Invalid opcode */
+	[7]  = GDB_SIGSEGV, /* coprocessor not available */
+	[8]  = GDB_SIGSEGV, /* double fault */
+	[9]  = GDB_SIGFPE,  /* coprocessor segment overrun */
+	[10] = GDB_SIGSEGV, /* Invalid TSS */
+	[11] = GDB_SIGBUS,  /* Segment not present */
+	[12] = GDB_SIGBUS,  /* stack exception */
+	[13] = GDB_SIGSEGV, /* general protection */
+	[14] = GDB_SIGSEGV, /* page fault */
+	[15] = GDB_UNKNOWN, /* reserved */
+	[16] = GDB_SIGEMT,  /* coprocessor error */
+	[17] = GDB_SIGBUS,  /* alignment check */
+	[18] = GDB_SIGSEGV, /* machine check */
+	[19] = GDB_SIGFPE,  /* simd floating point exception */
+	[20] = GDB_UNKNOWN,
+	[21] = GDB_UNKNOWN,
+	[22] = GDB_UNKNOWN,
+	[23] = GDB_UNKNOWN,
+	[24] = GDB_UNKNOWN,
+	[25] = GDB_UNKNOWN,
+	[26] = GDB_UNKNOWN,
+	[27] = GDB_UNKNOWN,
+	[28] = GDB_UNKNOWN,
+	[29] = GDB_UNKNOWN,
+	[30] = GDB_UNKNOWN,
+	[31] = GDB_UNKNOWN,
+	[32] = GDB_SIGINT,  /* User interrupt */
+};
+
+static const char hexchars[] = "0123456789abcdef";
+static char in_buffer[BUFMAX];
+static char out_buffer[BUFMAX];
+
+static inline void stub_putc(int ch)
+{
+	gdb_tx_byte(ch);
+}
+
+static inline void stub_flush(void)
+{
+	gdb_tx_flush();
+}
+
+static inline int stub_getc(void)
+{
+	return gdb_rx_byte();
+}
+
+static int hex(char ch)
+{
+	if ((ch >= 'a') && (ch <= 'f'))
+		return (ch - 'a' + 10);
+	if ((ch >= '0') && (ch <= '9'))
+		return (ch - '0');
+	if ((ch >= 'A') && (ch <= 'F'))
+		return (ch - 'A' + 10);
+	return (-1);
+}
+
+/*
+ * While we find hexadecimal digits, build an int.
+ * Fals is returned if nothing is parsed true otherwise.
+ */
+static int parse_ulong(char **ptr, unsigned long *value)
+{
+	int digit;
+	char *start;
+
+	start = *ptr;
+	*value = 0;
+
+	while ((digit = hex(**ptr)) >= 0) {
+		*value = ((*value) << 4) | digit;
+		(*ptr)++;
+	}
+	return start != *ptr;
+}
+
+/* convert the memory pointed to by mem into hex, placing result in buf */
+/* return a pointer to the last char put in buf (null) */
+static void copy_to_hex(char *buf, void *addr, unsigned long count)
+{
+	unsigned char ch;
+	char *mem = addr;
+
+	while (count--) {
+		ch = *mem++;
+		*buf++ = hexchars[ch >> 4];
+		*buf++ = hexchars[ch & 0x0f];
+	}
+	*buf = 0;
+}
+
+/* convert the hex array pointed to by buf into binary to be placed in mem */
+/* return a pointer to the character AFTER the last byte written */
+static void copy_from_hex(void *addr, char *buf, unsigned long count)
+{
+	unsigned char ch;
+	char *mem = addr;
+
+	while (count--) {
+		ch = hex(*buf++) << 4;
+		ch = ch + hex(*buf++);
+		*mem++ = ch;
+	}
+}
+
+/* scan for the sequence $<data>#<checksum>	*/
+
+static int get_packet(char *buffer)
+{
+	unsigned char checksum;
+	unsigned char xmitcsum;
+	int count;
+	char ch;
+
+	/* Wishlit implement a timeout in get_packet */
+	do {
+		/* wait around for the start character, ignore all other
+		 * characters
+		 */
+		while ((ch = (stub_getc() & 0x7f)) != '$')
+			;
+		checksum = 0;
+		xmitcsum = -1;
+
+		count = 0;
+
+		/* now, read until a # or end of buffer is found */
+		while (count < BUFMAX) {
+			ch = stub_getc() & 0x7f;
+			if (ch == '#')
+				break;
+			checksum = checksum + ch;
+			buffer[count] = ch;
+			count = count + 1;
+		}
+		buffer[count] = 0;
+
+		if (ch == '#') {
+			xmitcsum = hex(stub_getc() & 0x7f) << 4;
+			xmitcsum += hex(stub_getc() & 0x7f);
+
+			if (checksum != xmitcsum) {
+				stub_putc('-');	/* failed checksum */
+				stub_flush();
+			} else {
+				stub_putc('+');	/* successful transfer */
+				stub_flush();
+			}
+		}
+	} while (checksum != xmitcsum);
+	return 1;
+}
+
+/* send the packet in buffer.*/
+static void put_packet(char *buffer)
+{
+	unsigned char checksum;
+	int count;
+	char ch;
+
+	/*  $<packet info>#<checksum>. */
+	do {
+		stub_putc('$');
+		checksum = 0;
+		count = 0;
+
+		while ((ch = buffer[count])) {
+			stub_putc(ch);
+			checksum += ch;
+			count += 1;
+		}
+
+		stub_putc('#');
+		stub_putc(hexchars[checksum >> 4]);
+		stub_putc(hexchars[checksum % 16]);
+		stub_flush();
+
+	} while ((stub_getc() & 0x7f) != '+');
+
+}
+#endif /* CONFIG_GDB_STUB */
+
+#define DEBUG_VECTOR 1
+
+void x86_exception(struct eregs *info);
+
+void x86_exception(struct eregs *info)
+{
+#if CONFIG(GDB_STUB)
+	int signo;
+	memcpy(gdb_stub_registers, info, 8*sizeof(uint32_t));
+	gdb_stub_registers[PC] = info->eip;
+	gdb_stub_registers[CS] = info->cs;
+	gdb_stub_registers[PS] = info->eflags;
+	signo = GDB_UNKNOWN;
+	if (info->vector < ARRAY_SIZE(exception_to_signal))
+		signo = exception_to_signal[info->vector];
+
+	/* reply to the host that an exception has occurred */
+	out_buffer[0] = 'S';
+	out_buffer[1] = hexchars[(signo>>4) & 0xf];
+	out_buffer[2] = hexchars[signo & 0xf];
+	out_buffer[3] = '\0';
+	put_packet(out_buffer);
+
+	while (1) {
+		unsigned long addr, length;
+		char *ptr;
+		out_buffer[0] = '\0';
+		out_buffer[1] = '\0';
+		if (!get_packet(in_buffer))
+			break;
+		switch (in_buffer[0]) {
+		case '?': /* last signal */
+			out_buffer[0] = 'S';
+			out_buffer[1] = hexchars[(signo >> 4) & 0xf];
+			out_buffer[2] = hexchars[signo & 0xf];
+			out_buffer[3] = '\0';
+			break;
+		case 'g': /* return the value of the CPU registers */
+			copy_to_hex(out_buffer, &gdb_stub_registers,
+				sizeof(gdb_stub_registers));
+			break;
+		case 'G': /* set the value of the CPU registers - return OK */
+			copy_from_hex(&gdb_stub_registers, in_buffer + 1,
+				sizeof(gdb_stub_registers));
+			memcpy(info, gdb_stub_registers, 8*sizeof(uint32_t));
+			info->eip    = gdb_stub_registers[PC];
+			info->cs     = gdb_stub_registers[CS];
+			info->eflags = gdb_stub_registers[PS];
+			memcpy(out_buffer, "OK", 3);
+			break;
+		case 'm':
+			/* mAA..AA,LLLL  Read LLLL bytes at address AA..AA */
+			ptr = &in_buffer[1];
+			if (parse_ulong(&ptr, &addr) &&
+				(*ptr++ == ',') &&
+				parse_ulong(&ptr, &length)) {
+				copy_to_hex(out_buffer, (void *)addr, length);
+			} else
+				memcpy(out_buffer, "E01", 4);
+			break;
+		case 'M':
+			/* MAA..AA,LLLL: Write LLLL bytes at address AA.AA
+			 * return OK
+			 */
+			ptr = &in_buffer[1];
+			if (parse_ulong(&ptr, &addr) &&
+				(*(ptr++) == ',') &&
+				parse_ulong(&ptr, &length) &&
+				(*(ptr++) == ':')) {
+				copy_from_hex((void *)addr, ptr, length);
+				memcpy(out_buffer, "OK", 3);
+			} else
+				memcpy(out_buffer, "E02", 4);
+			break;
+		case 's':
+		case 'c':
+			/* cAA..AA    Continue at address AA..AA(optional)
+			 * sAA..AA    Step one instruction from AA..AA(optional)
+			 */
+			ptr = &in_buffer[1];
+			if (parse_ulong(&ptr, &addr))
+				info->eip = addr;
+
+			/* Clear the trace bit */
+			info->eflags &= ~(1 << 8);
+			/* Set the trace bit if we are single stepping */
+			if (in_buffer[0] == 's')
+				info->eflags |= (1 << 8);
+			return;
+		case 'D':
+			memcpy(out_buffer, "OK", 3);
+			break;
+		case 'k':  /* kill request? */
+			break;
+		case 'q':  /* query */
+			break;
+		case 'z':  /* z0AAAA,LLLL remove memory breakpoint */
+			   /* z1AAAA,LLLL remove hardware breakpoint */
+			   /* z2AAAA,LLLL remove write watchpoint */
+			   /* z3AAAA,LLLL remove read watchpoint */
+			   /* z4AAAA,LLLL remove access watchpoint */
+		case 'Z':  /* Z0AAAA,LLLL insert memory breakpoint */
+			   /* Z1AAAA,LLLL insert hardware breakpoint */
+			   /* Z2AAAA,LLLL insert write watchpoint */
+			   /* Z3AAAA,LLLL insert read watchpoint */
+			   /* Z4AAAA,LLLL insert access watchpoint */
+			break;
+		default:
+			break;
+		}
+		put_packet(out_buffer);
+	}
+#else /* !CONFIG_GDB_STUB */
+
+	if (info->vector == DEBUG_VECTOR) {
+		if (breakpoint_dispatch_handler(info) == 0)
+			return;
+	}
+
+	u8 *code;
+#if ENV_X86_64
+#define MDUMP_SIZE 0x100
+	printk(BIOS_EMERG,
+		"CPU Unexpected Exception:\n"
+		"%lld @ %02llx:%016llx - Halting\n"
+		"Code: %lld rflags: %016llx cr2: %016llx\n"
+		"rax: %016llx rbx: %016llx\n"
+		"rcx: %016llx rdx: %016llx\n"
+		"rdi: %016llx rsi: %016llx\n"
+		"rbp: %016llx rsp: %016llx\n"
+		"r08: %016llx r09: %016llx\n"
+		"r10: %016llx r11: %016llx\n"
+		"r12: %016llx r13: %016llx\n"
+		"r14: %016llx r15: %016llx\n",
+		info->vector, info->cs, info->rip,
+		info->error_code, info->rflags, read_cr2(),
+		info->rax, info->rbx, info->rcx, info->rdx,
+		info->rdi, info->rsi, info->rbp, info->rsp,
+		info->r8, info->r9, info->r10, info->r11,
+		info->r12, info->r13, info->r14, info->r15);
+	code = (u8 *)((uintptr_t)info->rip - (MDUMP_SIZE >> 2));
+#else
+#define MDUMP_SIZE 0x80
+
+	printk(BIOS_EMERG,
+		"CPU Unexpected Exception:"
+		"%d @ %02x:%08x - Halting\n"
+		"Code: %d eflags: %08x cr2: %08x\n"
+		"eax: %08x ebx: %08x ecx: %08x edx: %08x\n"
+		"edi: %08x esi: %08x ebp: %08x esp: %08x\n",
+		info->vector, info->cs, info->eip,
+		info->error_code, info->eflags, read_cr2(),
+		info->eax, info->ebx, info->ecx, info->edx,
+		info->edi, info->esi, info->ebp, info->esp);
+	code = (u8 *)((uintptr_t)info->eip - (MDUMP_SIZE >> 1));
+#endif
+	/* Align to 8-byte boundary please, and print eight bytes per row.
+	 * This is done to make DRAM burst timing/reordering errors more
+	 * evident from the looking at the dump */
+	code = (u8 *)((uintptr_t)code & ~0x7);
+	int i;
+	for (i = 0; i < MDUMP_SIZE; i++) {
+		if ((i & 0x07) == 0)
+			printk(BIOS_EMERG, "\n%p:\t", code + i);
+		printk(BIOS_EMERG, "%.2x ", code[i]);
+	}
+
+	/* Align to 4-byte boundary and up the stack. */
+	u32 *ptr = (u32 *)(ALIGN_DOWN((uintptr_t)info->esp, sizeof(u32)) + MDUMP_SIZE - 4);
+	for (i = 0; i < MDUMP_SIZE / sizeof(u32); ++i, --ptr) {
+		printk(BIOS_EMERG, "\n%p:\t0x%08x", ptr, *ptr);
+		if ((uintptr_t)ptr == info->ebp)
+			printk(BIOS_EMERG, " <-ebp");
+		else if ((uintptr_t)ptr == info->esp)
+			printk(BIOS_EMERG, " <-esp");
+	}
+
+	die("\n");
+#endif
+}
+
+#define GATE_P		(1 << 15)
+#define GATE_DPL(x)	(((x) & 0x3) << 13)
+#define GATE_SIZE_16	(0 << 11)
+#define GATE_SIZE_32	(1 << 11)
+
+#define IGATE_FLAGS (GATE_P | GATE_DPL(0) | GATE_SIZE_32 | (0x6 << 8))
+
+struct intr_gate {
+	uint16_t offset_0;
+	uint16_t segsel;
+	uint16_t flags;
+	uint16_t offset_1;
+#if ENV_X86_64
+	uint32_t offset_2;
+	uint32_t reserved;
+#endif
+} __packed;
+
+/* Even though the vecX symbols are interrupt entry points just treat them
+   like data to more easily get the pointer values in C. Because IDT entries
+   format splits the offset field up, one can't use the linker to resolve
+   parts of a relocation on x86 ABI. An array of pointers is used to gather
+   the symbols. The IDT is initialized at runtime when exception_init() is
+   called. */
+extern u8 vec0[], vec1[], vec2[], vec3[], vec4[], vec5[], vec6[], vec7[];
+extern u8 vec8[], vec9[], vec10[], vec11[], vec12[], vec13[], vec14[], vec15[];
+extern u8 vec16[], vec17[], vec18[], vec19[];
+
+static const uintptr_t intr_entries[] = {
+	(uintptr_t)vec0, (uintptr_t)vec1, (uintptr_t)vec2, (uintptr_t)vec3,
+	(uintptr_t)vec4, (uintptr_t)vec5, (uintptr_t)vec6, (uintptr_t)vec7,
+	(uintptr_t)vec8, (uintptr_t)vec9, (uintptr_t)vec10, (uintptr_t)vec11,
+	(uintptr_t)vec12, (uintptr_t)vec13, (uintptr_t)vec14, (uintptr_t)vec15,
+	(uintptr_t)vec16, (uintptr_t)vec17, (uintptr_t)vec18, (uintptr_t)vec19,
+};
+
+static struct intr_gate idt[ARRAY_SIZE(intr_entries)] __aligned(8);
+
+static inline uint16_t get_cs(void)
+{
+	uint16_t segment;
+
+	asm volatile (
+		"mov	%%cs, %0\n"
+		: "=r" (segment)
+		:
+		: "memory"
+	);
+
+	return segment;
+}
+
+struct lidtarg {
+	uint16_t limit;
+#if ENV_X86_32
+	uint32_t base;
+#else
+	uint64_t base;
+#endif
+} __packed;
+
+/* This global is for src/cpu/x86/lapic/secondary.S usage which is only
+   used during ramstage. */
+struct lidtarg idtarg;
+
+static void load_idt(void *table, size_t sz)
+{
+	struct lidtarg lidtarg = {
+		.limit = sz - 1,
+		.base = (uintptr_t)table,
+	};
+
+	asm volatile (
+		"lidt	%0"
+		:
+		: "m" (lidtarg)
+		: "memory"
+	);
+
+	if (ENV_RAMSTAGE)
+		memcpy(&idtarg, &lidtarg, sizeof(idtarg));
+}
+
+asmlinkage void exception_init(void)
+{
+	int i;
+	uint16_t segment;
+
+	segment = get_cs();
+
+	/* Initialize IDT. */
+	for (i = 0; i < ARRAY_SIZE(idt); i++) {
+		idt[i].offset_0 = intr_entries[i];
+		idt[i].segsel = segment;
+		idt[i].flags = IGATE_FLAGS;
+		idt[i].offset_1 = intr_entries[i] >> 16;
+#if ENV_X86_64
+		idt[i].offset_2 = intr_entries[i] >> 32;
+#endif
+	}
+
+	load_idt(idt, sizeof(idt));
+
+	null_breakpoint_init();
+}
diff --git a/src/arch/486/exit_car.S b/src/arch/486/exit_car.S
new file mode 100644
index 0000000000..7874c1321f
--- /dev/null
+++ b/src/arch/486/exit_car.S
@@ -0,0 +1,437 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+//TODO remove 686 and x86-64 code
+
+
+#include <cpu/486/cr.h>
+#include <cpu/486/cache.h>
+
+
+#define UMC_PCI_BDFR(BUS, DEV, FN, REG) ( \
+	(1 << 31) | \
+	(((BUS) & 0xff) << 16) | \
+	(((DEV) & 0x1f) << 11) | \
+	(((FN)  & 0x07) << 8) | \
+	(((REG)  & 0xff) << 0) \
+)
+
+
+#define send_uart		\
+	movw	$0x3f8, %dx;	\
+	outb	%al, %dx;	\
+1:	movw	$0x3fd, %dx;	\
+	inb	%dx, %al;	\
+	testb	$0x20, %al;	\
+	jz	1b
+
+
+#define pci_write(BDFR, REG_IMM)	\
+	movw	$0xcf8, %dx;	\
+	movl	$ BDFR, %eax;	\
+	outl	%eax, %dx;	\
+	movw	$0xcfc, %dx;	\
+	and	$0x3, %al;	\
+	add	%al, %dl;	\
+	movb	REG_IMM, %al;	\
+	outb	%al, %dx
+
+//value returned in AL
+#define pci_read(BDFR)		\
+	movw	$0xcf8, %dx;	\
+	movl	$ BDFR, %eax;	\
+	outl	%eax, %dx;	\
+	movw	$0xcfc, %dx;	\
+	and	$0x3, %al;	\
+	add	%al, %dl;	\
+	inb	%dx, %al
+
+
+
+
+/* Place the stack in the bss section. It's not necessary to define it in
+ * the linker script. */
+	.section .bss, "aw", @nobits
+.global _stack
+.global _estack
+.global _stack_size
+
+_stack:
+.space CONFIG_STACK_SIZE
+_estack:
+.set _stack_size, _estack - _stack
+
+.text
+.global _start
+_start:
+	/* Assume stack alignment doesn't matter here as chipset_teardown_car
+	   is expected to be implemented in assembly. */
+
+	/* Migrate GDT to this text segment */
+#if ENV_X86_64
+	call	gdt_init64
+#else
+	call	gdt_init
+#endif
+
+	mov	$'{', %al
+	send_uart
+	mov	$0xd, %al
+	send_uart
+	mov	$'{', %al
+	send_uart
+	mov	$0xd, %al
+	send_uart
+	mov	$'{', %al
+	send_uart
+	mov	$0xd, %al
+	send_uart
+
+#if ENV_X86_64
+	mov	%rdi, %rax
+	movabs %rax, _cbmem_top_ptr
+#else
+	/* The return argument is at 0(%esp), the calling argument at 4(%esp) */
+	movl	4(%esp), %eax
+	movl	%eax, _cbmem_top_ptr
+#endif
+
+
+#if 1
+	call	1f
+1:
+	pop	%eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+
+
+	# # 01000000 = _cbmem_top_ptr
+	# send_uart
+	# shr	$0x8, %eax
+	# send_uart
+	# shr	$0x8, %eax
+	# send_uart
+	# shr	$0x8, %eax
+	# send_uart
+ #
+ #
+	# mov	$0xd, %al	//pc2005
+	# send_uart
+
+	# 04560f7c
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+	# [esp] = 000e05dc
+	mov	(%esp), %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+
+	# 01000000
+	mov	_cbmem_top_ptr, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+#endif
+
+#if 0	//no cflush on 486 // TODO macro?
+	/* Make sure _cbmem_top_ptr hits dram before invd */
+	movl	$1, %eax
+	cpuid
+	btl	$CPUID_FEATURE_CLFLUSH_BIT, %edx
+	jnc	skip_clflush
+#if ENV_X86_64
+	movabs	$_cbmem_top_ptr, %rax
+	clflush	(%rax)
+#else
+	clflush	_cbmem_top_ptr
+#endif
+#endif
+
+	# //page 135 137 83
+
+
+	# movl	$0x3, %eax
+	# movl	%eax, %tr5
+
+
+#if 1
+	# CR0 val = 60000011 cd+nw
+	movl	%cr0, %eax
+
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+	mov	%cr0, %eax
+	andl	$(~(CR0_CD | CR0_NW)), %eax
+
+
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+#endif
+
+
+skip_clflush:
+	/* chipset_teardown_car() is expected to disable cache-as-ram. */
+	# call	chipset_teardown_car
+
+	# wbinvd	//pc2005
+
+	# invd
+
+	mov	$0x33, %al	//pc2005
+	send_uart
+	mov	$0x34, %al	//pc2005
+	send_uart
+	mov	$0x35, %al	//pc2005
+	send_uart
+	mov	$0x36, %al	//pc2005
+	send_uart
+	mov	$0x37, %al	//pc2005
+	send_uart
+
+
+	//fill L2 cache, twice as size?
+	movl	$0x200000, %edi
+	movl	$0x300000, %ecx
+	sub	%edi, %ecx
+	shr	$2, %ecx
+	cld
+
+	# rep	lodsl	/* DF=0, up */
+
+	xor	%eax, %eax
+	rep	stosl	/* DF=0, up */
+
+	invd
+
+	/* Enable caching if not already enabled. */
+#if ENV_X86_64
+	mov	%cr0, %rax
+	and     $(~(CR0_CD | CR0_NW)), %eax
+	mov	%rax, %cr0
+#else
+	mov	%cr0, %eax
+	and	$(~(CR0_CD | CR0_NW)), %eax
+	mov	%eax, %cr0
+#endif
+	/* Ensure cache is clean. */
+	# invd
+
+	# //hack puvodne invd pc2005
+	# wbinvd
+	invd
+	# invd
+
+	movl	$0x200000, %edi
+	movl	$0x400000, %ecx
+	sub	%edi, %ecx
+	shr	$2, %ecx
+	cld
+
+	rep	lodsl	/* DF=0, up */
+
+	# xor	%eax, %eax
+	# rep	stosl	/* DF=0, up */
+
+
+	# //dies here, WHY???
+
+#if 0
+	pci_read(UMC_PCI_BDFR(0, 0x10, 0, 0x5a))
+	movb	%al, %cl
+	andb	$(~0x40), %cl
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x5a), %cl)
+#endif
+
+	//TODO switch to writeback? (any time probably)
+#if 1
+	pci_read(UMC_PCI_BDFR(0, 0x10, 0, 0x50))
+	movb	%al, %cl
+	orb	$(0x40), %cl
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x50), %cl)
+#endif
+
+	mov	$'X', %al	//pc2005
+	send_uart
+	mov	$0xc, %al	//pc2005
+	send_uart
+	mov	$0xb, %al	//pc2005
+	send_uart
+	mov	$0xa, %al	//pc2005
+	send_uart
+
+#if 0
+	# //01ff21a5
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+	call	test
+test:
+	pop	%eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+
+
+	mov	$0xa, %al	//pc2005
+	send_uart
+
+
+	# 02000000
+	mov	_cbmem_top_ptr, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+	# 01ff21a5
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+#endif
+
+	//NOTICE all levels of memory should be coherent by now
+
+	movl	$_estack, %esp
+	/* Align stack to 16 bytes at call instruction. */
+	andl	$0xfffffff0, %esp
+
+	/* Call this in assembly as some platforms like to mess with the bootflow and
+	   call into main directly from chipset_teardown_car. */
+	/* call	postcar_mtrr_setup */
+
+#if 0
+	# 01ff9410
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+#endif
+
+#if 0
+	//quick search debug block
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	rdtsc
+#endif
+
+#if 0
+
+	# 01ff93d0
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+	mov	$0xa, %al	//pc2005
+	send_uart
+
+	# 01ff93d0
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+#endif
+
+	/* Call into main for postcar. */
+	call	main
+	/* Should never return. */
+1:
+	jmp	1b
diff --git a/src/arch/486/gdt_init.S b/src/arch/486/gdt_init.S
new file mode 100644
index 0000000000..456084fde7
--- /dev/null
+++ b/src/arch/486/gdt_init.S
@@ -0,0 +1,72 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+.code32
+
+.section .init, "ax", @progbits
+
+.section .init._gdt_, "ax", @progbits
+
+	.globl gdt_init
+gdt_init:
+/*
+nop
+nop
+nop
+nop
+nop
+nop
+nop
+	rdtsc
+	rdtsc
+	rdtsc
+	rdtsc
+*/
+	lgdt	%cs:gdtptr
+	ret
+
+.previous
+	.align	4
+.globl gdtptr
+gdtptr:
+	.word	gdt_end - gdt -1 /* compute the table limit */
+	.long	gdt		 /* we know the offset */
+
+#if ENV_X86_64
+.code64
+.section .init._gdt64_, "ax", @progbits
+	.globl gdt_init64
+gdt_init64:
+	movabs	$gdtptr64, %rax
+	lgdt	(%rax)
+	ret
+
+.previous
+	.align	4
+.globl gdtptr64
+gdtptr64:
+	.word	gdt_end - gdt -1 /* compute the table limit */
+	.quad	gdt		 /* we know the offset */
+#endif
+
+	.align	4
+gdt:
+	/* selgdt 0, unused */
+	.word	0x0000, 0x0000		/* dummy */
+	.byte	0x00, 0x00, 0x00, 0x00
+
+	/* selgdt 0x08, flat code segment */
+	.word	0xffff, 0x0000
+	.byte	0x00, 0x9b, 0xcf, 0x00 /* G=1 and 0x0f, So we get 4Gbytes
+					  for limit */
+
+	/* selgdt 0x10, flat data segment */
+	.word	0xffff, 0x0000
+	.byte	0x00, 0x93, 0xcf, 0x00
+
+	//TODO only 64bit??
+
+	/* selgdt 0x18, flat code segment (64-bit) */
+	.word   0xffff, 0x0000
+	.byte   0x00, 0x9b, 0xaf, 0x00
+
+gdt_end:
diff --git a/src/arch/486/id.S b/src/arch/486/id.S
new file mode 100644
index 0000000000..64f7a799b0
--- /dev/null
+++ b/src/arch/486/id.S
@@ -0,0 +1,24 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <build.h>
+
+.section ".id", "a", @progbits
+
+ver:
+	.asciz COREBOOT_VERSION
+vendor:
+	.asciz CONFIG_MAINBOARD_VENDOR
+part:
+	.asciz CONFIG_MAINBOARD_PART_NUMBER
+
+#if ENV_X86_64 || defined(__clang__)
+.long	0xffffffff - ver + 1		/* Reverse offset to the version */
+.long	0xffffffff - vendor + 1		/* Reverse offset to the vendor id */
+.long	0xffffffff - part + 1		/* Reverse offset to the part number */
+#else
+.long	- ver		/* Reverse offset to the version */
+.long	- vendor	/* Reverse offset to the vendor id */
+.long	- part		/* Reverse offset to the part number */
+#endif
+
+.long	CONFIG_ROM_SIZE /* Size of this romimage */
diff --git a/src/arch/486/idt.S b/src/arch/486/idt.S
new file mode 100644
index 0000000000..99d6e95ec5
--- /dev/null
+++ b/src/arch/486/idt.S
@@ -0,0 +1,216 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+	.section ".text._idt", "ax", @progbits
+#if ENV_X86_64
+	.code64
+#else
+	.code32
+#endif
+.global vec0, vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8, vec9
+.global vec10, vec11, vec12, vec13, vec14, vec15, vec16, vec17, vec18, vec19
+vec0:
+	push	$0 /* error code */
+	push	$0 /* vector */
+	jmp int_hand
+vec1:
+	push	$0 /* error code */
+	push	$1 /* vector */
+	jmp int_hand
+
+vec2:
+	push	$0 /* error code */
+	push	$2 /* vector */
+	jmp int_hand
+
+vec3:
+	push	$0 /* error code */
+	push	$3 /* vector */
+	jmp	int_hand
+
+vec4:
+	push	$0 /* error code */
+	push	$4 /* vector */
+	jmp	int_hand
+
+vec5:
+	push	$0 /* error code */
+	push	$5 /* vector */
+	jmp	int_hand
+
+vec6:
+	push	$0 /* error code */
+	push	$6 /* vector */
+	jmp	int_hand
+
+vec7:
+	push	$0 /* error code */
+	push	$7 /* vector */
+	jmp	int_hand
+
+vec8:
+	/* error code */
+	push	$8 /* vector */
+	jmp	int_hand
+
+vec9:
+	push	$0 /* error code */
+	push	$9 /* vector */
+	jmp int_hand
+
+vec10:
+	/* error code */
+	push	$10 /* vector */
+	jmp	int_hand
+
+vec11:
+	/* error code */
+	push	$11 /* vector */
+	jmp	int_hand
+
+vec12:
+	/* error code */
+	push	$12 /* vector */
+	jmp	int_hand
+
+vec13:
+	/* error code */
+	push	$13 /* vector */
+	jmp	int_hand
+
+vec14:
+	/* error code */
+	push	$14 /* vector */
+	jmp	int_hand
+
+vec15:
+	push	$0 /* error code */
+	push	$15 /* vector */
+	jmp	int_hand
+
+vec16:
+	push	$0 /* error code */
+	push	$16 /* vector */
+	jmp	int_hand
+
+vec17:
+	/* error code */
+	push	$17 /* vector */
+	jmp	int_hand
+
+vec18:
+	push	$0 /* error code */
+	push	$18 /* vector */
+	jmp	int_hand
+
+vec19:
+	push	$0 /* error code */
+	push	$19 /* vector */
+	jmp	int_hand
+
+.global int_hand
+int_hand:
+#if ENV_X86_64
+	/* At this point, on x86-64, on the stack there is:
+	 *  0(%rsp) vector
+	 *  8(%rsp) error code
+	 * 16(%rsp) rip
+	 * 24(%rsp) cs
+	 * 32(%rsp) rflags
+	 * 40(%rsp) rsp
+	 * 48(%rsp) ss
+	 */
+	push	%r15
+	push	%r14
+	push	%r13
+	push	%r12
+	push	%r11
+	push	%r10
+	push	%r9
+	push	%r8
+
+	push	%rdi
+	push	%rsi
+	push	%rbp
+
+	push	%rbx
+	push	%rdx
+	push	%rcx
+	push	%rax
+
+	/* Pass pointer to struct as first argument */
+	mov	%rsp, %rdi
+
+	/* Back up stack pointer */
+	mov	%rsp, %rbp
+
+	/* Align stack to 16 bytes. */
+	and	$(~0xf), %rsp
+
+	call	x86_exception
+
+	/* Restore stack pointer from backup */
+	mov	%rbp, %rsp
+
+	pop	%rax
+	pop	%rcx
+	pop	%rdx
+	pop	%rbx
+
+	pop	%rbp
+	pop	%rsi
+	pop	%rdi
+
+	pop	%r8
+	pop	%r9
+	pop	%r10
+	pop	%r11
+	pop	%r12
+	pop	%r13
+	pop	%r14
+	pop	%r15
+
+	add	$16, %rsp /* pop of the vector and error code */
+	iretq
+#else
+	/* At this point, on x86-32, on the stack there is:
+	 *  0(%esp) vector
+	 *  4(%esp) error code
+	 *  8(%esp) eip
+	 * 12(%esp) cs
+	 * 16(%esp) eflags
+	 */
+	pushl	%edi
+	pushl	%esi
+	pushl	%ebp
+
+	/* Original stack pointer */
+	leal	32(%esp), %ebp
+	pushl	%ebp
+	pushl	%ebx
+	pushl	%edx
+	pushl	%ecx
+	pushl	%eax
+
+	/* Save pointer to eregs structure */
+	movl	%esp, %ebp
+	/* Align stack to 16 bytes. */
+	andl	$0xfffffff0, %esp
+	/* Save original stack pointer while keeping stack alignment. This
+	   value is also the eregs argument x86_exception(). */
+	sub	$12, %esp
+	pushl	%ebp	/* Pointer to structure on the stack */
+	call	x86_exception
+	pop	%esp	/* Unwind the stack alignment and argument passing. */
+
+	popl	%eax
+	popl	%ecx
+	popl	%edx
+	popl	%ebx
+	popl	%ebp	/* Ignore saved %esp value */
+	popl	%ebp
+	popl	%esi
+	popl	%edi
+
+	addl	$8, %esp /* pop of the vector and error code */
+	iret
+#endif
diff --git a/src/arch/486/include/arch/bert_storage.h b/src/arch/486/include/arch/bert_storage.h
new file mode 100644
index 0000000000..9ed383a880
--- /dev/null
+++ b/src/arch/486/include/arch/bert_storage.h
@@ -0,0 +1,137 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef _BERT_STORAGE_H_
+#define _BERT_STORAGE_H_
+
+#include <acpi/acpi.h>
+#include <types.h>
+
+/* Items in the BERT region
+ *
+ *  * Each item begins with a Generic Error Status Block
+ *  * Zero or more Generic Error Data Entries follow, and
+ *    are associated with the Status Block
+ *  * Each Generic Error Data Entry must be a certain type,
+ *    as defined in the UEFI CPER appendix
+ *  * Each type may allow zero or more additional sets of
+ *    data, e.g. error descriptions, or processor contexts.
+ *
+ * In the example layout below, there are three BERT region
+ * entries.  The first two are a single error.  The third
+ * has two errors, with one providing a variable amount
+ * of additional information.
+ *
+ * +====================================================================+
+ * | Generic Error  | Generic Error   | Platform Memory Error	   |
+ * | Status	 | Data Entry      |				 |
+ * |====================================================================|
+ * | Generic Error  | Generic Error   | Generic Processor Error	 |
+ * | Status	 | Data Entry      |				 |
+ * |====================================================================|
+ * | Generic Error  | Generic Error   | IA32/X64 Processor Error	|
+ * | Status	 | Data Entry      |    +----------------------------+
+ * |		|		 |    | Error Check Data	   |
+ * |		|		 |    +----------------------------+
+ * |		|		 |    | MSR Context		|
+ * |		|		 |    +----------------------------+
+ * |		|		 |    | X64 Registers Context      |
+ * |		+-----------------+----+----------------------------+
+ * |		| Generic Error   | PCI Express Error	       |
+ * |		| Data Entry      |				 |
+ * +--------------------------------------------------------------------+
+ */
+
+#define CRASHLOG_RECORD_TYPE	0x2
+#define CRASHLOG_FW_ERR_REV	0x2
+
+/* Get the region where BERT error structures have been constructed for
+ * generating the ACPI table
+ */
+void bert_errors_region(void **start, size_t *size);
+
+/* Get amount of available storage left for error info */
+size_t bert_storage_remaining(void);
+/* Find if errors were added, a BERT region is present, and ACPI table needed */
+bool bert_errors_present(void);
+/* The BERT table should only be generated when BERT support is enabled and there's an error */
+static inline bool bert_should_generate_acpi_table(void)
+{
+	return CONFIG(ACPI_BERT) && bert_errors_present();
+}
+
+/* Get the number of entries associated with status */
+static inline size_t bert_entry_count(acpi_generic_error_status_t *status)
+{
+	return (status->block_status & GENERIC_ERR_STS_ENTRY_COUNT_MASK)
+				>> GENERIC_ERR_STS_ENTRY_COUNT_SHIFT;
+}
+
+/* Increment the number of entries this status describes */
+static inline void bert_bump_entry_count(acpi_generic_error_status_t *status)
+{
+	int count;
+
+	count = bert_entry_count(status) + 1;
+	status->block_status &= ~GENERIC_ERR_STS_ENTRY_COUNT_MASK;
+	status->block_status |= count << GENERIC_ERR_STS_ENTRY_COUNT_SHIFT;
+}
+
+/* Find the address of the first Generic Data structure from its status entry */
+static inline acpi_hest_generic_data_v300_t *acpi_hest_generic_data3(
+		acpi_generic_error_status_t *status)
+{
+	return (acpi_hest_generic_data_v300_t *)
+			((u8 *)status + sizeof(*status));
+}
+
+/* Find the address of a Generic Data structure's CPER error record section */
+#define section_of_acpientry(A, B) ((typeof(A))((u8 *)(B) + sizeof(*(B))))
+
+/* Add a context to an existing IA32/X64-type error entry */
+cper_ia32x64_context_t *new_cper_ia32x64_ctx(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err, int type, int num);
+
+/* Helper to add an MSR context to an existing IA32/X64-type error entry */
+cper_ia32x64_context_t *cper_new_ia32x64_context_msr(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err, u32 addr, int num);
+
+/* Add check info to an existing IA32/X64-type error entry */
+cper_ia32x64_proc_error_info_t *new_cper_ia32x64_check(
+		acpi_generic_error_status_t *status,
+		cper_ia32x64_proc_error_section_t *x86err,
+		enum cper_x86_check_type type);
+
+/* Append a new ACPI Generic Error Data Entry plus CPER Error Section to an
+ * existing ACPI Generic Error Status Block.  The caller is responsible for
+ * the setting the status and entry severity, as well as populating all fields
+ * of the error section.
+ */
+acpi_hest_generic_data_v300_t *bert_append_error_datasection(
+		acpi_generic_error_status_t *status, guid_t *guid);
+
+/* Helper to append an ACPI Generic Error Data Entry plus a CPER Processor
+ * Generic Error Section.  As many fields are populated as possible for the
+ * caller.
+ */
+acpi_hest_generic_data_v300_t *bert_append_genproc(
+					acpi_generic_error_status_t *status);
+
+/* Helper to append an ACPI Generic Error Data Entry plus a CPER IA32/X64
+ * Processor Error Section.  As many fields are populated as possible for the
+ * caller.
+ */
+acpi_hest_generic_data_v300_t *bert_append_ia32x64(
+					acpi_generic_error_status_t *status);
+
+void *new_cper_fw_error_crashlog(acpi_generic_error_status_t *status, size_t cl_size);
+acpi_hest_generic_data_v300_t *bert_append_fw_err(acpi_generic_error_status_t *status);
+
+/* Add a new event to the BERT region.  An event consists of an ACPI Error
+ * Status Block, a Generic Error Data Entry, and an associated CPER Error
+ * Section.
+ */
+acpi_generic_error_status_t *bert_new_event(guid_t *guid);
+
+#endif /* _BERT_STORAGE_H_ */
diff --git a/src/arch/486/include/arch/boot/boot.h b/src/arch/486/include/arch/boot/boot.h
new file mode 100644
index 0000000000..e719d20aa5
--- /dev/null
+++ b/src/arch/486/include/arch/boot/boot.h
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef X86_BOOT_H
+#define X86_BOOT_H
+
+#include <types.h>
+/*
+ * Jump to function in protected mode.
+ * @arg func_ptr           Function to jump to in protected mode
+ * @arg                    Argument to pass to called function
+ *
+ * @noreturn
+ */
+void protected_mode_jump(uint32_t func_ptr, uint32_t argument);
+
+#endif /* X86_BOOT_H */
diff --git a/src/arch/486/include/arch/bootblock.h b/src/arch/486/include/arch/bootblock.h
new file mode 100644
index 0000000000..0019e5fab2
--- /dev/null
+++ b/src/arch/486/include/arch/bootblock.h
@@ -0,0 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_BOOTBLOCK_H__
+#define __ARCH_BOOTBLOCK_H__
+
+void bootblock_early_cpu_init(void);
+void bootblock_early_northbridge_init(void);
+void bootblock_early_southbridge_init(void);
+
+#endif
diff --git a/src/arch/486/include/arch/breakpoint.h b/src/arch/486/include/arch/breakpoint.h
new file mode 100644
index 0000000000..32e9f48d09
--- /dev/null
+++ b/src/arch/486/include/arch/breakpoint.h
@@ -0,0 +1,58 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+#ifndef _BREAKPOINT_H_
+#define _BREAKPOINT_H_
+
+#include <arch/registers.h>
+#include <types.h>
+
+#if CONFIG(DEBUG_HW_BREAKPOINTS) && \
+	(CONFIG(DEBUG_HW_BREAKPOINTS_IN_ALL_STAGES) || ENV_RAMSTAGE)
+struct breakpoint_handle {
+	int bp;
+};
+
+typedef int (*breakpoint_handler)(struct breakpoint_handle, struct eregs *info);
+
+enum breakpoint_result {
+	BREAKPOINT_RES_OK = 0,
+	BREAKPOINT_RES_NONE_AVAILABLE = -1,
+	BREAKPOINT_RES_INVALID_HANDLE = -2,
+	BREAKPOINT_RES_INVALID_LENGTH = -3
+};
+
+enum breakpoint_type {
+	BREAKPOINT_TYPE_INSTRUCTION = 0x0,
+	BREAKPOINT_TYPE_DATA_WRITE = 0x1,
+	BREAKPOINT_TYPE_IO = 0x2,
+	BREAKPOINT_TYPE_DATA_RW = 0x3,
+};
+
+/* Creates an instruction breakpoint at the given address. */
+enum breakpoint_result breakpoint_create_instruction(struct breakpoint_handle *out_handle,
+						     void *virt_addr);
+/* Creates a data breakpoint at the given address for len bytes. */
+enum breakpoint_result breakpoint_create_data(struct breakpoint_handle *out_handle,
+					      void *virt_addr, size_t len, bool write_only);
+/* Removes a given breakpoint. */
+enum breakpoint_result breakpoint_remove(struct breakpoint_handle handle);
+/* Enables or disables a given breakpoint. */
+enum breakpoint_result breakpoint_enable(struct breakpoint_handle handle, bool enabled);
+/* Returns the type of a breakpoint. */
+enum breakpoint_result breakpoint_get_type(struct breakpoint_handle handle,
+					   enum breakpoint_type *type);
+/*
+ * Sets a handler function to be called when the breakpoint is hit. The handler should return 0
+ * to continue or any other value to halt execution as a fatal error.
+ */
+enum breakpoint_result breakpoint_set_handler(struct breakpoint_handle handle,
+					      breakpoint_handler handler);
+/* Called by x86_exception to dispatch breakpoint exceptions to the correct handler. */
+int breakpoint_dispatch_handler(struct eregs *info);
+#else
+static inline int breakpoint_dispatch_handler(struct eregs *info)
+{
+	/* Not implemented */
+	return 0;
+}
+#endif
+#endif /* _BREAKPOINT_H_ */
diff --git a/src/arch/486/include/arch/byteorder.h b/src/arch/486/include/arch/byteorder.h
new file mode 100644
index 0000000000..2485358044
--- /dev/null
+++ b/src/arch/486/include/arch/byteorder.h
@@ -0,0 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef _BYTEORDER_H
+#define _BYTEORDER_H
+
+#define __LITTLE_ENDIAN 1234
+
+#endif /* _BYTEORDER_H */
diff --git a/src/arch/486/include/arch/cache.h b/src/arch/486/include/arch/cache.h
new file mode 100644
index 0000000000..3db28b0077
--- /dev/null
+++ b/src/arch/486/include/arch/cache.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+
+#ifndef ARCH_CACHE_H
+#define ARCH_CACHE_H
+
+#include <cpu/486/cache.h>
+
+/* Executing WBINVD when running out of CAR would not be good, prevent that. */
+static inline void dcache_clean_invalidate_all(void)
+{
+	if (!ENV_CACHE_AS_RAM)
+		wbinvd();
+}
+static inline void dcache_clean_all(void)
+{
+	/* x86 doesn't have a "clean without invalidate", fall back to both. */
+	dcache_clean_invalidate_all();
+}
+static inline void dcache_invalidate_all(void)
+{
+	if (!ENV_CACHE_AS_RAM)
+		invd();
+}
+
+#endif /* ARCH_CACHE_H */
diff --git a/src/arch/486/include/arch/cbconfig.h b/src/arch/486/include/arch/cbconfig.h
new file mode 100644
index 0000000000..3779646e9a
--- /dev/null
+++ b/src/arch/486/include/arch/cbconfig.h
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef _ARCH_CBCONFIG_H_
+#define _ARCH_CBCONFIG_H_
+
+/*
+ * Instead of using Kconfig variables for internal coreboot infrastructure
+ * variables that are architecture dependent land those things in this file.
+ * If it's not obvious all variables that are used in the common code need
+ * to have the same name across all architectures.
+ */
+
+#define COREBOOT_TABLE_SIZE 0x8000
+
+#endif
diff --git a/src/arch/486/include/arch/cpu.h b/src/arch/486/include/arch/cpu.h
new file mode 100644
index 0000000000..d056403e48
--- /dev/null
+++ b/src/arch/486/include/arch/cpu.h
@@ -0,0 +1,316 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_CPU_H
+#define ARCH_CPU_H
+
+#include <types.h>
+#include <arch/cpuid.h> /* IWYU pragma: export */
+
+/*
+ * EFLAGS bits
+ */
+#define X86_EFLAGS_CF	0x00000001 /* Carry Flag */
+#define X86_EFLAGS_PF	0x00000004 /* Parity Flag */
+#define X86_EFLAGS_AF	0x00000010 /* Auxiliary carry Flag */
+#define X86_EFLAGS_ZF	0x00000040 /* Zero Flag */
+#define X86_EFLAGS_SF	0x00000080 /* Sign Flag */
+#define X86_EFLAGS_TF	0x00000100 /* Trap Flag */
+#define X86_EFLAGS_IF	0x00000200 /* Interrupt Flag */
+#define X86_EFLAGS_DF	0x00000400 /* Direction Flag */
+#define X86_EFLAGS_OF	0x00000800 /* Overflow Flag */
+#define X86_EFLAGS_IOPL	0x00003000 /* IOPL mask */
+#define X86_EFLAGS_NT	0x00004000 /* Nested Task */
+#define X86_EFLAGS_RF	0x00010000 /* Resume Flag */
+#define X86_EFLAGS_VM	0x00020000 /* Virtual Mode */
+#define X86_EFLAGS_AC	0x00040000 /* Alignment Check */
+#define X86_EFLAGS_VIF	0x00080000 /* Virtual Interrupt Flag */
+#define X86_EFLAGS_VIP	0x00100000 /* Virtual Interrupt Pending */
+#define X86_EFLAGS_ID	0x00200000 /* CPUID detection flag */
+
+static inline unsigned int cpuid_get_max_func(void)
+{
+	return cpuid_eax(0);
+}
+
+#define X86_VENDOR_INVALID    0
+#define X86_VENDOR_INTEL      1
+#define X86_VENDOR_CYRIX      2
+#define X86_VENDOR_AMD	3
+#define X86_VENDOR_UMC	4
+#define X86_VENDOR_NEXGEN     5
+#define X86_VENDOR_CENTAUR    6
+#define X86_VENDOR_RISE       7
+#define X86_VENDOR_TRANSMETA  8
+#define X86_VENDOR_NSC	9
+#define X86_VENDOR_SIS       10
+#define X86_VENDOR_HYGON     11
+#define X86_VENDOR_ANY     0xfe
+#define X86_VENDOR_UNKNOWN 0xff
+
+#define CPUID_FEATURE_PAE (1 << 6)
+#define CPUID_FEATURE_PSE36 (1 << 17)
+#define CPUID_FEAURE_HTT (1 << 28)
+
+// Intel leaf 0x4, AMD leaf 0x8000001d EAX
+
+#define CPUID_CACHE(x, res) \
+	(((res) >> CPUID_CACHE_##x##_SHIFT) & CPUID_CACHE_##x##_MASK)
+
+#define CPUID_CACHE_SHARING_CACHE_SHIFT 14
+#define CPUID_CACHE_SHARING_CACHE_MASK 0xfff
+#define CPUID_CACHE_SHARING_CACHE(res) CPUID_CACHE(SHARING_CACHE, (res).eax)
+
+#define CPUID_CACHE_FULL_ASSOC_SHIFT 9
+#define CPUID_CACHE_FULL_ASSOC_MASK 0x1
+#define CPUID_CACHE_FULL_ASSOC(res) CPUID_CACHE(FULL_ASSOC, (res).eax)
+
+#define CPUID_CACHE_SELF_INIT_SHIFT 8
+#define CPUID_CACHE_SELF_INIT_MASK 0x1
+#define CPUID_CACHE_SELF_INIT(res) CPUID_CACHE(SELF_INIT, (res).eax)
+
+#define CPUID_CACHE_LEVEL_SHIFT 5
+#define CPUID_CACHE_LEVEL_MASK 0x7
+#define CPUID_CACHE_LEVEL(res) CPUID_CACHE(LEVEL, (res).eax)
+
+#define CPUID_CACHE_TYPE_SHIFT 0
+#define CPUID_CACHE_TYPE_MASK 0x1f
+#define CPUID_CACHE_TYPE(res) CPUID_CACHE(TYPE, (res).eax)
+
+// Intel leaf 0x4, AMD leaf 0x8000001d EBX
+
+#define CPUID_CACHE_WAYS_OF_ASSOC_SHIFT 22
+#define CPUID_CACHE_WAYS_OF_ASSOC_MASK 0x3ff
+#define CPUID_CACHE_WAYS_OF_ASSOC(res) CPUID_CACHE(WAYS_OF_ASSOC, (res).ebx)
+
+#define CPUID_CACHE_PHYS_LINE_SHIFT 12
+#define CPUID_CACHE_PHYS_LINE_MASK 0x3ff
+#define CPUID_CACHE_PHYS_LINE(res) CPUID_CACHE(PHYS_LINE, (res).ebx)
+
+#define CPUID_CACHE_COHER_LINE_SHIFT 0
+#define CPUID_CACHE_COHER_LINE_MASK 0xfff
+#define CPUID_CACHE_COHER_LINE(res) CPUID_CACHE(COHER_LINE, (res).ebx)
+
+// Intel leaf 0x4, AMD leaf 0x8000001d ECX
+
+#define CPUID_CACHE_NO_OF_SETS_SHIFT 0
+#define CPUID_CACHE_NO_OF_SETS_MASK 0xffffffff
+#define CPUID_CACHE_NO_OF_SETS(res) CPUID_CACHE(NO_OF_SETS, (res).ecx)
+
+unsigned int cpu_cpuid_extended_level(void);
+int cpu_have_cpuid(void);
+
+static inline bool cpu_is_amd(void)
+{
+	return CONFIG(CPU_AMD_PI) || CONFIG(SOC_AMD_COMMON);
+}
+
+static inline bool cpu_is_intel(void)
+{
+	return CONFIG(CPU_INTEL_COMMON) || CONFIG(SOC_INTEL_COMMON);
+}
+
+struct device;
+
+#define CPUID_FROM_FMS(family, model, stepping) ( \
+	/* bits 31..28: reserved, set to 0 */ \
+	((family) > 0xf ? ((family) - 0xf) & 0xff : 0) << 20 | \
+	((model) >> 4 & 0xf) << 16 | \
+	/* bits 15..14: reserved, set to 0 */ \
+	/* bits 13..12: processor type, set to 0 */ \
+	((family) > 0xf ? 0xf : (family) & 0xf) << 8 | \
+	((model) & 0xf) << 4 | \
+	((stepping) & 0xf) << 0)
+
+#define CPUID_EXACT_MATCH_MASK				0xffffffff
+#define CPUID_ALL_STEPPINGS_MASK			0xfffffff0
+#define CPUID_ALL_STEPPINGS_AND_BASE_MODELS_MASK	0xffffff00
+
+static inline bool cpuid_match(uint32_t a, uint32_t b, uint32_t mask)
+{
+	return (a & mask) == (b & mask);
+}
+
+#define CPU_TABLE_END	{ X86_VENDOR_INVALID, 0, 0 }
+
+struct cpu_device_id {
+	unsigned int vendor;
+	uint32_t device;
+	uint32_t device_match_mask;
+};
+
+struct cpu_driver {
+	struct device_operations *ops;
+	const struct cpu_device_id *id_table;
+};
+
+struct cpu_driver *find_cpu_driver(struct device *cpu);
+
+struct thread;
+
+struct cpu_info {
+	struct device *cpu;
+	size_t index;
+};
+
+/*
+ * This structure describes the data allocated in the %gs segment for each CPU.
+ * In order to read from this structure you will need to use assembly to
+ * reference the segment.
+ *
+ * e.g., Reading the cpu_info pointer:
+ *     %%gs:0
+ */
+struct per_cpu_segment_data {
+	/*
+	 * Instead of keeping a `struct cpu_info`, we actually keep a pointer
+	 * pointing to the cpu_info struct located in %ds. This prevents
+	 * needing specific access functions to read the fields in the cpu_info.
+	 */
+	struct cpu_info *cpu_info;
+};
+
+enum cb_err set_cpu_info(unsigned int index, struct device *cpu);
+
+static inline struct cpu_info *cpu_info(void)
+{
+	struct cpu_info *ci = NULL;
+
+	__asm__ __volatile__("mov %%gs:%c[offset], %[ci]"
+		: [ci] "=r" (ci)
+		: [offset] "i" (offsetof(struct per_cpu_segment_data, cpu_info))
+	);
+
+	return ci;
+}
+
+static inline unsigned long cpu_index(void)
+{
+	struct cpu_info *ci;
+	ci = cpu_info();
+	return ci->index;
+}
+
+struct cpuinfo_x86 {
+	uint8_t	x86;		/* CPU family */
+	uint8_t	x86_vendor;	/* CPU vendor */
+	uint8_t	x86_model;
+	uint8_t	x86_mask;
+};
+
+static inline void get_fms(struct cpuinfo_x86 *c, uint32_t tfms)
+{
+	c->x86 = (tfms >> 8) & 0xf;
+	c->x86_model = (tfms >> 4) & 0xf;
+	c->x86_mask = tfms & 0xf;
+	if (c->x86 == 0xf)
+		c->x86 += (tfms >> 20) & 0xff;
+	if (c->x86 >= 0x6)
+		c->x86_model += ((tfms >> 16) & 0xF) << 4;
+
+}
+
+/* REP NOP (PAUSE) is a good thing to insert into busy-wait loops. */
+static __always_inline void cpu_relax(void)
+{
+	__asm__ __volatile__("rep;nop" : : : "memory");
+}
+
+#define asmlinkage __attribute__((regparm(0)))
+
+/*
+ * The car_stage_entry() is the symbol jumped to for each stage
+ * after bootblock using cache-as-ram.
+ */
+asmlinkage void car_stage_entry(void);
+
+/*
+ * Get processor id using cpuid eax=1
+ * return value in EAX register
+ */
+uint32_t cpu_get_cpuid(void);
+
+/*
+ * Get processor feature flag using cpuid eax=1
+ * return value in ECX register
+ */
+uint32_t cpu_get_feature_flags_ecx(void);
+
+/*
+ * Get processor feature flag using cpuid eax=1
+ * return value in EDX register
+ */
+uint32_t cpu_get_feature_flags_edx(void);
+
+#define DETERMINISTIC_CACHE_PARAMETERS_CPUID_IA	0x04
+#define DETERMINISTIC_CACHE_PARAMETERS_CPUID_AMD	0x8000001d
+
+enum cache_level {
+	CACHE_L1D = 0,
+	CACHE_L1I = 1,
+	CACHE_L2 = 2,
+	CACHE_L3 = 3,
+	CACHE_LINV = 0xFF,
+};
+
+enum cpu_type {
+	CPUID_COMMAND_UNSUPPORTED = 0,
+	CPUID_TYPE_AMD = 1,
+	CPUID_TYPE_INTEL = 2,
+	CPUID_TYPE_INVALID = 0xFF,
+};
+
+struct cpu_cache_info {
+	uint8_t type;
+	uint8_t level;
+	size_t num_ways;
+	size_t num_sets;
+	size_t line_size;
+	size_t size;
+	size_t physical_partitions;
+	size_t num_cores_shared;
+	bool fully_associative;
+};
+
+enum cpu_type cpu_check_deterministic_cache_cpuid_supported(void);
+
+/* cpu_get_cache_assoc_info to get cache ways of associativity information. */
+size_t cpu_get_cache_ways_assoc_info(const struct cpu_cache_info *info);
+
+/*
+ * cpu_get_cache_type to get cache type.
+ * Cache type can be between 0: no cache, 1: data cache, 2: instruction cache
+ * 3: unified cache and rests are reserved.
+ */
+uint8_t cpu_get_cache_type(const struct cpu_cache_info *info);
+
+/*
+ * cpu_get_cache_level to get cache level.
+ * Cache level can be between 0: reserved, 1: L1, 2: L2, 3: L3 and rests are reserved.
+ */
+uint8_t cpu_get_cache_level(const struct cpu_cache_info *info);
+
+/* cpu_get_cache_phy_partition_info to get cache physical partitions information. */
+size_t cpu_get_cache_phy_partition_info(const struct cpu_cache_info *info);
+
+/* cpu_get_cache_line_size to get cache line size in bytes. */
+size_t cpu_get_cache_line_size(const struct cpu_cache_info *info);
+
+/* cpu_get_cache_line_size to get cache number of sets information. */
+size_t cpu_get_cache_sets(const struct cpu_cache_info *info);
+
+/* cpu_is_cache_full_assoc checks if cache is fully associative. */
+bool cpu_is_cache_full_assoc(const struct cpu_cache_info *info);
+
+/* cpu_get_max_cache_share checks the number of cores are sharing this cache. */
+size_t cpu_get_max_cache_share(const struct cpu_cache_info *info);
+
+/* get_cache_size to calculate the cache size. */
+size_t get_cache_size(const struct cpu_cache_info *info);
+
+/*
+ * fill_cpu_cache_info to get all required cache info data and fill into cpu_cache_info
+ * structure by calling CPUID.EAX=leaf and ECX=Cache Level.
+ */
+bool fill_cpu_cache_info(uint8_t level, struct cpu_cache_info *info);
+
+#endif /* ARCH_CPU_H */
diff --git a/src/arch/486/include/arch/cpuid.h b/src/arch/486/include/arch/cpuid.h
new file mode 100644
index 0000000000..70a5beb9b9
--- /dev/null
+++ b/src/arch/486/include/arch/cpuid.h
@@ -0,0 +1,95 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_CPUID_H
+#define ARCH_CPUID_H
+
+#include <types.h>
+
+struct cpuid_result {
+	uint32_t eax;
+	uint32_t ebx;
+	uint32_t ecx;
+	uint32_t edx;
+};
+
+/*
+ * Generic CPUID function
+ */
+static inline struct cpuid_result cpuid(const uint32_t eax)
+{
+	struct cpuid_result result;
+	asm volatile(
+		"cpuid;"
+		: "=a" (result.eax),
+		  "=b" (result.ebx),
+		  "=c" (result.ecx),
+		  "=d" (result.edx)
+		: "a" (eax));
+	return result;
+}
+
+/*
+ * Generic Extended CPUID function
+ */
+static inline struct cpuid_result cpuid_ext(const uint32_t eax, const uint32_t ecx)
+{
+	struct cpuid_result result;
+	asm volatile(
+		"cpuid;"
+		: "=a" (result.eax),
+		  "=b" (result.ebx),
+		  "=c" (result.ecx),
+		  "=d" (result.edx)
+		: "a" (eax), "c" (ecx));
+	return result;
+}
+
+/*
+ * CPUID functions returning a single datum
+ */
+static inline uint32_t cpuid_eax(uint32_t eax)
+{
+	asm volatile(
+		"cpuid;"
+		: "+a" (eax)
+		:: "ebx", "ecx", "edx");
+	return eax;
+}
+
+static inline uint32_t cpuid_ebx(const uint32_t eax)
+{
+	uint32_t ebx;
+
+	asm volatile(
+		"cpuid;"
+		: "=b" (ebx)
+		: "a" (eax)
+		: "ecx", "edx");
+	return ebx;
+}
+
+static inline uint32_t cpuid_ecx(const uint32_t eax)
+{
+	uint32_t ecx;
+
+	asm volatile(
+		"cpuid;"
+		: "=c" (ecx)
+		: "a" (eax)
+		: "ebx", "edx");
+	return ecx;
+}
+
+static inline uint32_t cpuid_edx(const uint32_t eax)
+{
+	uint32_t edx;
+
+	asm volatile(
+		"cpuid;"
+		: "=d" (edx)
+		: "a" (eax)
+		: "ebx", "ecx");
+	return edx;
+}
+
+#endif /* ARCH_CPUID_H */
diff --git a/src/arch/486/include/arch/exception.h b/src/arch/486/include/arch/exception.h
new file mode 100644
index 0000000000..14e35b914d
--- /dev/null
+++ b/src/arch/486/include/arch/exception.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+
+#ifndef _ARCH_EXCEPTION_H
+#define _ARCH_EXCEPTION_H
+
+#include <arch/cpu.h>
+
+#if CONFIG(IDT_IN_EVERY_STAGE) || ENV_RAMSTAGE
+asmlinkage void exception_init(void);
+#else
+static inline void exception_init(void) { /* not implemented */ }
+#endif
+
+#endif
diff --git a/src/arch/486/include/arch/header.ld b/src/arch/486/include/arch/header.ld
new file mode 100644
index 0000000000..5b380faad5
--- /dev/null
+++ b/src/arch/486/include/arch/header.ld
@@ -0,0 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+PHDRS
+{
+	to_load PT_LOAD;
+}
+
+ENTRY(_start)
diff --git a/src/arch/486/include/arch/hlt.h b/src/arch/486/include/arch/hlt.h
new file mode 100644
index 0000000000..887c737b9c
--- /dev/null
+++ b/src/arch/486/include/arch/hlt.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_HLT_H
+#define ARCH_HLT_H
+
+static __noreturn __always_inline void hlt(void)
+{
+	while (1)
+		asm("hlt");
+}
+
+#endif /* ARCH_HLT_H */
diff --git a/src/arch/486/include/arch/interrupt.h b/src/arch/486/include/arch/interrupt.h
new file mode 100644
index 0000000000..a4a80f1da7
--- /dev/null
+++ b/src/arch/486/include/arch/interrupt.h
@@ -0,0 +1,18 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef INTERRUPT_H
+#define INTERRUPT_H
+
+#include "registers.h"
+
+/* setup interrupt handlers for mainboard */
+#if CONFIG(PCI_OPTION_ROM_RUN_REALMODE)
+extern void mainboard_interrupt_handlers(int intXX, int (*intXX_func)(void));
+#elif CONFIG(PCI_OPTION_ROM_RUN_YABEL)
+#include <device/oprom/yabel/biosemu.h>
+#else
+static inline void mainboard_interrupt_handlers(int intXX,
+	int (*intXX_func)(void)) { }
+#endif
+
+#endif /* INTERRUPT_H */
diff --git a/src/arch/486/include/arch/io.h b/src/arch/486/include/arch/io.h
new file mode 100644
index 0000000000..00fb277ec0
--- /dev/null
+++ b/src/arch/486/include/arch/io.h
@@ -0,0 +1,106 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_IO_H__
+#define __ARCH_IO_H__
+
+#include <stdint.h>
+
+/*
+ * This file contains the definitions for the x86 IO instructions
+ * inb/inw/inl/outb/outw/outl and the "string versions" of the same
+ * (insb/insw/insl/outsb/outsw/outsl).
+ */
+static inline void outb(uint8_t value, uint16_t port)
+{
+	__asm__ __volatile__ ("outb %b0, %w1" : : "a" (value), "Nd" (port));
+}
+
+static inline void outw(uint16_t value, uint16_t port)
+{
+	__asm__ __volatile__ ("outw %w0, %w1" : : "a" (value), "Nd" (port));
+}
+
+static inline void outl(uint32_t value, uint16_t port)
+{
+	__asm__ __volatile__ ("outl %0, %w1" : : "a" (value), "Nd" (port));
+}
+
+static inline uint8_t inb(uint16_t port)
+{
+	uint8_t value;
+	__asm__ __volatile__ ("inb %w1, %b0" : "=a"(value) : "Nd" (port));
+	return value;
+}
+
+static inline uint16_t inw(uint16_t port)
+{
+	uint16_t value;
+	__asm__ __volatile__ ("inw %w1, %w0" : "=a"(value) : "Nd" (port));
+	return value;
+}
+
+static inline uint32_t inl(uint16_t port)
+{
+	uint32_t value;
+	__asm__ __volatile__ ("inl %w1, %0" : "=a"(value) : "Nd" (port));
+	return value;
+}
+
+static inline void outsb(uint16_t port, const void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; outsb "
+		: "=S" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		);
+}
+
+static inline void outsw(uint16_t port, const void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; outsw "
+		: "=S" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		);
+}
+
+static inline void outsl(uint16_t port, const void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; outsl "
+		: "=S" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		);
+}
+
+static inline void insb(uint16_t port, void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; insb "
+		: "=D" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		: "memory"
+		);
+}
+
+static inline void insw(uint16_t port, void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; insw "
+		: "=D" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		: "memory"
+		);
+}
+
+static inline void insl(uint16_t port, void *addr, unsigned long count)
+{
+	__asm__ __volatile__ (
+		"cld ; rep ; insl "
+		: "=D" (addr), "=c" (count)
+		: "d"(port), "0"(addr), "1" (count)
+		: "memory"
+		);
+}
+
+#endif
diff --git a/src/arch/486/include/arch/memlayout.h b/src/arch/486/include/arch/memlayout.h
new file mode 100644
index 0000000000..3e99a78d57
--- /dev/null
+++ b/src/arch/486/include/arch/memlayout.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_MEMLAYOUT_H
+#define __ARCH_MEMLAYOUT_H
+
+/* Intel386 psABI requires a 16 byte aligned stack. */
+#define ARCH_STACK_ALIGN_SIZE 16
+
+/* 32bit pointers on 486 */
+#define ARCH_POINTER_ALIGN_SIZE 4
+
+#endif /* __ARCH_MEMLAYOUT_H */
diff --git a/src/arch/486/include/arch/memory_clear.h b/src/arch/486/include/arch/memory_clear.h
new file mode 100644
index 0000000000..65fc62e98c
--- /dev/null
+++ b/src/arch/486/include/arch/memory_clear.h
@@ -0,0 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef MEMORY_CLEAR_H
+#define MEMORY_CLEAR_H
+
+#include <memrange.h>
+
+int arch_clear_memranges(const struct memranges *mem_reserved);
+
+#endif /* MEMORY_CLEAR_H */
diff --git a/src/arch/486/include/arch/mmio.h b/src/arch/486/include/arch/mmio.h
new file mode 100644
index 0000000000..c2aa0fb910
--- /dev/null
+++ b/src/arch/486/include/arch/mmio.h
@@ -0,0 +1,48 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_MMIO_H__
+#define __ARCH_MMIO_H__
+
+#include <stdint.h>
+
+static __always_inline uint8_t read8(const volatile void *addr)
+{
+	return *((volatile uint8_t *)(addr));
+}
+
+static __always_inline uint16_t read16(const volatile void *addr)
+{
+	return *((volatile uint16_t *)(addr));
+}
+
+static __always_inline uint32_t read32(const volatile void *addr)
+{
+	return *((volatile uint32_t *)(addr));
+}
+
+static __always_inline uint64_t read64(const volatile void *addr)
+{
+	return *((volatile uint64_t *)(addr));
+}
+
+static __always_inline void write8(volatile void *addr, uint8_t value)
+{
+	*((volatile uint8_t *)(addr)) = value;
+}
+
+static __always_inline void write16(volatile void *addr, uint16_t value)
+{
+	*((volatile uint16_t *)(addr)) = value;
+}
+
+static __always_inline void write32(volatile void *addr, uint32_t value)
+{
+	*((volatile uint32_t *)(addr)) = value;
+}
+
+static __always_inline void write64(volatile void *addr, uint64_t value)
+{
+	*((volatile uint64_t *)(addr)) = value;
+}
+
+#endif /* __ARCH_MMIO_H__ */
diff --git a/src/arch/486/include/arch/null_breakpoint.h b/src/arch/486/include/arch/null_breakpoint.h
new file mode 100644
index 0000000000..9d69d3c0e4
--- /dev/null
+++ b/src/arch/486/include/arch/null_breakpoint.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+#ifndef _NULL_BREAKPOINT_H_
+#define _NULL_BREAKPOINT_H_
+
+#if CONFIG(DEBUG_NULL_DEREF_BREAKPOINTS) && \
+    (CONFIG(DEBUG_NULL_DEREF_BREAKPOINTS_IN_ALL_STAGES) || ENV_RAMSTAGE)
+
+/* Places data and instructions breakpoints at address zero. */
+void null_breakpoint_init(void);
+void null_breakpoint_disable(void);
+#else
+static inline void null_breakpoint_init(void)
+{
+	/* Not implemented */
+}
+static inline void null_breakpoint_disable(void)
+{
+	/* Not implemented */
+}
+#endif
+#endif /* _NULL_BREAKPOINT_H_ */
diff --git a/src/arch/486/include/arch/pci_io_cfg.h b/src/arch/486/include/arch/pci_io_cfg.h
new file mode 100644
index 0000000000..5e69288f92
--- /dev/null
+++ b/src/arch/486/include/arch/pci_io_cfg.h
@@ -0,0 +1,117 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef _PCI_IO_CFG_H
+#define _PCI_IO_CFG_H
+
+#include <stdint.h>
+#include <arch/io.h>
+#include <device/pci_type.h>
+
+static __always_inline
+uint32_t pci_io_encode_addr(pci_devfn_t dev, uint16_t reg)
+{
+	uint32_t addr = 1 << 31;
+
+	addr |= dev >> 4;
+	addr |= reg & 0xfc;
+
+	if (CONFIG(PCI_IO_CFG_EXT))
+		addr |= (reg & 0xf00) << 16;
+
+	return addr;
+}
+
+static __always_inline
+uint8_t pci_io_read_config8(pci_devfn_t dev, uint16_t reg)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	return inb(0xCFC + (reg & 3));
+}
+
+static __always_inline
+uint16_t pci_io_read_config16(pci_devfn_t dev, uint16_t reg)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	return inw(0xCFC + (reg & 2));
+}
+
+static __always_inline
+uint32_t pci_io_read_config32(pci_devfn_t dev, uint16_t reg)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	return inl(0xCFC);
+}
+
+static __always_inline
+void pci_io_write_config8(pci_devfn_t dev, uint16_t reg, uint8_t value)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	outb(value, 0xCFC + (reg & 3));
+}
+
+static __always_inline
+void pci_io_write_config16(pci_devfn_t dev, uint16_t reg, uint16_t value)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	outw(value, 0xCFC + (reg & 2));
+}
+
+static __always_inline
+void pci_io_write_config32(pci_devfn_t dev, uint16_t reg, uint32_t value)
+{
+	uint32_t addr = pci_io_encode_addr(dev, reg);
+	outl(addr, 0xCF8);
+	outl(value, 0xCFC);
+}
+
+#if !CONFIG(ECAM_MMCONF_SUPPORT)
+
+/* Avoid name collisions as different stages have different signature
+ * for these functions. The _s_ stands for simple, fundamental IO or
+ * MMIO variant.
+ */
+
+static __always_inline
+uint8_t pci_s_read_config8(pci_devfn_t dev, uint16_t reg)
+{
+	return pci_io_read_config8(dev, reg);
+}
+
+static __always_inline
+uint16_t pci_s_read_config16(pci_devfn_t dev, uint16_t reg)
+{
+	return pci_io_read_config16(dev, reg);
+}
+
+static __always_inline
+uint32_t pci_s_read_config32(pci_devfn_t dev, uint16_t reg)
+{
+	return pci_io_read_config32(dev, reg);
+}
+
+static __always_inline
+void pci_s_write_config8(pci_devfn_t dev, uint16_t reg, uint8_t value)
+{
+	pci_io_write_config8(dev, reg, value);
+}
+
+static __always_inline
+void pci_s_write_config16(pci_devfn_t dev, uint16_t reg, uint16_t value)
+{
+	pci_io_write_config16(dev, reg, value);
+}
+
+static __always_inline
+void pci_s_write_config32(pci_devfn_t dev, uint16_t reg, uint32_t value)
+{
+	pci_io_write_config32(dev, reg, value);
+}
+
+#endif
+
+#endif /* _PCI_IO_CFG_H */
diff --git a/src/arch/486/include/arch/pci_ops.h b/src/arch/486/include/arch/pci_ops.h
new file mode 100644
index 0000000000..a7b8b663a5
--- /dev/null
+++ b/src/arch/486/include/arch/pci_ops.h
@@ -0,0 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_I386_PCI_OPS_H
+#define ARCH_I386_PCI_OPS_H
+
+#include <arch/pci_io_cfg.h>
+
+#endif /* ARCH_I386_PCI_OPS_H */
diff --git a/src/arch/486/include/arch/pirq_routing.h b/src/arch/486/include/arch/pirq_routing.h
new file mode 100644
index 0000000000..fed6d1e3da
--- /dev/null
+++ b/src/arch/486/include/arch/pirq_routing.h
@@ -0,0 +1,49 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+#ifndef ARCH_PIRQ_ROUTING_H
+#define ARCH_PIRQ_ROUTING_H
+
+/* This is the maximum number on interrupt entries that a PCI device may have.
+ *   This is NOT the number of slots or devices in the system
+ *   This is NOT the number of entries in the PIRQ table
+ * This tells us that in the PIRQ table, we are going to have 4 link-bitmap
+ * entries per PCI device
+ * It is fixed at 4: INTA, INTB, INTC, and INTD
+ * CAUTION: If you change this, pirq_routing will not work correctly */
+#define MAX_INTX_ENTRIES 4
+
+#include <stdint.h>
+
+#define PIRQ_SIGNATURE	(('$' << 0) + ('P' << 8) + ('I' << 16) + ('R' << 24))
+#define PIRQ_VERSION 0x0100
+
+struct irq_info {
+	u8 bus, devfn;	    /* Bus, device and function */
+	struct {
+		u8 link;    /* IRQ line ID, chipset dependent, 0=not routed */
+		u16 bitmap; /* Available IRQs */
+	} __packed irq[4];
+	u8 slot;	    /* Slot number, 0=onboard */
+	u8 rfu;
+} __packed;
+
+struct irq_routing_table {
+	u32 signature;		/* PIRQ_SIGNATURE should be here */
+	u16 version;		/* PIRQ_VERSION */
+	u16 size;		/* Table size in bytes */
+	u8  rtr_bus, rtr_devfn;	/* Where the interrupt router lies */
+	u16 exclusive_irqs;	/* IRQs devoted exclusively to PCI usage */
+	u16 rtr_vendor, rtr_device;/* Vendor/device ID of interrupt router */
+	u32 miniport_data;
+	u8  rfu[11];
+	u8  checksum;		/* Modulo 256 checksum must give zero */
+	struct irq_info slots[CONFIG_IRQ_SLOT_COUNT];
+} __packed;
+
+unsigned long copy_pirq_routing_table(unsigned long addr,
+	const struct irq_routing_table *routing_table);
+unsigned long write_pirq_routing_table(unsigned long start);
+
+void pirq_assign_irqs(const unsigned char pirq[CONFIG_MAX_PIRQ_LINKS]);
+
+#endif /* ARCH_PIRQ_ROUTING_H */
diff --git a/src/arch/486/include/arch/ram_segs.h b/src/arch/486/include/arch/ram_segs.h
new file mode 100644
index 0000000000..f3472f4646
--- /dev/null
+++ b/src/arch/486/include/arch/ram_segs.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef RAM_SEGS_H
+#define RAM_SEGS_H
+
+#define RAM_CODE_SEG	    0x10
+#define RAM_DATA_SEG	    0x18
+#define RAM_CODE16_SEG	  0x28
+#define RAM_DATA16_SEG	  0x30
+#define RAM_CODE_ACPI_SEG       0x38
+#define RAM_DATA_ACPI_SEG       0x40
+#define RAM_CODE_SEG64	  0x48
+
+#endif /* RAM_SEGS_H */
diff --git a/src/arch/486/include/arch/registers.h b/src/arch/486/include/arch/registers.h
new file mode 100644
index 0000000000..7043cd1941
--- /dev/null
+++ b/src/arch/486/include/arch/registers.h
@@ -0,0 +1,95 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_REGISTERS_H
+#define __ARCH_REGISTERS_H
+
+#if !defined(__ASSEMBLER__)
+#include <stdint.h>
+
+#define LONG_DOWNTO8(A) \
+	union { \
+		struct { \
+			union { \
+				struct { \
+					uint8_t A##l; \
+					uint8_t A##h; \
+				} __packed; \
+				uint16_t A##x; \
+			} __packed; \
+			uint16_t h##A##x; \
+		} __packed; \
+		uint32_t e##A##x; \
+	} __packed;
+
+#define LONG_DOWNTO16(A) \
+	union { \
+		struct { \
+			uint16_t A; \
+			uint16_t h##A; \
+		} __packed; \
+		uint32_t e##A; \
+	} __packed;
+
+#define QUAD_DOWNTO8(A) \
+	union { \
+		LONG_DOWNTO8(A) \
+		uint64_t r##A##x; \
+	} __packed
+
+#define QUAD_DOWNTO16(A) \
+	union {\
+		LONG_DOWNTO16(A) \
+		uint64_t r##A; \
+	} __packed
+
+#if ENV_X86_64
+struct eregs {
+	QUAD_DOWNTO8(a);
+	QUAD_DOWNTO8(c);
+	QUAD_DOWNTO8(d);
+	QUAD_DOWNTO8(b);
+	QUAD_DOWNTO16(bp);
+	QUAD_DOWNTO16(si);
+	QUAD_DOWNTO16(di);
+	uint64_t r8;
+	uint64_t r9;
+	uint64_t r10;
+	uint64_t r11;
+	uint64_t r12;
+	uint64_t r13;
+	uint64_t r14;
+	uint64_t r15;
+	uint64_t vector;
+	uint64_t error_code;
+	uint64_t rip;
+	uint64_t cs;
+	uint64_t rflags;
+	QUAD_DOWNTO16(sp);
+	uint64_t ss;
+};
+#else
+struct eregs {
+	LONG_DOWNTO8(a);
+	LONG_DOWNTO8(c);
+	LONG_DOWNTO8(d);
+	LONG_DOWNTO8(b);
+	LONG_DOWNTO16(sp);
+	LONG_DOWNTO16(bp);
+	LONG_DOWNTO16(si);
+	LONG_DOWNTO16(di);
+	uint32_t vector;
+	uint32_t error_code;
+	uint32_t eip;
+	uint32_t cs;
+	uint32_t eflags;
+};
+#endif
+#endif // !ASSEMBLER
+
+#if CONFIG(COMPILER_LLVM_CLANG)
+#define ADDR32(opcode) opcode
+#else
+#define ADDR32(opcode) addr32 opcode
+#endif
+
+#endif
diff --git a/src/arch/486/include/arch/rom_segs.h b/src/arch/486/include/arch/rom_segs.h
new file mode 100644
index 0000000000..a7e31d2951
--- /dev/null
+++ b/src/arch/486/include/arch/rom_segs.h
@@ -0,0 +1,17 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ROM_SEGS_H
+#define ROM_SEGS_H
+
+#define ROM_CODE_SEG 0x08
+#define ROM_DATA_SEG 0x10
+#define ROM_CODE_SEG64 0x18
+
+/*
+ * This define is placed here to make sure future romstage programmers
+ * know about it.
+ * It is used for STM setup code.
+ */
+#define SMM_TASK_STATE_SEG 0x20
+
+#endif /* ROM_SEGS_H */
diff --git a/src/arch/486/include/arch/romstage.h b/src/arch/486/include/arch/romstage.h
new file mode 100644
index 0000000000..d4906d530d
--- /dev/null
+++ b/src/arch/486/include/arch/romstage.h
@@ -0,0 +1,32 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_ROMSTAGE_H__
+#define __ARCH_ROMSTAGE_H__
+
+#include <stddef.h>
+#include <stdint.h>
+
+void mainboard_romstage_entry(void);
+
+/*
+ * prepare_and_run_postcar() determines the stack to use after
+ * cache-as-ram is torn down as well as the MTRR settings to use.
+ */
+void __noreturn prepare_and_run_postcar(void);
+
+/*
+ * Systems without a native coreboot cache-as-ram teardown may implement
+ * this to use an alternate method.
+ */
+void late_car_teardown(void);
+
+/*
+ * Cache the TSEG region at the top of ram. This region is
+ * not restricted to SMM mode until SMM has been relocated.
+ * By setting the region to cacheable it provides faster access
+ * when relocating the SMM handler as well as using the TSEG
+ * region for other purposes.
+ */
+void postcar_enable_tseg_cache(void);
+
+#endif /* __ARCH_ROMSTAGE_H__ */
diff --git a/src/arch/486/include/arch/smp/atomic.h b/src/arch/486/include/arch/smp/atomic.h
new file mode 100644
index 0000000000..4037e48a7f
--- /dev/null
+++ b/src/arch/486/include/arch/smp/atomic.h
@@ -0,0 +1,70 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_SMP_ATOMIC_H
+#define ARCH_SMP_ATOMIC_H
+
+/*
+ * Make sure gcc doesn't try to be clever and move things around
+ * on us. We need to use _exactly_ the address the user gave us,
+ * not some alias that contains the same information.
+ */
+typedef struct { volatile int counter; } atomic_t;
+
+#define ATOMIC_INIT(i)	{ (i) }
+
+/** @file x86/include/arch/smp/atomic.h
+ *
+ * Atomic operations that C can't guarantee us.  Useful for
+ * resource counting etc..
+ */
+
+/**
+ * atomic_read - read atomic variable
+ * @param v: pointer of type atomic_t
+ *
+ * Atomically reads the value of v.  Note that the guaranteed
+ * useful range of an atomic_t is only 24 bits.
+ */
+#define atomic_read(v)		((v)->counter)
+
+/**
+ * atomic_set - set atomic variable
+ * @param v: pointer of type atomic_t
+ * @param i: required value
+ *
+ * Atomically sets the value of v to i.  Note that the guaranteed
+ * useful range of an atomic_t is only 24 bits.
+ */
+#define atomic_set(v, i)	(((v)->counter) = (i))
+
+/**
+ * atomic_inc - increment atomic variable
+ * @param v: pointer of type atomic_t
+ *
+ * Atomically increments v by 1.  Note that the guaranteed
+ * useful range of an atomic_t is only 24 bits.
+ */
+static __always_inline void atomic_inc(atomic_t *v)
+{
+	__asm__ __volatile__(
+		"lock ; incl %0"
+		: "=m" (v->counter)
+		: "m" (v->counter));
+}
+
+/**
+ * atomic_dec - decrement atomic variable
+ * @param v: pointer of type atomic_t
+ *
+ * Atomically decrements v by 1.  Note that the guaranteed
+ * useful range of an atomic_t is only 24 bits.
+ */
+static __always_inline void atomic_dec(atomic_t *v)
+{
+	__asm__ __volatile__(
+		"lock ; decl %0"
+		: "=m" (v->counter)
+		: "m" (v->counter));
+}
+
+#endif /* ARCH_SMP_ATOMIC_H */
diff --git a/src/arch/486/include/arch/smp/mpspec.h b/src/arch/486/include/arch/smp/mpspec.h
new file mode 100644
index 0000000000..d83812960e
--- /dev/null
+++ b/src/arch/486/include/arch/smp/mpspec.h
@@ -0,0 +1,267 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ASM_MPSPEC_H
+#define __ASM_MPSPEC_H
+
+#include <acpi/acpi.h>
+#include <device/device.h>
+
+/*
+ * Structure definitions for SMP machines following the
+ * Intel Multiprocessing Specification 1.1 and 1.4.
+ */
+
+/*
+ * This tag identifies where the SMP configuration
+ * information is.
+ */
+
+#define SMP_MAGIC_IDENT	(('_'<<24)|('P'<<16)|('M'<<8)|'_')
+
+/*
+ * a maximum of 16 APICs with the current APIC ID architecture.
+ */
+#define MAX_APICS 0
+
+#define SMP_FLOATING_TABLE_LEN sizeof(struct intel_mp_floating)
+
+struct intel_mp_floating {
+	char mpf_signature[4];	/* "_MP_" */
+	u32 mpf_physptr;	/* Configuration table address */
+	u8 mpf_length;	/* Our length (paragraphs) */
+	u8 mpf_specification;/* Specification version */
+	u8 mpf_checksum;	/* Checksum (makes sum 0) */
+	u8 mpf_feature1;	/* Predefined or Unique configuration? */
+	u8 mpf_feature2;	/* Bit7 set for IMCR/PIC */
+#define MP_FEATURE_VIRTUALWIRE (0 << 7)
+#define MP_FEATURE_PIC         (1 << 7)
+	u8 mpf_feature3;	/* Unused (0) */
+	u8 mpf_feature4;	/* Unused (0) */
+	u8 mpf_feature5;	/* Unused (0) */
+} __packed;
+
+struct mp_config_table {
+	char mpc_signature[4];
+#define MPC_SIGNATURE "PCMP"
+	u16 mpc_length;	/* Size of table */
+	u8 mpc_spec;			/* 0x01 */
+	u8 mpc_checksum;
+	char  mpc_oem[8];
+	char  mpc_productid[12];
+	u32 mpc_oemptr;	/* 0 if not present */
+	u16 mpc_oemsize;	/* 0 if not present */
+	u16 mpc_entry_count;
+	u32 mpc_lapic;	/* APIC address */
+	u16 mpe_length;	/* Extended Table size */
+	u8 mpe_checksum;	/* Extended Table checksum */
+	u8 reserved;
+} __packed;
+
+/* Followed by entries */
+
+#define	MP_PROCESSOR	0
+#define	MP_BUS		1
+#define	MP_IOAPIC	2
+#define	MP_INTSRC	3
+#define	MP_LINTSRC	4
+
+struct mpc_config_processor {
+	u8 mpc_type;
+	u8 mpc_apicid;	/* Local APIC number */
+	u8 mpc_apicver;	/* Its versions */
+	u8 mpc_cpuflag;
+#define MPC_CPU_ENABLED		1	/* Processor is available */
+#define MPC_CPU_BOOTPROCESSOR	2	/* Processor is the BP */
+	u32 mpc_cpufeature;
+#define MPC_CPU_STEPPING_MASK 0x0F
+#define MPC_CPU_MODEL_MASK	0xF0
+#define MPC_CPU_FAMILY_MASK	0xF00
+	u32 mpc_featureflag;	/* CPUID feature value */
+	u32 mpc_reserved[2];
+} __packed;
+
+struct mpc_config_bus {
+	u8 mpc_type;
+	u8 mpc_busid;
+	u8 mpc_bustype[6];
+} __packed;
+
+#define BUSTYPE_EISA	"EISA"
+#define BUSTYPE_ISA	"ISA"
+#define BUSTYPE_INTERN	"INTERN"	/* Internal BUS */
+#define BUSTYPE_MCA	"MCA"
+#define BUSTYPE_VL	"VL"		/* Local bus */
+#define BUSTYPE_PCI	"PCI"
+#define BUSTYPE_PCMCIA	"PCMCIA"
+
+struct mpc_config_ioapic {
+	u8 mpc_type;
+	u8 mpc_apicid;
+	u8 mpc_apicver;
+	u8 mpc_flags;
+#define MPC_APIC_USABLE		0x01
+	void *mpc_apicaddr;
+} __packed;
+
+struct mpc_config_intsrc {
+	u8 mpc_type;
+	u8 mpc_irqtype;
+	u16 mpc_irqflag;
+	u8 mpc_srcbus;
+	u8 mpc_srcbusirq;
+	u8 mpc_dstapic;
+	u8 mpc_dstirq;
+} __packed;
+
+enum mp_irq_source_types {
+	mp_INT = 0,
+	mp_NMI = 1,
+	mp_SMI = 2,
+	mp_ExtINT = 3
+};
+
+struct mpc_config_lintsrc {
+	u8 mpc_type;
+	u8 mpc_irqtype;
+	u16 mpc_irqflag;
+	u8 mpc_srcbusid;
+	u8 mpc_srcbusirq;
+	u8 mpc_destapic;
+#define MP_APIC_ALL	0xFF
+	u8 mpc_destapiclint;
+} __packed;
+
+/*
+ *	Default configurations
+ *
+ *	1	2 CPU ISA 82489DX
+ *	2	2 CPU EISA 82489DX neither IRQ 0 timer nor IRQ 13 DMA chaining
+ *	3	2 CPU EISA 82489DX
+ *	4	2 CPU MCA 82489DX
+ *	5	2 CPU ISA+PCI
+ *	6	2 CPU EISA+PCI
+ *	7	2 CPU MCA+PCI
+ */
+
+#define MAX_IRQ_SOURCES 16
+#define MAX_MP_BUSSES 32
+enum mp_bustype {
+	MP_BUS_ISA = 0,
+	MP_BUS_EISA,
+	MP_BUS_PCI,
+	MP_BUS_MCA
+};
+
+/* Followed by entries */
+
+#define	MPE_SYSTEM_ADDRESS_SPACE	0x80
+#define	MPE_BUS_HIERARCHY		0x81
+#define	MPE_COMPATIBILITY_ADDRESS_SPACE	0x82
+
+struct mp_exten_config {
+	u8 mpe_type;
+	u8 mpe_length;
+} __packed;
+
+typedef struct mp_exten_config *mpe_t;
+
+struct mp_exten_system_address_space {
+	u8 mpe_type;
+	u8 mpe_length;
+	u8 mpe_busid;
+	u8 mpe_address_type;
+#define ADDRESS_TYPE_IO       0
+#define ADDRESS_TYPE_MEM      1
+#define ADDRESS_TYPE_PREFETCH 2
+	u32 mpe_address_base_low;
+	u32 mpe_address_base_high;
+	u32 mpe_address_length_low;
+	u32 mpe_address_length_high;
+} __packed;
+
+struct mp_exten_bus_hierarchy {
+	u8 mpe_type;
+	u8 mpe_length;
+	u8 mpe_busid;
+	u8 mpe_bus_info;
+#define BUS_SUBTRACTIVE_DECODE 1
+	u8 mpe_parent_busid;
+	u8 reserved[3];
+} __packed;
+
+struct mp_exten_compatibility_address_space {
+	u8 mpe_type;
+	u8 mpe_length;
+	u8 mpe_busid;
+	u8 mpe_address_modifier;
+#define ADDRESS_RANGE_SUBTRACT 1
+#define ADDRESS_RANGE_ADD      0
+	u32 mpe_range_list;
+#define RANGE_LIST_IO_ISA	0
+	/* X100 - X3FF
+	 * X500 - X7FF
+	 * X900 - XBFF
+	 * XD00 - XFFF
+	 */
+#define RANGE_LIST_IO_VGA	1
+	/* X3B0 - X3BB
+	 * X3C0 - X3DF
+	 * X7B0 - X7BB
+	 * X7C0 - X7DF
+	 * XBB0 - XBBB
+	 * XBC0 - XBDF
+	 * XFB0 - XFBB
+	 * XFC0 - XCDF
+	 */
+} __packed;
+
+void mptable_init(struct mp_config_table *mc);
+void *smp_next_mpc_entry(struct mp_config_table *mc);
+void *smp_next_mpe_entry(struct mp_config_table *mc);
+
+void smp_write_processor(struct mp_config_table *mc,
+	u8 apicid, u8 apicver,
+	u8 cpuflag, u32 cpufeature,
+	u32 featureflag);
+void smp_write_processors(struct mp_config_table *mc);
+void smp_write_ioapic(struct mp_config_table *mc,
+	u8 id, u8 ver, void *apicaddr);
+
+/* Call smp_write_ioapic() and return IOAPIC ID field. */
+u8 smp_write_ioapic_from_hw(struct mp_config_table *mc, void *apicaddr);
+
+void smp_write_intsrc(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag, u8 srcbus, u8 srcbusirq,
+	u8 dstapic, u8 dstirq);
+void smp_write_pci_intsrc(struct mp_config_table *mc,
+	u8 irqtype, u8 srcbus, u8 dev, u8 pirq,
+	u8 dstapic, u8 dstirq);
+void smp_write_intsrc_pci_bridge(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag,
+	struct device *dev,
+	unsigned char dstapic, unsigned char *dstirq);
+void smp_write_lintsrc(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag,
+	u8 srcbusid, u8 srcbusirq,
+	u8 destapic, u8 destapiclint);
+void smp_write_address_space(struct mp_config_table *mc,
+	u8 busid, u8 address_type,
+	u32 address_base_low, u32 address_base_high,
+	u32 address_length_low, u32 address_length_high);
+void smp_write_bus_hierarchy(struct mp_config_table *mc,
+	u8 busid, u8 bus_info,
+	u8 parent_busid);
+void smp_write_compatibility_address_space(struct mp_config_table *mc,
+	u8 busid, u8 address_modifier,
+	u32 range_list);
+void *smp_write_floating_table(unsigned long addr, unsigned int virtualwire);
+unsigned long write_smp_table(unsigned long addr);
+
+void mptable_lintsrc(struct mp_config_table *mc, unsigned long bus_isa);
+void mptable_add_isa_interrupts(struct mp_config_table *mc,
+	unsigned long bus_isa, unsigned long apicid, int external);
+void mptable_write_buses(struct mp_config_table *mc, int *max_pci_bus,
+	int *isa_bus);
+void *mptable_finalize(struct mp_config_table *mc);
+
+#endif
diff --git a/src/arch/486/include/arch/smp/spinlock.h b/src/arch/486/include/arch/smp/spinlock.h
new file mode 100644
index 0000000000..cb25531b15
--- /dev/null
+++ b/src/arch/486/include/arch/smp/spinlock.h
@@ -0,0 +1,70 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef ARCH_SMP_SPINLOCK_H
+#define ARCH_SMP_SPINLOCK_H
+
+#include <thread.h>
+
+/*
+ * Your basic SMP spinlocks, allowing only a single CPU anywhere
+ */
+
+typedef struct {
+	volatile unsigned int lock;
+} spinlock_t;
+
+#define SPIN_LOCK_UNLOCKED { 1 }
+
+#define DECLARE_SPIN_LOCK(x)	\
+	static spinlock_t x = SPIN_LOCK_UNLOCKED;
+
+/*
+ * Simple spin lock operations.  There are two variants, one clears IRQ's
+ * on the local processor, one does not.
+ *
+ * We make no fairness assumptions. They have a cost.
+ */
+#define barrier() __asm__ __volatile__("" : : : "memory")
+#define spin_is_locked(x)	(*(volatile int *)(&(x)->lock) <= 0)
+#define spin_unlock_wait(x)	do { barrier(); } while (spin_is_locked(x))
+#undef barrier
+
+#define spin_lock_string \
+	"\n1:\t" \
+	"lock ; decl %0\n\t" \
+	"js 2f\n" \
+	".section .text.lock,\"ax\"\n" \
+	"2:\t" \
+	"cmpl $0,%0\n\t" \
+	"rep;nop\n\t" \
+	"jle 2b\n\t" \
+	"jmp 1b\n" \
+	".previous"
+
+/*
+ * This works. Despite all the confusion.
+ */
+#define spin_unlock_string \
+	"movl $1,%0"
+
+static __always_inline void spin_lock(spinlock_t *lock)
+{
+	__asm__ __volatile__(
+		spin_lock_string
+		: "=m" (lock->lock) : : "memory");
+
+	/* Switching contexts while holding a spinlock will lead to deadlocks */
+	thread_coop_disable();
+
+}
+
+static __always_inline void spin_unlock(spinlock_t *lock)
+{
+	thread_coop_enable();
+
+	__asm__ __volatile__(
+		spin_unlock_string
+		: "=m" (lock->lock) : : "memory");
+}
+
+#endif /* ARCH_SMP_SPINLOCK_H */
diff --git a/src/arch/486/include/arch/stages.h b/src/arch/486/include/arch/stages.h
new file mode 100644
index 0000000000..e45105b3c3
--- /dev/null
+++ b/src/arch/486/include/arch/stages.h
@@ -0,0 +1,6 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_STAGES_H
+#define __ARCH_STAGES_H
+
+#endif
diff --git a/src/arch/486/include/arch/symbols.h b/src/arch/486/include/arch/symbols.h
new file mode 100644
index 0000000000..caafdfa08d
--- /dev/null
+++ b/src/arch/486/include/arch/symbols.h
@@ -0,0 +1,30 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __ARCH_SYMBOLS_H
+#define __ARCH_SYMBOLS_H
+
+/*
+ * The _car_region_[start|end] covers the entirety of the cache as RAM
+ * region. All other symbols with the _car prefix a subsets of this
+ * larger region.
+ */
+extern char _car_region_start[];
+extern char _car_region_end[];
+#define _car_region_size (_car_region_end - _car_region_start)
+
+/*
+ * This is the stack area used for all stages that execute when cache-as-ram
+ * is up. Area is not cleared in between stages.
+ */
+extern char _car_stack[];
+extern char _ecar_stack[];
+#define _car_stack_size (_ecar_stack - _car_stack)
+
+extern char _car_unallocated_start[];
+
+extern char _car_ehci_dbg_info[];
+extern char _ecar_ehci_dbg_info[];
+#define _car_ehci_dbg_info_size \
+	(_ecar_ehci_dbg_info - _car_ehci_dbg_info)
+
+#endif
diff --git a/src/arch/486/include/cf9_reset.h b/src/arch/486/include/cf9_reset.h
new file mode 100644
index 0000000000..51f89504d2
--- /dev/null
+++ b/src/arch/486/include/cf9_reset.h
@@ -0,0 +1,27 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef X86_CF9_RESET_H
+#define X86_CF9_RESET_H
+
+/* Reset control port */
+#define RST_CNT			0xcf9
+#define FULL_RST		(1 << 3)
+#define RST_CPU			(1 << 2)
+#define SYS_RST			(1 << 1)
+
+/* Implement the bare reset, i.e. write to cf9. */
+void do_system_reset(void);
+void do_full_reset(void);
+
+/* Called by functions below before reset. */
+#if CONFIG(HAVE_CF9_RESET_PREPARE)
+void cf9_reset_prepare(void);
+#else
+static inline void cf9_reset_prepare(void) {}
+#endif
+
+/* Prepare for reset, run do_*_reset(), halt. */
+__noreturn void system_reset(void);
+__noreturn void full_reset(void);
+
+#endif	/* X86_CF9_RESET_H */
diff --git a/src/arch/486/include/mode_switch.h b/src/arch/486/include/mode_switch.h
new file mode 100644
index 0000000000..24efb1ef58
--- /dev/null
+++ b/src/arch/486/include/mode_switch.h
@@ -0,0 +1,69 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <stdint.h>
+
+#if ENV_X86_64
+int protected_mode_call_narg(uint32_t arg_count,
+			     uint32_t func_ptr,
+			     uint32_t opt_arg1,
+			     uint32_t opt_arg2);
+
+/*
+ * Drops into protected mode and calls the function, which must have been compiled for x86_32.
+ * After the function returns it enters long mode again.
+ * The function pointer destination must be below 4GiB in physical memory.
+ *
+ * The called function doesn't have arguments and returns an int.
+ */
+static inline int protected_mode_call(void *func)
+{
+	return protected_mode_call_narg(0, (uintptr_t)func, 0, 0);
+}
+
+/*
+ * Drops into protected mode and calls the function, which must have been compiled for x86_32.
+ * After the function returns it enters long mode again.
+ * The function pointer destination must be below 4GiB in physical memory.
+ * Only the lower 32bits of the argument are passed to the called function.
+ *
+ * The called function have one argument and returns an int.
+ */
+static inline int protected_mode_call_1arg(void *func, uint32_t arg1)
+{
+	return protected_mode_call_narg(1, (uintptr_t)func, arg1, 0);
+}
+
+/*
+ * Drops into protected mode and calls the function, which must have been compiled for x86_32.
+ * After the function returns it enters long mode again.
+ * The function pointer destination must be below 4GiB in physical memory.
+ * Only the lower 32bits of the argument are passed to the called function.
+ *
+ * The called function has two arguments and returns an int.
+ */
+static inline int protected_mode_call_2arg(void *func, uint32_t arg1, uint32_t arg2)
+{
+	return protected_mode_call_narg(2, (uintptr_t)func, arg1, arg2);
+}
+#else
+static inline int protected_mode_call(void *func)
+{
+	int (*doit)(void) = func;
+
+	return doit();
+}
+
+static inline int protected_mode_call_1arg(void *func, uint32_t arg1)
+{
+	int (*doit)(uint32_t arg1) = func;
+
+	return doit(arg1);
+}
+
+static inline int protected_mode_call_2arg(void *func, uint32_t arg1, uint32_t arg2)
+{
+	int (*doit)(uint32_t arg1, uint32_t arg2) = func;
+
+	return doit(arg1, arg2);
+}
+#endif
diff --git a/src/arch/486/include/smm.h b/src/arch/486/include/smm.h
new file mode 100644
index 0000000000..e6db9dcf04
--- /dev/null
+++ b/src/arch/486/include/smm.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <stdint.h>
+#include <cpu/x86/smm.h>
+
+/*
+ * calls into SMM with the given cmd and subcmd in eax, and arg in ebx
+ *
+ * static inline because the resulting assembly is often smaller than
+ * the call sequence due to constant folding.
+ */
+static inline u32 call_smm(u8 cmd, u8 subcmd, void *arg)
+{
+	u32 res = 0;
+	__asm__ __volatile__ (
+		"outb %b0, %3"
+		: "=a" (res)
+		: "a" ((subcmd << 8) | cmd), "b" (arg), "i" (APM_CNT));
+	return res;
+}
diff --git a/src/arch/486/memcpy.c b/src/arch/486/memcpy.c
new file mode 100644
index 0000000000..97bd308235
--- /dev/null
+++ b/src/arch/486/memcpy.c
@@ -0,0 +1,117 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <string.h>
+#include <stdbool.h>
+#include <asan.h>
+
+#include <console/console.h>
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)	//pc2005 enable for ALI
+#	include "../../northbridge/ali/m1489/regs.h"
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+// #	include "../../northbridge/umc/um8881/regs.h"
+#endif
+
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)	//pc2005 enable for ALI
+
+//original
+static void __memcpy_raw(void *dest, const void *src, size_t n)
+{
+	unsigned long d0, d1, d2;
+
+	asm volatile(
+#if ENV_X86_64
+		"rep ; movsd\n\t"
+		"mov %4,%%rcx\n\t"
+#else
+		"rep ; movsl\n\t"
+		"movl %4,%%ecx\n\t"
+#endif
+		"rep ; movsb\n\t"
+		: "=&c" (d0), "=&D" (d1), "=&S" (d2)
+		: "0" (n >> 2), "g" (n & 3), "1" (dest), "2" (src)
+		: "memory"
+	);
+
+	// return dest;
+}
+
+
+void *memcpy(void *dest, const void *src, size_t n)
+{
+
+#if (ENV_ROMSTAGE && CONFIG(ASAN_IN_ROMSTAGE)) || \
+	(ENV_RAMSTAGE && CONFIG(ASAN_IN_RAMSTAGE))
+	check_memory_region((unsigned long)src, n, false, _RET_IP_);
+	check_memory_region((unsigned long)dest, n, true, _RET_IP_);
+#endif
+
+	// printk(BIOS_DEBUG, "!!MCPY %p<-%p n:%u\n", dest, src, n);
+
+	uintptr_t dstaddr = (uintptr_t) dest;
+	uintptr_t srcaddr = (uintptr_t) src;
+
+	if ((ENV_RAMSTAGE) && (srcaddr >= 0xe0000) && (srcaddr < 0x100000)) {
+		size_t frag_size = n;
+
+		//pc2005
+		DIS_SEGMENT_E;	//so we can have RAM
+		EN_SHADOW_EF;	//enable RAM	TODO check if only shadow is enough (higher priority)
+		EN_ROM_A31;	//enable FFFF
+
+		//now we can switch between E and F in FFFF
+
+		if (srcaddr < 0xf0000) {
+			//map E to FFFF
+			EN_SWAP_EF;
+
+			frag_size = n < (0xf0000-srcaddr) ? n: 0xf0000-srcaddr;
+
+			// printk(BIOS_DEBUG, " ROME a:0x%lx s:0x%x\n", srcaddr, frag_size);
+
+			__memcpy_raw((void*)dstaddr, (void*)(srcaddr | 0xffff0000), frag_size);
+
+			dstaddr += frag_size;	//next start
+			srcaddr += frag_size;	//should be either 0xf0000 or less (and frag == 0)
+			frag_size = n - frag_size;
+
+			// printk(BIOS_DEBUG, " ROMEnew a:0x%lx s:0x%x\n", srcaddr, frag_size);
+		}
+
+		if (frag_size) {
+			//rest of buffer should be always in 0xf0000
+
+			if (frag_size > 0x10000) {
+				printk(BIOS_INFO, "overflowed 0xfffff!!!\n");
+			}
+
+			//map F to FFFF
+			DIS_SWAP_EF;
+
+			// printk(BIOS_DEBUG, " ROMF a:0x%lx s:0x%x\n", srcaddr, frag_size);
+
+			__memcpy_raw((void*)dstaddr, (void*)(srcaddr | 0xffff0000), frag_size);
+		}
+	} else {
+		__memcpy_raw(dest, src, n);
+	}
+
+	return dest;
+}
+
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+
+void *memcpy(void *vdest, const void *vsrc, size_t bytes)
+{
+	const char *src = vsrc;
+	char *dest = vdest;
+	int i;
+
+	for (i = 0; i < (int)bytes; i++)
+		dest[i] = src[i];
+
+	return vdest;
+}
+
+#endif
diff --git a/src/arch/486/memlayout.ld b/src/arch/486/memlayout.ld
new file mode 100644
index 0000000000..9c1eeb054f
--- /dev/null
+++ b/src/arch/486/memlayout.ld
@@ -0,0 +1,42 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <memlayout.h>
+#include <arch/header.ld>
+
+SECTIONS
+{
+	/*
+	 * It would be good to lay down RAMSTAGE, ROMSTAGE, etc consecutively
+	 * like other architectures/chipsets it's not possible because of
+	 * the linking games played during romstage creation by trying
+	 * to find the final landing place in CBFS for XIP. Therefore,
+	 * conditionalize with macros.
+	 */
+#if ENV_RAMSTAGE
+	/* Relocated at runtime in cbmem so the address does not matter. */
+	RAMSTAGE(8M, 8M)
+
+#elif ENV_ROMSTAGE
+	/* The 1M size is not allocated. It's just for basic size checking.
+	 * Link at 32MiB address and rely on cbfstool to relocate to XIP. */
+	ROMSTAGE(CONFIG_ROMSTAGE_ADDR, 1M)
+
+	INCLUDE "romstage/arch/486/car.ld"
+#elif ENV_SEPARATE_VERSTAGE
+	/* The 1M size is not allocated. It's just for basic size checking.
+	 * Link at 32MiB address and rely on cbfstool to relocate to XIP. */
+	VERSTAGE(CONFIG_VERSTAGE_ADDR, 1M)
+
+	INCLUDE "verstage/arch/486/car.ld"
+#elif ENV_BOOTBLOCK
+
+	INCLUDE "bootblock/arch/486/car.ld"
+
+#elif ENV_POSTCAR
+	POSTCAR(8M, 1M)
+#endif
+}
+
+#if ENV_BOOTBLOCK
+	INCLUDE "bootblock/arch/486/bootblock.ld"
+#endif  /* ENV_BOOTBLOCK */
diff --git a/src/arch/486/memmove_32.c b/src/arch/486/memmove_32.c
new file mode 100644
index 0000000000..c5894f744f
--- /dev/null
+++ b/src/arch/486/memmove_32.c
@@ -0,0 +1,202 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+/*
+ * This file is derived from memcpy_32.c in the Linux kernel.
+ */
+
+//TODO maybe use lib/memmove.c ? which is smaller, speed probably doesn't matter
+
+#include <string.h>
+#include <stdbool.h>
+#include <asan.h>
+
+void *memmove(void *dest, const void *src, size_t n)
+{
+	int d0, d1, d2, d3, d4, d5;
+	char *ret = dest;
+
+#if (ENV_ROMSTAGE && CONFIG(ASAN_IN_ROMSTAGE)) || \
+		(ENV_RAMSTAGE && CONFIG(ASAN_IN_RAMSTAGE))
+	check_memory_region((unsigned long)src, n, false, _RET_IP_);
+	check_memory_region((unsigned long)dest, n, true, _RET_IP_);
+#endif
+
+	__asm__ __volatile__(
+		/* Handle more 16bytes in loop */
+		"cmp $0x10, %0\n\t"
+		"jb	1f\n\t"
+
+		/* Decide forward/backward copy mode */
+		"cmp %2, %1\n\t"
+		"jb	2f\n\t"
+
+		/*
+		 * movs instruction have many startup latency
+		 * so we handle small size by general register.
+		 */
+		"cmp  $680, %0\n\t"
+		"jb 3f\n\t"
+		/*
+		 * movs instruction is only good for aligned case.
+		 */
+		"mov %1, %3\n\t"
+		"xor %2, %3\n\t"
+		"and $0xff, %3\n\t"
+		"jz 4f\n\t"
+		"3:\n\t"
+		"sub $0x10, %0\n\t"
+
+		/*
+		 * We gobble 16byts forward in each loop.
+		 */
+		"3:\n\t"
+		"sub $0x10, %0\n\t"
+		"mov 0*4(%1), %3\n\t"
+		"mov 1*4(%1), %4\n\t"
+		"mov  %3, 0*4(%2)\n\t"
+		"mov  %4, 1*4(%2)\n\t"
+		"mov 2*4(%1), %3\n\t"
+		"mov 3*4(%1), %4\n\t"
+		"mov  %3, 2*4(%2)\n\t"
+		"mov  %4, 3*4(%2)\n\t"
+		"lea  0x10(%1), %1\n\t"
+		"lea  0x10(%2), %2\n\t"
+		"jae 3b\n\t"
+		"add $0x10, %0\n\t"
+		"jmp 1f\n\t"
+
+		/*
+		 * Handle data forward by movs.
+		 */
+		".p2align 4\n\t"
+		"4:\n\t"
+		"mov -4(%1, %0), %3\n\t"
+		"lea -4(%2, %0), %4\n\t"
+		"shr $2, %0\n\t"
+		"rep movsl\n\t"
+		"mov %3, (%4)\n\t"
+		"jmp 11f\n\t"
+		/*
+		 * Handle data backward by movs.
+		 */
+		".p2align 4\n\t"
+		"6:\n\t"
+		"mov (%1), %3\n\t"
+		"mov %2, %4\n\t"
+		"lea -4(%1, %0), %1\n\t"
+		"lea -4(%2, %0), %2\n\t"
+		"shr $2, %0\n\t"
+		"std\n\t"
+		"rep movsl\n\t"
+		"mov %3,(%4)\n\t"
+		"cld\n\t"
+		"jmp 11f\n\t"
+
+		/*
+		 * Start to prepare for backward copy.
+		 */
+		".p2align 4\n\t"
+		"2:\n\t"
+		"cmp  $680, %0\n\t"
+		"jb 5f\n\t"
+		"mov %1, %3\n\t"
+		"xor %2, %3\n\t"
+		"and $0xff, %3\n\t"
+		"jz 6b\n\t"
+
+		/*
+		 * Calculate copy position to tail.
+		 */
+		"5:\n\t"
+		"add %0, %1\n\t"
+		"add %0, %2\n\t"
+		"sub $0x10, %0\n\t"
+
+		/*
+		 * We gobble 16byts backward in each loop.
+		 */
+		"7:\n\t"
+		"sub $0x10, %0\n\t"
+
+		"mov -1*4(%1), %3\n\t"
+		"mov -2*4(%1), %4\n\t"
+		"mov  %3, -1*4(%2)\n\t"
+		"mov  %4, -2*4(%2)\n\t"
+		"mov -3*4(%1), %3\n\t"
+		"mov -4*4(%1), %4\n\t"
+		"mov  %3, -3*4(%2)\n\t"
+		"mov  %4, -4*4(%2)\n\t"
+		"lea  -0x10(%1), %1\n\t"
+		"lea  -0x10(%2), %2\n\t"
+		"jae 7b\n\t"
+		/*
+		 * Calculate copy position to head.
+		 */
+		"add $0x10, %0\n\t"
+		"sub %0, %1\n\t"
+		"sub %0, %2\n\t"
+
+		/*
+		 * Move data from 8 bytes to 15 bytes.
+		 */
+		".p2align 4\n\t"
+		"1:\n\t"
+		"cmp $8, %0\n\t"
+		"jb 8f\n\t"
+		"mov 0*4(%1), %3\n\t"
+		"mov 1*4(%1), %4\n\t"
+		"mov -2*4(%1, %0), %5\n\t"
+		"mov -1*4(%1, %0), %1\n\t"
+
+		"mov  %3, 0*4(%2)\n\t"
+		"mov  %4, 1*4(%2)\n\t"
+		"mov  %5, -2*4(%2, %0)\n\t"
+		"mov  %1, -1*4(%2, %0)\n\t"
+		"jmp 11f\n\t"
+
+		/*
+		 * Move data from 4 bytes to 7 bytes.
+		 */
+		".p2align 4\n\t"
+		"8:\n\t"
+		"cmp $4, %0\n\t"
+		"jb 9f\n\t"
+		"mov 0*4(%1), %3\n\t"
+		"mov -1*4(%1, %0), %4\n\t"
+		"mov  %3, 0*4(%2)\n\t"
+		"mov  %4, -1*4(%2, %0)\n\t"
+		"jmp 11f\n\t"
+
+		/*
+		 * Move data from 2 bytes to 3 bytes.
+		 */
+		".p2align 4\n\t"
+		"9:\n\t"
+		"cmp $2, %0\n\t"
+		"jb 10f\n\t"
+		"movw 0*2(%1), %%dx\n\t"
+		"movw -1*2(%1, %0), %%bx\n\t"
+		"movw %%dx, 0*2(%2)\n\t"
+		"movw %%bx, -1*2(%2, %0)\n\t"
+		"jmp 11f\n\t"
+
+		/*
+		 * Move data for 1 byte.
+		 */
+		".p2align 4\n\t"
+		"10:\n\t"
+		"cmp $1, %0\n\t"
+		"jb 11f\n\t"
+		"movb (%1), %%cl\n\t"
+		"movb %%cl, (%2)\n\t"
+		".p2align 4\n\t"
+		"11:"
+		: "=&c" (d0), "=&S" (d1), "=&D" (d2),
+		  "=r" (d3), "=r" (d4), "=r"(d5)
+		: "0" (n),
+		 "1" (src),
+		 "2" (dest)
+		: "memory");
+
+	return ret;
+
+}
diff --git a/src/arch/486/memset.c b/src/arch/486/memset.c
new file mode 100644
index 0000000000..e1d75a0b0e
--- /dev/null
+++ b/src/arch/486/memset.c
@@ -0,0 +1,74 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+/* From glibc-2.14, sysdeps/i386/memset.c */
+
+//TODO maybe use lib funcs?
+
+
+#include <string.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include <asan.h>
+
+typedef uint32_t op_t;
+
+void *memset(void *dstpp, int c, size_t len)
+{
+	int d0;
+	unsigned long int dstp = (unsigned long int)dstpp;
+
+#if (ENV_ROMSTAGE && CONFIG(ASAN_IN_ROMSTAGE)) || \
+		(ENV_RAMSTAGE && CONFIG(ASAN_IN_RAMSTAGE))
+	check_memory_region((unsigned long)dstpp, len, true, _RET_IP_);
+#endif
+
+	/* This explicit register allocation improves code very much indeed. */
+	register op_t x asm("ax");
+
+	x = (unsigned char)c;
+
+	/* Clear the direction flag, so filling will move forward.  */
+	asm volatile("cld");
+
+	/* This threshold value is optimal.  */
+	if (len >= 12) {
+		/* Fill X with four copies of the char we want to fill with. */
+		x |= (x << 8);
+		x |= (x << 16);
+
+		/* Adjust LEN for the bytes handled in the first loop.  */
+		len -= (-dstp) % sizeof(op_t);
+
+		/*
+		 * There are at least some bytes to set. No need to test for
+		 * LEN == 0 in this alignment loop.
+		 */
+
+		/* Fill bytes until DSTP is aligned on a longword boundary. */
+		asm volatile(
+			"rep\n"
+			"stosb" /* %0, %2, %3 */ :
+			"=D" (dstp), "=c" (d0) :
+			"0" (dstp), "1" ((-dstp) % sizeof(op_t)), "a" (x) :
+			"memory");
+
+		/* Fill longwords.  */
+		asm volatile(
+			"rep\n"
+			"stosl" /* %0, %2, %3 */ :
+			"=D" (dstp), "=c" (d0) :
+			"0" (dstp), "1" (len / sizeof(op_t)), "a" (x) :
+			"memory");
+		len %= sizeof(op_t);
+	}
+
+	/* Write the last few bytes. */
+	asm volatile(
+		"rep\n"
+		"stosb" /* %0, %2, %3 */ :
+		"=D" (dstp), "=c" (d0) :
+		"0" (dstp), "1" (len), "a" (x) :
+		"memory");
+
+	return dstpp;
+}
diff --git a/src/arch/486/mmap_boot.c b/src/arch/486/mmap_boot.c
new file mode 100644
index 0000000000..0a60ddfa94
--- /dev/null
+++ b/src/arch/486/mmap_boot.c
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <boot_device.h>
+// #include <spi_flash.h>
+#include <stdint.h>
+
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)	//pc2005 enable for ALI
+
+// NOTICE 0xfffe0000 not existent on finali
+#	define rom_base ((void *)(uintptr_t)(0x100000ULL-CONFIG_ROM_SIZE))
+
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+
+/* The ROM is memory mapped just below 4GiB. Form a pointer for the base. */
+#	define rom_base ((void *)(uintptr_t)(0x100000000ULL-CONFIG_ROM_SIZE))
+
+#endif
+
+
+static const struct mem_region_device boot_dev =
+	MEM_REGION_DEV_RO_INIT(rom_base, CONFIG_ROM_SIZE);
+
+const struct region_device *boot_device_ro(void)
+{
+	return &boot_dev.rdev;
+}
+
+#if 0
+uint32_t spi_flash_get_mmap_windows(struct flash_mmap_window *table)
+{
+	return 0;
+}
+#endif
diff --git a/src/arch/486/mpspec.c b/src/arch/486/mpspec.c
new file mode 100644
index 0000000000..84d5ebc1bb
--- /dev/null
+++ b/src/arch/486/mpspec.c
@@ -0,0 +1,506 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <acpi/acpi.h>
+#include <console/console.h>
+#include <cpu/cpu.h>
+#include <device/device.h>
+#include <device/path.h>
+#include <device/pci_ids.h>
+#include <stdint.h>
+#include <string.h>
+
+/* Initialize the specified "mc" struct with initial values. */
+void mptable_init(struct mp_config_table *mc)
+{
+	int i;
+	u32 lapic_addr = cpu_get_lapic_addr();
+
+	memset(mc, 0, sizeof(*mc));
+
+	memcpy(mc->mpc_signature, MPC_SIGNATURE, 4);
+
+	mc->mpc_length = sizeof(*mc);	/* Initially just the header size. */
+	mc->mpc_spec = 0x04;		/* MultiProcessor specification 1.4 */
+	mc->mpc_checksum = 0;		/* Not yet computed. */
+	mc->mpc_oemptr = 0;
+	mc->mpc_oemsize = 0;
+	mc->mpc_entry_count = 0;	/* No entries yet... */
+	mc->mpc_lapic = lapic_addr;
+	mc->mpe_length = 0;
+	mc->mpe_checksum = 0;
+	mc->reserved = 0;
+
+	strncpy(mc->mpc_oem, CONFIG_MAINBOARD_VENDOR, 8);
+	strncpy(mc->mpc_productid, CONFIG_MAINBOARD_PART_NUMBER, 12);
+
+	/*
+	 * The oem/productid fields are exactly 8/12 bytes long. If the resp.
+	 * entry is shorter, the remaining bytes are filled with spaces.
+	 */
+	for (i = MIN(strlen(CONFIG_MAINBOARD_VENDOR), 8); i < 8; i++)
+		mc->mpc_oem[i] = ' ';
+	for (i = MIN(strlen(CONFIG_MAINBOARD_PART_NUMBER), 12); i < 12; i++)
+		mc->mpc_productid[i] = ' ';
+}
+
+static unsigned char smp_compute_checksum(void *v, int len)
+{
+	unsigned char *bytes;
+	unsigned char checksum;
+	int i;
+	bytes = v;
+	checksum = 0;
+	for (i = 0; i < len; i++)
+		checksum -= bytes[i];
+	return checksum;
+}
+
+static void *smp_write_floating_table_physaddr(uintptr_t addr,
+	uintptr_t mpf_physptr, unsigned int virtualwire)
+{
+	struct intel_mp_floating *mf;
+	void *v;
+
+	v = (void *)addr;
+	mf = v;
+	mf->mpf_signature[0] = '_';
+	mf->mpf_signature[1] = 'M';
+	mf->mpf_signature[2] = 'P';
+	mf->mpf_signature[3] = '_';
+	mf->mpf_physptr = mpf_physptr;
+	mf->mpf_length = 1;
+	mf->mpf_specification = 4;
+	mf->mpf_checksum = 0;
+	mf->mpf_feature1 = 0;
+	mf->mpf_feature2 = virtualwire?MP_FEATURE_PIC:MP_FEATURE_VIRTUALWIRE;
+	mf->mpf_feature3 = 0;
+	mf->mpf_feature4 = 0;
+	mf->mpf_feature5 = 0;
+	mf->mpf_checksum = smp_compute_checksum(mf, mf->mpf_length*16);
+	return v;
+}
+
+void *smp_write_floating_table(unsigned long addr, unsigned int virtualwire)
+{
+	/* 16 byte align the table address */
+	addr = (addr + 0xf) & (~0xf);
+	return smp_write_floating_table_physaddr(addr, addr
+		+ SMP_FLOATING_TABLE_LEN, virtualwire);
+}
+
+void *smp_next_mpc_entry(struct mp_config_table *mc)
+{
+	void *v;
+	v = (void *)(((char *)mc) + mc->mpc_length);
+
+	return v;
+}
+static void smp_add_mpc_entry(struct mp_config_table *mc, u16 length)
+{
+	mc->mpc_length += length;
+	mc->mpc_entry_count++;
+}
+
+void *smp_next_mpe_entry(struct mp_config_table *mc)
+{
+	void *v;
+	v = (void *)(((char *)mc) + mc->mpc_length + mc->mpe_length);
+
+	return v;
+}
+static void smp_add_mpe_entry(struct mp_config_table *mc, mpe_t mpe)
+{
+	mc->mpe_length += mpe->mpe_length;
+}
+
+/*
+ * Type 0: Processor Entries:
+ * Entry Type, LAPIC ID, LAPIC Version, CPU Flags EN/BP,
+ * CPU Signature (Stepping, Model, Family), Feature Flags
+ */
+void smp_write_processor(struct mp_config_table *mc,
+	u8 apicid, u8 apicver, u8 cpuflag,
+	u32 cpufeature, u32 featureflag)
+{
+	struct mpc_config_processor *mpc;
+	mpc = smp_next_mpc_entry(mc);
+	memset(mpc, '\0', sizeof(*mpc));
+	mpc->mpc_type = MP_PROCESSOR;
+	mpc->mpc_apicid = apicid;
+	mpc->mpc_apicver = apicver;
+	mpc->mpc_cpuflag = cpuflag;
+	mpc->mpc_cpufeature = cpufeature;
+	mpc->mpc_featureflag = featureflag;
+	smp_add_mpc_entry(mc, sizeof(*mpc));
+}
+
+/*
+ * If we assume a symmetric processor configuration we can
+ * get all of the information we need to write the processor
+ * entry from the bootstrap processor.
+ * Plus I don't think linux really even cares.
+ * Having the proper apicid's in the table so the non-bootstrap
+ *  processors can be woken up should be enough.
+ */
+void smp_write_processors(struct mp_config_table *mc)
+{
+	int boot_apic_id;
+	int order_id;
+	unsigned int apic_version;
+	unsigned int cpu_features;
+	unsigned int cpu_feature_flags;
+	struct device *cpu;
+
+	boot_apic_id = lapicid();
+	apic_version = lapic_read(LAPIC_LVR) & 0xff;
+	cpu_features = cpu_get_cpuid();
+	cpu_feature_flags = cpu_get_feature_flags_edx();
+	/* order the output of the cpus to fix a bug in kernel 2.6.11 */
+	for (order_id = 0; order_id < 256; order_id++) {
+		for (cpu = all_devices; cpu; cpu = cpu->next) {
+			unsigned long cpu_flag;
+			if (!is_enabled_cpu(cpu))
+				continue;
+
+			cpu_flag = MPC_CPU_ENABLED;
+
+			if (boot_apic_id == cpu->path.apic.apic_id)
+				cpu_flag = MPC_CPU_ENABLED
+					| MPC_CPU_BOOTPROCESSOR;
+
+			if (cpu->path.apic.apic_id == order_id) {
+				smp_write_processor(mc,
+					cpu->path.apic.apic_id, apic_version,
+					cpu_flag, cpu_features,
+					cpu_feature_flags
+				);
+				break;
+			}
+		}
+	}
+}
+
+/*
+ * Type 1: Bus Entries:
+ * Entry Type, Bus ID, Bus Type
+ */
+static void smp_write_bus(struct mp_config_table *mc,
+	u8 id, const char *bustype)
+{
+	struct mpc_config_bus *mpc;
+	mpc = smp_next_mpc_entry(mc);
+	memset(mpc, '\0', sizeof(*mpc));
+	mpc->mpc_type = MP_BUS;
+	mpc->mpc_busid = id;
+	memcpy(mpc->mpc_bustype, bustype, sizeof(mpc->mpc_bustype));
+	smp_add_mpc_entry(mc, sizeof(*mpc));
+}
+
+/*
+ * Type 2: I/O APIC Entries:
+ * Entry Type, APIC ID, Version,
+ * APIC Flags:EN, Address
+ */
+void smp_write_ioapic(struct mp_config_table *mc,
+	u8 id, u8 ver, void *apicaddr)
+{
+	struct mpc_config_ioapic *mpc;
+	mpc = smp_next_mpc_entry(mc);
+	memset(mpc, '\0', sizeof(*mpc));
+	mpc->mpc_type = MP_IOAPIC;
+	mpc->mpc_apicid = id;
+	mpc->mpc_apicver = ver;
+	mpc->mpc_flags = MPC_APIC_USABLE;
+	mpc->mpc_apicaddr = apicaddr;
+	smp_add_mpc_entry(mc, sizeof(*mpc));
+}
+
+u8 smp_write_ioapic_from_hw(struct mp_config_table *mc, void *apicaddr)
+{
+	u8 id = get_ioapic_id(apicaddr);
+	u8 ver = get_ioapic_version(apicaddr);
+	smp_write_ioapic(mc, id, ver, apicaddr);
+	return id;
+}
+
+/*
+ * Type 3: I/O Interrupt Table Entries:
+ * Entry Type, Int Type, Int Polarity, Int Level,
+ * Source Bus ID, Source Bus IRQ, Dest APIC ID, Dest PIN#
+ */
+void smp_write_intsrc(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag,
+	u8 srcbus, u8 srcbusirq,
+	u8 dstapic, u8 dstirq)
+{
+	struct mpc_config_intsrc *mpc;
+	mpc = smp_next_mpc_entry(mc);
+	memset(mpc, '\0', sizeof(*mpc));
+	mpc->mpc_type = MP_INTSRC;
+	mpc->mpc_irqtype = irqtype;
+	mpc->mpc_irqflag = irqflag;
+	mpc->mpc_srcbus = srcbus;
+	mpc->mpc_srcbusirq = srcbusirq;
+	mpc->mpc_dstapic = dstapic;
+	mpc->mpc_dstirq = dstirq;
+	smp_add_mpc_entry(mc, sizeof(*mpc));
+}
+
+/*
+ * Type 3: I/O Interrupt Table Entries for PCI Devices:
+ * This has the same fields as 'Type 3: I/O Interrupt Table Entries'
+ * but the Source Bus IRQ field has a slightly different
+ * definition:
+ * Bits 1-0: PIRQ pin: INT_A# = 0, INT_B# = 1, INT_C# = 2, INT_D# = 3
+ * Bits 2-6: Originating PCI Device Number (Not its parent bridge device number)
+ * Bit 7: Reserved
+ */
+void smp_write_pci_intsrc(struct mp_config_table *mc,
+	u8 irqtype, u8 srcbus, u8 dev, u8 pirq,
+	u8 dstapic, u8 dstirq)
+{
+	u8 srcbusirq = (dev << 2) | pirq;
+	printk(BIOS_SPEW,
+		"\tPCI srcbusirq = 0x%x from dev = 0x%x and pirq = %x\n",
+		srcbusirq, dev, pirq);
+	smp_write_intsrc(mc, irqtype, MP_IRQ_TRIGGER_LEVEL
+		| MP_IRQ_POLARITY_LOW, srcbus, srcbusirq, dstapic, dstirq);
+}
+
+void smp_write_intsrc_pci_bridge(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag, struct device *dev,
+	unsigned char dstapic, unsigned char *dstirq)
+{
+	struct device *child;
+
+	int i;
+	int srcbus;
+	int slot;
+
+	struct bus *link;
+	unsigned char dstirq_x[4];
+
+	for (link = dev->link_list; link; link = link->next) {
+
+		child = link->children;
+		srcbus = link->secondary;
+
+		while (child) {
+			if (child->path.type != DEVICE_PATH_PCI)
+				goto next;
+
+			slot = (child->path.pci.devfn >> 3);
+			/* round pins */
+			for (i = 0; i < 4; i++)
+				dstirq_x[i] = dstirq[(i + slot) % 4];
+
+			if ((child->class >> 16) != PCI_BASE_CLASS_BRIDGE) {
+				/* pci device */
+				printk(BIOS_DEBUG, "route irq: %s\n",
+					dev_path(child));
+				for (i = 0; i < 4; i++)
+					smp_write_intsrc(mc, irqtype, irqflag,
+						srcbus, (slot<<2)|i, dstapic,
+						dstirq_x[i]);
+				goto next;
+			}
+
+			switch (child->class>>8) {
+			case PCI_CLASS_BRIDGE_PCI:
+			case PCI_CLASS_BRIDGE_PCMCIA:
+			case PCI_CLASS_BRIDGE_CARDBUS:
+				printk(BIOS_DEBUG, "route irq bridge: %s\n",
+					dev_path(child));
+				smp_write_intsrc_pci_bridge(mc, irqtype,
+					irqflag, child, dstapic, dstirq_x);
+			}
+
+next:
+			child = child->sibling;
+		}
+
+	}
+}
+
+/*
+ * Type 4: Local Interrupt Assignment Entries:
+ * Entry Type, Int Type, Int Polarity, Int Level,
+ * Source Bus ID, Source Bus IRQ, Dest LAPIC ID,
+ * Dest LAPIC LINTIN#
+ */
+void smp_write_lintsrc(struct mp_config_table *mc,
+	u8 irqtype, u16 irqflag,
+	u8 srcbusid, u8 srcbusirq,
+	u8 destapic, u8 destapiclint)
+{
+	struct mpc_config_lintsrc *mpc;
+	mpc = smp_next_mpc_entry(mc);
+	memset(mpc, '\0', sizeof(*mpc));
+	mpc->mpc_type = MP_LINTSRC;
+	mpc->mpc_irqtype = irqtype;
+	mpc->mpc_irqflag = irqflag;
+	mpc->mpc_srcbusid = srcbusid;
+	mpc->mpc_srcbusirq = srcbusirq;
+	mpc->mpc_destapic = destapic;
+	mpc->mpc_destapiclint = destapiclint;
+	smp_add_mpc_entry(mc, sizeof(*mpc));
+}
+
+/*
+ * Type 128: System Address Space Mapping Entries
+ * Entry Type, Entry Length, Bus ID, Address Type,
+ * Address Base Lo/Hi, Address Length Lo/Hi
+ */
+void smp_write_address_space(struct mp_config_table *mc,
+	u8 busid, u8 address_type,
+	u32 address_base_low, u32 address_base_high,
+	u32 address_length_low, u32 address_length_high)
+{
+	struct mp_exten_system_address_space *mpe;
+	mpe = smp_next_mpe_entry(mc);
+	memset(mpe, '\0', sizeof(*mpe));
+	mpe->mpe_type = MPE_SYSTEM_ADDRESS_SPACE;
+	mpe->mpe_length = sizeof(*mpe);
+	mpe->mpe_busid = busid;
+	mpe->mpe_address_type = address_type;
+	mpe->mpe_address_base_low  = address_base_low;
+	mpe->mpe_address_base_high = address_base_high;
+	mpe->mpe_address_length_low  = address_length_low;
+	mpe->mpe_address_length_high = address_length_high;
+	smp_add_mpe_entry(mc, (mpe_t)mpe);
+}
+
+/*
+ * Type 129: Bus Hierarchy Descriptor Entry
+ * Entry Type, Entry Length, Bus ID, Bus Info,
+ * Parent Bus ID
+ */
+void smp_write_bus_hierarchy(struct mp_config_table *mc,
+	u8 busid, u8 bus_info, u8 parent_busid)
+{
+	struct mp_exten_bus_hierarchy *mpe;
+	mpe = smp_next_mpe_entry(mc);
+	memset(mpe, '\0', sizeof(*mpe));
+	mpe->mpe_type = MPE_BUS_HIERARCHY;
+	mpe->mpe_length = sizeof(*mpe);
+	mpe->mpe_busid = busid;
+	mpe->mpe_bus_info = bus_info;
+	mpe->mpe_parent_busid = parent_busid;
+	smp_add_mpe_entry(mc, (mpe_t)mpe);
+}
+
+/*
+ * Type 130: Compatibility Bus Address Space Modifier Entry
+ * Entry Type, Entry Length, Bus ID, Address Modifier
+ * Predefined Range List
+ */
+void smp_write_compatibility_address_space(struct mp_config_table *mc,
+	u8 busid, u8 address_modifier,
+	u32 range_list)
+{
+	struct mp_exten_compatibility_address_space *mpe;
+	mpe = smp_next_mpe_entry(mc);
+	memset(mpe, '\0', sizeof(*mpe));
+	mpe->mpe_type = MPE_COMPATIBILITY_ADDRESS_SPACE;
+	mpe->mpe_length = sizeof(*mpe);
+	mpe->mpe_busid = busid;
+	mpe->mpe_address_modifier = address_modifier;
+	mpe->mpe_range_list = range_list;
+	smp_add_mpe_entry(mc, (mpe_t)mpe);
+}
+
+void mptable_lintsrc(struct mp_config_table *mc, unsigned long bus_isa)
+{
+	smp_write_lintsrc(mc, mp_ExtINT, MP_IRQ_TRIGGER_EDGE
+		| MP_IRQ_POLARITY_HIGH, bus_isa, 0x0, MP_APIC_ALL, 0x0);
+	smp_write_lintsrc(mc, mp_NMI, MP_IRQ_TRIGGER_EDGE
+		| MP_IRQ_POLARITY_HIGH, bus_isa, 0x0, MP_APIC_ALL, 0x1);
+}
+
+void mptable_add_isa_interrupts(struct mp_config_table *mc,
+	unsigned long bus_isa, unsigned long apicid, int external_int2)
+{
+/*I/O Ints:		   Type	 Trigger	    Polarity
+ *				   Bus ID   IRQ  APIC ID   PIN# */
+	smp_write_intsrc(mc, external_int2?mp_INT:mp_ExtINT,
+				     MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x0, apicid, 0x0);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x1, apicid, 0x1);
+	smp_write_intsrc(mc, external_int2?mp_ExtINT:mp_INT,
+				     MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x0, apicid, 0x2);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x3, apicid, 0x3);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x4, apicid, 0x4);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x6, apicid, 0x6);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x7, apicid, 0x7);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x8, apicid, 0x8);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0x9, apicid, 0x9);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xa, apicid, 0xa);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xb, apicid, 0xb);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xc, apicid, 0xc);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xd, apicid, 0xd);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xe, apicid, 0xe);
+	smp_write_intsrc(mc, mp_INT, MP_IRQ_TRIGGER_EDGE | MP_IRQ_POLARITY_HIGH,
+				     bus_isa, 0xf, apicid, 0xf);
+}
+
+void mptable_write_buses(struct mp_config_table *mc, int *max_pci_bus,
+	int *isa_bus)
+{
+	int dummy, i, highest;
+	char buses[256];
+	struct device *dev;
+
+	if (!max_pci_bus)
+		max_pci_bus = &dummy;
+	if (!isa_bus)
+		isa_bus = &dummy;
+
+	*max_pci_bus = 0;
+	highest = 0;
+	memset(buses, 0, sizeof(buses));
+
+	for (dev = all_devices; dev; dev = dev->next) {
+		struct bus *bus;
+		for (bus = dev->link_list; bus; bus = bus->next) {
+			if (bus->secondary > 255) {
+				printk(BIOS_ERR,
+					"A bus claims to have a bus ID > 255?!? Aborting");
+				return;
+			}
+			buses[bus->secondary] = 1;
+			if (highest < bus->secondary)
+				highest = bus->secondary;
+		}
+	}
+	for (i = 0; i <= highest; i++) {
+		if (buses[i]) {
+			smp_write_bus(mc, i, "PCI   ");
+			*max_pci_bus = i;
+		}
+	}
+	*isa_bus = *max_pci_bus + 1;
+	smp_write_bus(mc, *isa_bus, "ISA   ");
+}
+
+void *mptable_finalize(struct mp_config_table *mc)
+{
+	mc->mpe_checksum = smp_compute_checksum(smp_next_mpc_entry(mc),
+		mc->mpe_length);
+	mc->mpc_checksum = smp_compute_checksum(mc, mc->mpc_length);
+	printk(BIOS_DEBUG, "Wrote the mp table end at: %p - %p\n",
+		mc, smp_next_mpe_entry(mc));
+	return smp_next_mpe_entry(mc);
+}
diff --git a/src/arch/486/null_breakpoint.c b/src/arch/486/null_breakpoint.c
new file mode 100644
index 0000000000..43e3727448
--- /dev/null
+++ b/src/arch/486/null_breakpoint.c
@@ -0,0 +1,73 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/breakpoint.h>
+#include <arch/null_breakpoint.h>
+#include <bootstate.h>
+#include <console/console.h>
+#include <types.h>
+
+static struct breakpoint_handle null_deref_bp;
+static struct breakpoint_handle null_fetch_bp;
+
+static int handle_fetch_breakpoint(struct breakpoint_handle handle, struct eregs *regs)
+{
+	printk(BIOS_ERR, "Instruction fetch from address zero\n");
+	return CONFIG(DEBUG_NULL_DEREF_HALT);
+}
+
+static int handle_deref_breakpoint(struct breakpoint_handle handle, struct eregs *regs)
+{
+#if ENV_X86_64
+	printk(BIOS_ERR, "Null dereference at rip: 0x%llx\n", regs->rip);
+#else
+	printk(BIOS_ERR, "Null dereference at eip: 0x%x\n", regs->eip);
+#endif
+	return CONFIG(DEBUG_NULL_DEREF_HALT);
+}
+
+static void create_deref_breakpoint(void)
+{
+	enum breakpoint_result res =
+		breakpoint_create_data(&null_deref_bp, NULL, sizeof(uintptr_t), false);
+
+	if (res != BREAKPOINT_RES_OK) {
+		printk(BIOS_ERR, "Failed to create NULL dereference breakpoint\n");
+		return;
+	}
+
+	breakpoint_set_handler(null_deref_bp, &handle_deref_breakpoint);
+	breakpoint_enable(null_deref_bp, true);
+}
+
+static void create_instruction_breakpoint(void)
+{
+	enum breakpoint_result res = breakpoint_create_instruction(&null_fetch_bp, NULL);
+
+	if (res != BREAKPOINT_RES_OK) {
+		printk(BIOS_ERR, "Failed to create address zero instruction fetch breakpoint\n");
+		return;
+	}
+
+	breakpoint_set_handler(null_fetch_bp, &handle_fetch_breakpoint);
+	breakpoint_enable(null_fetch_bp, true);
+}
+
+void null_breakpoint_init(void)
+{
+	create_deref_breakpoint();
+	create_instruction_breakpoint();
+}
+
+void null_breakpoint_disable(void)
+{
+	breakpoint_remove(null_fetch_bp);
+	breakpoint_remove(null_deref_bp);
+}
+
+static void null_breakpoint_disable_hook(void *unused)
+{
+	null_breakpoint_disable();
+}
+
+BOOT_STATE_INIT_ENTRY(BS_OS_RESUME, BS_ON_ENTRY, null_breakpoint_disable_hook, NULL);
+BOOT_STATE_INIT_ENTRY(BS_PAYLOAD_BOOT, BS_ON_ENTRY, null_breakpoint_disable_hook, NULL);
diff --git a/src/arch/486/pirq_routing.c b/src/arch/486/pirq_routing.c
new file mode 100644
index 0000000000..9b2da4e228
--- /dev/null
+++ b/src/arch/486/pirq_routing.c
@@ -0,0 +1,208 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+#include <arch/pirq_routing.h>
+#include <commonlib/helpers.h>
+#include <console/console.h>
+#include <device/pci.h>
+#include <string.h>
+#include <types.h>
+
+void __weak pirq_assign_irqs(const unsigned char pirq[CONFIG_MAX_PIRQ_LINKS])
+{
+}
+
+static void check_pirq_routing_table(struct irq_routing_table *rt)
+{
+	uint8_t *addr = (uint8_t *)rt;
+	uint8_t sum = 0;
+	int i;
+
+	printk(BIOS_INFO, "Checking Interrupt Routing Table consistency...\n");
+
+	if (sizeof(struct irq_routing_table) != rt->size) {
+		printk(BIOS_WARNING,
+			"Inconsistent Interrupt Routing Table size (0x%x/0x%x).\n",
+			(unsigned int)sizeof(struct irq_routing_table),
+			rt->size);
+		rt->size = sizeof(struct irq_routing_table);
+	}
+
+	for (i = 0; i < rt->size; i++)
+		sum += addr[i];
+
+	printk(BIOS_DEBUG, "%s(): Interrupt Routing Table located at %p.\n",
+		     __func__, addr);
+
+	sum = rt->checksum - sum;
+
+	if (sum != rt->checksum) {
+		printk(BIOS_WARNING,
+			"Interrupt Routing Table checksum is: 0x%02x but should be: 0x%02x, fixing.\n",
+			rt->checksum, sum);
+		rt->checksum = sum;
+	}
+
+	if (rt->signature != PIRQ_SIGNATURE || rt->version != PIRQ_VERSION ||
+	    rt->size % 16) {
+		printk(BIOS_WARNING, "Interrupt Routing Table not valid.\n");
+		return;
+	}
+
+	sum = 0;
+	for (i = 0; i < rt->size; i++)
+		sum += addr[i];
+
+	/* We're manually fixing the checksum above. This warning can probably
+	 * never happen because if the target location is read-only this
+	 * function would have bailed out earlier.
+	 */
+	if (sum) {
+		printk(BIOS_WARNING, "Checksum error in Interrupt Routing Table "
+				"could not be fixed.\n");
+	}
+
+	printk(BIOS_INFO, "done.\n");
+}
+
+static enum cb_err verify_copy_pirq_routing_table(unsigned long addr,
+	const struct irq_routing_table *routing_table)
+{
+	int i;
+	uint8_t *rt_orig, *rt_curr;
+
+	rt_curr = (uint8_t *)addr;
+	rt_orig = (uint8_t *)routing_table;
+	printk(BIOS_INFO,
+		"Verifying copy of Interrupt Routing Table at 0x%08lx... ",
+		addr);
+	for (i = 0; i < routing_table->size; i++) {
+		if (*(rt_curr + i) != *(rt_orig + i)) {
+			printk(BIOS_INFO, "failed\n");
+			return CB_ERR;
+		}
+	}
+	printk(BIOS_INFO, "done\n");
+
+	check_pirq_routing_table((struct irq_routing_table *)addr);
+
+	return CB_SUCCESS;
+}
+
+static u8 pirq_get_next_free_irq(u8 *pirq, u16 bitmap)
+{
+	int i, link;
+	u8 irq = 0;
+	for (i = 2; i <= 15; i++) {
+		/* Can we assign this IRQ ? */
+		if (!((bitmap >> i) & 1))
+			continue;
+		/* We can, Now let's assume we can use this IRQ */
+		irq = i;
+		/* And assume we have not yet routed it */
+		int already_routed = 0;
+		/* Have we already routed it ? */
+		for (link = 0; link < CONFIG_MAX_PIRQ_LINKS; link++) {
+			if (pirq[link] == irq) {
+				already_routed = 1;
+				break;
+			}
+		}
+		/* If it's not yet routed, use it */
+		if (!already_routed)
+			break;
+	}
+	/* Now we got our IRQ */
+	return irq;
+}
+
+static void pirq_route_irqs(unsigned long addr)
+{
+	int i, intx, num_entries;
+	unsigned char irq_slot[MAX_INTX_ENTRIES];
+	unsigned char pirq[CONFIG_MAX_PIRQ_LINKS];
+	struct irq_routing_table *pirq_tbl;
+
+	memset(pirq, 0, CONFIG_MAX_PIRQ_LINKS);
+
+	pirq_tbl = (struct irq_routing_table *)(addr);
+	num_entries = (pirq_tbl->size - 32) / 16;
+
+	/* Set PCI IRQs. */
+	for (i = 0; i < num_entries; i++) {
+
+		u8 bus = pirq_tbl->slots[i].bus;
+		u8 devfn = pirq_tbl->slots[i].devfn;
+
+		printk(BIOS_DEBUG, "PIRQ Entry %d Dev/Fn: %X Slot: %d\n", i,
+			devfn >> 3, pirq_tbl->slots[i].slot);
+
+		for (intx = 0; intx < MAX_INTX_ENTRIES; intx++) {
+
+			int link = pirq_tbl->slots[i].irq[intx].link;
+			int bitmap = pirq_tbl->slots[i].irq[intx].bitmap;
+			int irq = 0;
+
+			printk(BIOS_DEBUG, "INT: %c link: %x bitmap: %x  ",
+				'A' + intx, link, bitmap);
+
+			if (!bitmap || !link || link > CONFIG_MAX_PIRQ_LINKS) {
+
+				printk(BIOS_DEBUG, "not routed\n");
+				irq_slot[intx] = irq;
+				continue;
+			}
+
+			/* yet not routed */
+			if (!pirq[link - 1]) {
+				irq = pirq_get_next_free_irq(pirq, bitmap);
+				if (irq)
+					pirq[link - 1] = irq;
+			} else
+				irq = pirq[link - 1];
+
+			printk(BIOS_DEBUG, "IRQ: %d\n", irq);
+			irq_slot[intx] = irq;
+		}
+
+		/* Bus, device, slots IRQs for {A,B,C,D}. */
+		pci_assign_irqs(pcidev_path_on_bus(bus, devfn), irq_slot);
+	}
+
+	for (i = 0; i < CONFIG_MAX_PIRQ_LINKS; i++)
+		printk(BIOS_DEBUG, "PIRQ%c: %d\n", i + 'A', pirq[i]);
+
+	pirq_assign_irqs(pirq);
+}
+
+unsigned long copy_pirq_routing_table(unsigned long addr,
+	const struct irq_routing_table *routing_table)
+{
+	// asm volatile("rdtsc" :::);
+
+#if 0	//nemazat, resp ulozit snippet
+	void* current_address;
+	asm volatile(
+		"call get_eip\n\t"
+		"get_eip:\n\t"
+		"pop %%eax\n\t"
+		"movl %%eax, %0\n\t"
+		: "=r" (current_address)::"%eax"
+	);
+	printk(BIOS_INFO, "******XXXX current address: %p\n", current_address);
+#endif
+
+	/* Align the table to be 16 byte aligned. */
+	addr = ALIGN_UP(addr, 16);
+
+	/* This table must be between 0xf0000 & 0x100000 */
+	printk(BIOS_INFO, "Copying Interrupt Routing Table to 0x%08lx-0x%08lx... ",
+		addr, addr + routing_table->size);
+	memcpy((void *)addr, routing_table, routing_table->size);
+	printk(BIOS_INFO, "done.\n");
+	if (CONFIG(DEBUG_PIRQ))
+		verify_copy_pirq_routing_table(addr, routing_table);
+	if (CONFIG(PIRQ_ROUTE))
+		pirq_route_irqs(addr);
+
+	return addr + routing_table->size;
+}
diff --git a/src/arch/486/post.c b/src/arch/486/post.c
new file mode 100644
index 0000000000..908cc3bd36
--- /dev/null
+++ b/src/arch/486/post.c
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/io.h>
+#include <console/console.h>
+#include <post.h>
+#include <stdint.h>
+
+void arch_post_code(uint8_t value)
+{
+	if (CONFIG(POST_IO))
+		outb(value, CONFIG_POST_IO_PORT);
+
+	if (CONFIG(CMOS_POST) && !ENV_SMM)
+		cmos_post_code(value);
+}
diff --git a/src/arch/486/postcar.c b/src/arch/486/postcar.c
new file mode 100644
index 0000000000..f02dfddfa9
--- /dev/null
+++ b/src/arch/486/postcar.c
@@ -0,0 +1,53 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/romstage.h>
+#include <cbmem.h>
+#include <console/console.h>
+#include <main_decl.h>
+#include <program_loading.h>
+#include <timestamp.h>
+
+/*
+ * Systems without a native coreboot cache-as-ram teardown may implement
+ * this to use an alternate method.
+ */
+__weak void late_car_teardown(void) { /* do nothing */ }
+
+//NOTICE called from exit_car.S, right after enabling L1 cache in CR0
+void main(void)
+{
+	late_car_teardown();
+
+	console_init();
+
+printk(BIOS_DEBUG, "=+=+=+=+ postcar main %p\n", main);
+
+	/*
+	 * CBMEM needs to be recovered because timestamps rely on
+	 * the cbmem infrastructure being around. Explicitly recover it.
+	 *
+	 * On some platforms CBMEM needs to be initialized earlier.
+	 * Use cbmem_online() to avoid init CBMEM twice.
+	 */
+	if (!cbmem_online()) {
+		// printk(BIOS_DEBUG, "TODO cbmem_initialize\n");
+		cbmem_initialize();
+	}
+
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+
+	timestamp_add_now(TS_POSTCAR_START);
+
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+	// asm volatile("rdtsc" :::);
+
+printk(BIOS_DEBUG, "postcar before run ramstage\n");
+
+	/* Load and run ramstage. */
+	run_ramstage();
+}
diff --git a/src/arch/486/postcar_loader.c b/src/arch/486/postcar_loader.c
new file mode 100644
index 0000000000..f6e0a5c90a
--- /dev/null
+++ b/src/arch/486/postcar_loader.c
@@ -0,0 +1,153 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/romstage.h>
+#include <cbmem.h>
+#include <console/console.h>
+#include <program_loading.h>
+#include <reset.h>
+#include <rmodule.h>
+#include <stage_cache.h>
+#include <timestamp.h>
+#include <types.h>
+
+
+//temp, for dump
+#include <device/pci_ops.h>
+#include <northbridge/umc/um8881/reg_init.h>
+
+
+static void run_postcar_phase(void);
+
+/* prepare_and_run_postcar() determines the stack to use after
+ * cache-as-ram is torn down as well as the MTRR settings to use. */
+void __noreturn prepare_and_run_postcar(void)
+{
+	printk(BIOS_DEBUG, "prepare_and_run_postcar\n");
+
+	run_postcar_phase();
+	/* We do not return here. */
+	die("Failed to load postcar\n!");
+}
+
+static void load_postcar_cbfs(struct prog *prog)
+{
+	struct rmod_stage_load rsl = {
+		.cbmem_id = CBMEM_ID_AFTER_CAR,
+		.prog = prog,
+	};
+
+	printk(BIOS_NOTICE, "load_postcar_cbfs {\n");
+
+	if (rmodule_stage_load(&rsl))
+		die_with_post_code(POST_INVALID_ROM,
+				   "Failed to load after CAR program.\n");
+
+	printk(BIOS_NOTICE, "S2\n");
+
+	stage_cache_add(STAGE_POSTCAR, prog);
+
+	printk(BIOS_NOTICE, "load_postcar_cbfs }\n");
+
+
+#if 0
+
+	//pc2005 !!!!! TODO
+
+	printk(BIOS_DEBUG, "dump HB:\n");
+	for (unsigned idx=0;idx<0x63;idx++) {
+		if ((idx % 16) == 0) {
+			printk(BIOS_DEBUG, "%02x: ", idx);
+		}
+		printk(BIOS_DEBUG, "%02hhx ",
+		       pci_read_config8(HOST_BRIDGE, idx)
+		);
+		if (((idx % 16) == 15) || (idx == (0x63-1))) {
+			printk(BIOS_DEBUG, "\n");
+		}
+	}
+
+	printk(BIOS_DEBUG, "dump IBC:\n");
+	for (unsigned idx=0;idx<0xb0;idx++) {
+		if ((idx % 16) == 0) {
+			printk(BIOS_DEBUG, "%02x: ", idx);
+		}
+		printk(BIOS_DEBUG, "%02hhx ",
+		       pci_read_config8(ISA_BRIDGE, idx)
+		);
+		if (((idx % 16) == 15) || (idx == (0xb0-1))) {
+			printk(BIOS_DEBUG, "\n");
+		}
+	}
+#endif
+
+}
+
+/*
+ * Cache the TSEG region at the top of ram. This region is
+ * not restricted to SMM mode until SMM has been relocated.
+ * By setting the region to cacheable it provides faster access
+ * when relocating the SMM handler as well as using the TSEG
+ * region for other purposes.
+ */
+void postcar_enable_tseg_cache(void)
+{
+	// uintptr_t smm_base;
+	// size_t smm_size;
+//
+	// smm_region(&smm_base, &smm_size);
+}
+
+static void postcar_cache_invalid(void)
+{
+	printk(BIOS_ERR, "postcar cache invalid.\n");
+	board_reset();
+}
+
+static void run_postcar_phase(void)
+{
+	struct prog prog =
+		PROG_INIT(PROG_POSTCAR, CONFIG_CBFS_PREFIX "/postcar");
+
+// printk(BIOS_DEBUG, "M1\n");
+#if 0
+printk(BIOS_DEBUG, "0x500 table: ");
+for (unsigned idx=0;idx<40;idx++) {
+	u8 * dptr = (u8 *)0x500;
+	printk(BIOS_DEBUG, "%02x ", dptr[idx]);
+}
+printk(BIOS_DEBUG, "\n");
+#endif
+	if (resume_from_stage_cache()) {
+
+// printk(BIOS_DEBUG, "M2\n");
+
+		stage_cache_load_stage(STAGE_POSTCAR, &prog);
+		/* This is here to allow platforms to pass different stack
+		   parameters between S3 resume and normal boot. On the
+		   platforms where the values are the same it's a nop. */
+
+		// printk(BIOS_DEBUG, "M3\n");
+
+		if (prog_entry(&prog) == NULL)
+			postcar_cache_invalid();
+
+		// printk(BIOS_DEBUG, "M5\n");
+
+	} else
+		load_postcar_cbfs(&prog);
+
+	// printk(BIOS_DEBUG, "M6\n");
+
+	/* As postcar exist, it's end of romstage here */
+	// timestamp_add_now(TS_ROMSTAGE_END);
+
+	console_time_report();
+
+	// printk(BIOS_DEBUG, "M7 cbmem_top() %p\n", cbmem_top());
+
+	prog_set_arg(&prog, cbmem_top());
+
+	// printk(BIOS_DEBUG, "M8\n");
+
+	prog_run(&prog);
+}
diff --git a/src/arch/486/romstage.c b/src/arch/486/romstage.c
new file mode 100644
index 0000000000..a7ee4d99b4
--- /dev/null
+++ b/src/arch/486/romstage.c
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/cpu.h>
+#include <console/console.h>
+#include <timestamp.h>
+#include <romstage_common.h>
+
+asmlinkage void car_stage_entry(void)
+{
+	timestamp_add_now(TS_ROMSTAGE_START);
+
+	/* Assumes the hardware was set up during the bootblock */
+	console_init();
+
+	romstage_main();
+}
diff --git a/src/arch/486/smbios.c b/src/arch/486/smbios.c
new file mode 100644
index 0000000000..1ab219bbc7
--- /dev/null
+++ b/src/arch/486/smbios.c
@@ -0,0 +1,1528 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <assert.h>
+#include <string.h>
+#include <smbios.h>
+#include <console/console.h>
+#include <version.h>
+#include <device/device.h>
+#include <device/dram/spd.h>
+#include <arch/cpu.h>
+#include <cpu/486/name.h>
+#include <elog.h>
+#include <endian.h>
+#include <memory_info.h>
+#include <spd.h>
+#include <cbmem.h>
+#include <commonlib/helpers.h>
+#include <device/pci_ids.h>
+#include <device/pci.h>
+#include <drivers/vpd/vpd.h>
+#include <stdlib.h>
+
+#define update_max(len, max_len, stmt)		\
+	do {					\
+		int tmp = stmt;			\
+						\
+		max_len = MAX(max_len, tmp);	\
+		len += tmp;			\
+	} while (0)
+
+static u8 smbios_checksum(u8 *p, u32 length)
+{
+	u8 ret = 0;
+	while (length--)
+		ret += *p++;
+	return -ret;
+}
+
+int smbios_add_string(u8 *start, const char *str)
+{
+	int i = 1;
+	char *p = (char *)start;
+
+	/*
+	 * Return 0 as required for empty strings.
+	 * See Section 6.1.3 "Text Strings" of the SMBIOS specification.
+	 */
+	if (*str == '\0')
+		return 0;
+
+	for (;;) {
+		if (!*p) {
+			strcpy(p, str);
+			p += strlen(str);
+			*p++ = '\0';
+			*p++ = '\0';
+			return i;
+		}
+
+		if (!strcmp(p, str))
+			return i;
+
+		p += strlen(p)+1;
+		i++;
+	}
+}
+
+int smbios_string_table_len(u8 *start)
+{
+	char *p = (char *)start;
+	int i, len = 0;
+
+	while (*p) {
+		i = strlen(p) + 1;
+		p += i;
+		len += i;
+	}
+
+	if (!len)
+		return 2;
+
+	return len + 1;
+}
+
+int smbios_full_table_len(struct smbios_header *header, u8 *str_table_start)
+{
+	return header->length + smbios_string_table_len(str_table_start);
+}
+
+void *smbios_carve_table(unsigned long start, u8 type, u8 length, u16 handle)
+{
+	struct smbios_header *t = (struct smbios_header *)start;
+
+	assert(length >= sizeof(*t));
+	memset(t, 0, length);
+	t->type = type;
+	t->length = length - 2;
+	t->handle = handle;
+	return t;
+}
+
+static int smbios_cpu_vendor(u8 *start)
+{
+	if (cpu_have_cpuid()) {
+		u32 tmp[4];
+		const struct cpuid_result res = cpuid(0);
+		tmp[0] = res.ebx;
+		tmp[1] = res.edx;
+		tmp[2] = res.ecx;
+		tmp[3] = 0;
+		return smbios_add_string(start, (const char *)tmp);
+	} else {
+		return smbios_add_string(start, "Unknown");
+	}
+}
+
+static int smbios_processor_name(u8 *start)
+{
+	// u32 tmp[13];
+	const char *str = "Am5x86-133";
+	return smbios_add_string(start, str);
+}
+
+
+static void trim_trailing_whitespace(char *buffer, size_t buffer_size)
+{
+	size_t len = strnlen(buffer, buffer_size);
+
+	if (len == 0)
+		return;
+
+	for (char *p = buffer + len - 1; p >= buffer; --p) {
+		if (*p == ' ')
+			*p = 0;
+		else
+			break;
+	}
+}
+
+
+////////////////////
+
+
+/** This function will fill the corresponding part number */
+static void smbios_fill_simm_part_number(const char *part_number, struct smbios_type17 *t)
+{
+	int invalid;
+	size_t i, len;
+	char trimmed_part_number[DIMM_INFO_PART_NUMBER_SIZE];
+
+	strncpy(trimmed_part_number, part_number, sizeof(trimmed_part_number));
+	trimmed_part_number[sizeof(trimmed_part_number) - 1] = '\0';
+
+	/*
+	 * SPD mandates that unused characters be represented with a ' '.
+	 * We don't want to publish the whitespace in the SMBIOS tables.
+	 */
+	trim_trailing_whitespace(trimmed_part_number, sizeof(trimmed_part_number));
+
+	len = strlen(trimmed_part_number);
+
+	invalid = 0; /* assume valid */
+	for (i = 0; i < len; i++) {
+		if (trimmed_part_number[i] < ' ') {
+			invalid = 1;
+			trimmed_part_number[i] = '*';
+		}
+	}
+
+	if (len == 0) {
+		/* Null String in Part Number will have "None" instead. */
+		t->part_number = smbios_add_string(t->eos, "None");
+	} else if (invalid) {
+		char string_buffer[sizeof(trimmed_part_number) + 10];
+
+		snprintf(string_buffer, sizeof(string_buffer), "Invalid (%s)",
+			 trimmed_part_number);
+		t->part_number = smbios_add_string(t->eos, string_buffer);
+	} else {
+		t->part_number = smbios_add_string(t->eos, trimmed_part_number);
+	}
+}
+
+#if 0
+static void smbios_fill_simm_serial_number(struct smbios_type17 *t)
+{
+	char serial[9];
+
+	snprintf(serial, sizeof(serial), "%02hhx%02hhx%02hhx%02hhx",
+		 0x12, 0x34, 0x56, 0x78);
+
+	t->serial_number = smbios_add_string(t->eos, serial);
+}
+
+/* this function will fill the corresponding manufacturer */
+static void smbios_fill_simm_manufacturer(struct smbios_type17 *t)
+{
+	char string_buffer[256];
+
+	snprintf(string_buffer, sizeof(string_buffer), "N/A");
+	t->manufacturer = smbios_add_string(t->eos, string_buffer);
+}
+#endif
+
+
+unsigned get_bank_size_mb(unsigned char slot);
+bool get_bank_double_sided(unsigned char slot);
+
+
+#define TYPE_DRAM	0x3
+#define FORM_SIMM	0x3
+
+static int create_smbios_type17_for_simm(
+	unsigned long *current,
+	int *handle,
+	int type16_handle,
+	unsigned char slot
+)
+{
+	struct smbios_type17 *t = smbios_carve_table(
+		*current,
+		SMBIOS_MEMORY_DEVICE,
+		sizeof(*t),
+		*handle
+	);
+
+	t->memory_type = TYPE_DRAM;
+	t->clock_speed = 0;	//unknown (you would need benchmark)
+	t->speed = 0;		//unknown (you would need benchmark)
+
+	//TODO device_set member of pair
+
+	//in MiB
+	t->size = (0<<15) | get_bank_size_mb(slot);	//32MB
+
+	t->data_width = 32;	//32bit simm TODO parity?
+	t->total_width = 32;	//32bit simm TODO parity?
+	t->form_factor = FORM_SIMM;
+
+	//TODO
+
+	char dev_loc[16];
+	snprintf(dev_loc, sizeof(dev_loc), "SIMM %u", slot);
+	t->device_locator = smbios_add_string(t->eos, dev_loc);
+
+	//TODO !!!
+	char bank_loc[16];
+	snprintf(bank_loc, sizeof(bank_loc), "Region TODO %u", slot);
+	t->bank_locator = smbios_add_string(t->eos, bank_loc);
+
+	/* put '\0' in the end of data */
+	smbios_fill_simm_part_number("N/A", t);
+
+	/* Voltage Levels */
+	t->configured_voltage = 0;
+	t->minimum_voltage = 3300;
+	t->maximum_voltage = 5000;
+
+	/* Fill in type detail */
+	t->type_detail =
+		MEMORY_TYPE_DETAIL_EDO |
+		MEMORY_TYPE_DETAIL_FAST_PAGED;
+
+	/* no handle for error information */
+	t->memory_error_information_handle = 0xFFFE;
+
+	//1:single sided, 2:double sided, 0:unknown
+	if (get_bank_double_sided(slot)) {
+		t->attributes = 2;
+	} else {
+		t->attributes = 1;
+	}
+
+	t->phys_memory_array_handle = type16_handle;
+
+	*handle += 1;
+	return smbios_full_table_len(&t->header, t->eos);
+}
+
+static int create_smbios_type17_for_empty_slot(
+	unsigned long *current,
+	int *handle,
+	int type16_handle,
+	unsigned char slot
+)
+{
+	struct smbios_type17 *t = smbios_carve_table(*current, SMBIOS_MEMORY_DEVICE,
+						     sizeof(*t), *handle);
+	t->phys_memory_array_handle = type16_handle;
+	/* no handle for error information */
+	t->memory_error_information_handle = 0xfffe;
+	t->total_width = 0xffff; /* Unknown */
+	t->data_width = 0xffff; /* Unknown */
+	t->form_factor = 0x2; /* Unknown */
+
+	char dev_loc[16];
+	snprintf(dev_loc, sizeof(dev_loc), "SIMM %u", slot);
+	t->device_locator = smbios_add_string(t->eos, dev_loc);
+
+	t->bank_locator = 0;
+	t->memory_type = 0x2; /* Unknown */
+	t->type_detail = 0x2; /* Unknown */
+
+	*handle += 1;
+	return smbios_full_table_len(&t->header, t->eos);
+}
+
+#define VERSION_VPD "firmware_version"
+static const char *vpd_get_bios_version(void)
+{
+	int size;
+	const char *s;
+	char *version;
+
+	s = vpd_find(VERSION_VPD, &size, VPD_RO);
+	if (!s) {
+		printk(BIOS_ERR, "Find version from VPD %s failed\n", VERSION_VPD);
+		return NULL;
+	}
+
+	version = malloc(size + 1);
+	if (!version) {
+		printk(BIOS_ERR, "Failed to malloc %d bytes for VPD version\n", size + 1);
+		return NULL;
+	}
+	memcpy(version, s, size);
+	version[size] = '\0';
+	printk(BIOS_DEBUG, "Firmware version %s from VPD %s\n", version, VERSION_VPD);
+	return version;
+}
+
+static const char *get_bios_version(void)
+{
+	const char *s;
+
+#define SPACES \
+	"								  "
+
+	if (CONFIG(CHROMEOS))
+		return SPACES;
+
+	if (CONFIG(VPD_SMBIOS_VERSION)) {
+		s = vpd_get_bios_version();
+		if (s != NULL)
+			return s;
+	}
+
+	s = smbios_mainboard_bios_version();
+	if (s != NULL)
+		return s;
+
+	if (strlen(CONFIG_LOCALVERSION) != 0) {
+		printk(BIOS_DEBUG, "BIOS version set to CONFIG_LOCALVERSION: '%s'\n",
+			CONFIG_LOCALVERSION);
+		return CONFIG_LOCALVERSION;
+	}
+
+	printk(BIOS_DEBUG, "SMBIOS firmware version is set to coreboot_version: '%s'\n",
+		coreboot_version);
+	return coreboot_version;
+}
+
+static int smbios_write_type0(unsigned long *current, int handle)
+{
+	struct smbios_type0 *t = smbios_carve_table(*current, SMBIOS_BIOS_INFORMATION,
+						    sizeof(*t), handle);
+
+	t->vendor = smbios_add_string(t->eos, "coreboot");
+	t->bios_release_date = smbios_add_string(t->eos, coreboot_dmi_date);
+
+	if (CONFIG(CHROMEOS_NVS)) {
+		uintptr_t version_address = (uintptr_t)t->eos;
+		/* SMBIOS offsets start at 1 rather than 0 */
+		version_address += (u32)smbios_string_table_len(t->eos) - 1;
+		smbios_type0_bios_version(version_address);
+	}
+	t->bios_version = smbios_add_string(t->eos, get_bios_version());
+	uint32_t rom_size = CONFIG_ROM_SIZE;
+	rom_size = MIN(CONFIG_ROM_SIZE, 16 * MiB);
+	t->bios_rom_size = (rom_size / 65535) - 1;
+
+	if (CONFIG_ROM_SIZE >= 1 * GiB)
+		t->extended_bios_rom_size = DIV_ROUND_UP(CONFIG_ROM_SIZE, GiB) | (1 << 14);
+	else
+		t->extended_bios_rom_size = DIV_ROUND_UP(CONFIG_ROM_SIZE, MiB);
+
+	t->system_bios_major_release = coreboot_major_revision;
+	t->system_bios_minor_release = coreboot_minor_revision;
+
+	smbios_ec_revision(&t->ec_major_release, &t->ec_minor_release);
+
+	//TODO on some boards BIOS_CHARACTERISTICS_VLBUS_SUPPORTED
+	//ESCD ?? https://en.wikipedia.org/wiki/Extended_System_Configuration_Data
+
+	t->bios_characteristics =
+		BIOS_CHARACTERISTICS_ISA_SUPPORTED |
+		BIOS_CHARACTERISTICS_PCI_SUPPORTED |
+		BIOS_CHARACTERISTICS_SHADOW |	//???
+		BIOS_CHARACTERISTICS_BOOT_FROM_CD | //depends on seabios
+		BIOS_CHARACTERISTICS_SELECTABLE_BOOT | //depends on seabios
+		BIOS_CHARACTERISTICS_BIOS_SOCKETED | //depends on motherboard
+		BIOS_CHARACTERISTICS_EDD_SUPPORTED | //seabios supports EDD
+		BIOS_CHARACTERISTICS_UPGRADEABLE;
+
+	t->bios_characteristics |= BIOS_CHARACTERISTICS_FDD_525_360K_SUPPORTED;
+	t->bios_characteristics |= BIOS_CHARACTERISTICS_FDD_525_1M2_SUPPORTED;
+	t->bios_characteristics |= BIOS_CHARACTERISTICS_FDD_35_720K_SUPPORTED;
+	t->bios_characteristics |= BIOS_CHARACTERISTICS_FDD_35_2M88_SUPPORTED;
+
+	//NOTICE PCI->pccard bridge obviously supported
+	//also ISA
+	if (CONFIG(CARDBUS_PLUGIN_SUPPORT))
+		t->bios_characteristics |= BIOS_CHARACTERISTICS_PC_CARD;
+
+	if (CONFIG(HAVE_ACPI_TABLES))
+		t->bios_characteristics_ext1 = BIOS_EXT1_CHARACTERISTICS_ACPI;
+
+	t->bios_characteristics_ext2 = BIOS_EXT2_CHARACTERISTICS_TARGET;
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+static int get_socket_type(void)
+{
+	if (CONFIG(CPU_INTEL_SLOT_1))
+		return PROCESSOR_UPGRADE_SLOT_1;
+	if (CONFIG(CPU_INTEL_SOCKET_MPGA604))
+		return PROCESSOR_UPGRADE_SOCKET_MPGA604;
+	if (CONFIG(CPU_INTEL_SOCKET_LGA775))
+		return PROCESSOR_UPGRADE_SOCKET_LGA775;
+	if (CONFIG(SOC_INTEL_ALDERLAKE))
+		return PROCESSOR_UPGRADE_SOCKET_LGA1700;
+	if (CONFIG(SOC_INTEL_SKYLAKE_SP))
+		return PROCESSOR_UPGRADE_SOCKET_LGA3647_1;
+	if (CONFIG(SOC_INTEL_COOPERLAKE_SP))
+		return PROCESSOR_UPGRADE_SOCKET_LGA4189;
+	if (CONFIG(SOC_INTEL_SAPPHIRERAPIDS_SP))
+		return PROCESSOR_UPGRADE_SOCKET_LGA4677;
+	if (CONFIG(CPU_486))
+		return PROCESSOR_UPGRADE_ZIF_SOCKET;
+
+	return PROCESSOR_UPGRADE_UNKNOWN;
+}
+
+unsigned int __weak smbios_processor_external_clock(void)
+{
+	return 0; /* Unknown */
+}
+
+unsigned int __weak smbios_processor_characteristics(void)
+{
+	return 0;
+}
+
+unsigned int __weak smbios_processor_family(struct cpuid_result res)
+{
+	if (((res.eax >> 8) & 0xf) == 4) {
+		return 6;
+	}
+
+	return 6;
+	// return (res.eax > 0) ? 0x0c : 0x6;
+}
+
+unsigned int __weak smbios_cache_error_correction_type(u8 level)
+{
+	return SMBIOS_CACHE_ERROR_CORRECTION_UNKNOWN;
+}
+
+unsigned int __weak smbios_cache_sram_type(void)
+{
+	return  SMBIOS_CACHE_SRAM_TYPE_UNKNOWN;
+}
+
+unsigned int __weak smbios_cache_conf_operation_mode(u8 level)
+{
+	return SMBIOS_CACHE_OP_MODE_UNKNOWN; /* Unknown */
+}
+
+/* Returns the processor voltage in 100mV units */
+unsigned int __weak smbios_cpu_get_voltage(void)
+{
+	return 0; /* Unknown */
+}
+
+static size_t get_number_of_caches(size_t max_logical_cpus_sharing_cache)
+{
+	size_t number_of_cpus_per_package = 0;
+	size_t max_logical_cpus_per_package = 0;
+	struct cpuid_result res;
+
+	if (!cpu_have_cpuid())
+		return 1;
+
+	res = cpuid(1);
+
+	max_logical_cpus_per_package = (res.ebx >> 16) & 0xff;
+
+	/* Check if it's last level cache */
+	if (max_logical_cpus_sharing_cache == max_logical_cpus_per_package)
+		return 1;
+
+	if (cpuid_get_max_func() >= 0xb) {
+		res = cpuid_ext(0xb, 1);
+		number_of_cpus_per_package = res.ebx & 0xff;
+	} else {
+		number_of_cpus_per_package = max_logical_cpus_per_package;
+	}
+
+	return number_of_cpus_per_package / max_logical_cpus_sharing_cache;
+}
+
+static int smbios_write_type1(unsigned long *current, int handle)
+{
+	struct smbios_type1 *t = smbios_carve_table(*current, SMBIOS_SYSTEM_INFORMATION,
+						    sizeof(*t), handle);
+
+	t->manufacturer = smbios_add_string(t->eos, smbios_system_manufacturer());
+	t->product_name = smbios_add_string(t->eos, smbios_system_product_name());
+	t->serial_number = smbios_add_string(t->eos, smbios_system_serial_number());
+	t->wakeup_type = smbios_system_wakeup_type();
+	t->sku = smbios_add_string(t->eos, smbios_system_sku());
+	t->version = smbios_add_string(t->eos, smbios_system_version());
+#ifdef CONFIG_MAINBOARD_FAMILY
+	t->family = smbios_add_string(t->eos, CONFIG_MAINBOARD_FAMILY);
+#endif
+	smbios_system_set_uuid(t->uuid);
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+static int smbios_write_type2(unsigned long *current, int handle, const int chassis_handle)
+{
+	struct smbios_type2 *t = smbios_carve_table(*current, SMBIOS_BOARD_INFORMATION,
+						    sizeof(*t), handle);
+
+	t->manufacturer = smbios_add_string(t->eos, smbios_mainboard_manufacturer());
+	t->product_name = smbios_add_string(t->eos, smbios_mainboard_product_name());
+	t->serial_number = smbios_add_string(t->eos, smbios_mainboard_serial_number());
+	t->version = smbios_add_string(t->eos, smbios_mainboard_version());
+	t->asset_tag = smbios_add_string(t->eos, smbios_mainboard_asset_tag());
+	t->feature_flags = smbios_mainboard_feature_flags();
+	t->location_in_chassis = smbios_add_string(t->eos,
+		smbios_mainboard_location_in_chassis());
+	t->board_type = smbios_mainboard_board_type();
+	t->chassis_handle = chassis_handle;
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+static int smbios_write_type3(unsigned long *current, int handle)
+{
+	struct smbios_type3 *t = smbios_carve_table(*current, SMBIOS_SYSTEM_ENCLOSURE,
+						    sizeof(*t), handle);
+
+	t->manufacturer = smbios_add_string(t->eos, smbios_system_manufacturer());
+	t->bootup_state = SMBIOS_STATE_SAFE;
+	t->power_supply_state = SMBIOS_STATE_SAFE;
+	t->thermal_state = SMBIOS_STATE_SAFE;
+	t->_type = smbios_mainboard_enclosure_type();
+	t->security_status = SMBIOS_STATE_SAFE;
+	t->number_of_power_cords = smbios_chassis_power_cords();
+	t->asset_tag_number = smbios_add_string(t->eos, smbios_mainboard_asset_tag());
+	t->version = smbios_add_string(t->eos, smbios_chassis_version());
+	t->serial_number = smbios_add_string(t->eos, smbios_chassis_serial_number());
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+#define MAX_CPUS_ENABLED (CONFIG_MAX_CPUS > 0xff ? 0xff : CONFIG_MAX_CPUS)
+
+static int smbios_write_type4(unsigned long *current, int handle)
+{
+	// unsigned int cpu_voltage;
+	struct cpuid_result res;
+	uint16_t characteristics = 0;
+	static unsigned int cnt = 0;
+	char buf[8];
+
+	/* Provide sane defaults even for CPU without CPUID */
+	res.eax = res.edx = 0;
+	res.ebx = 0x10000;
+
+	if (cpu_have_cpuid())
+		res = cpuid(1);
+
+	struct smbios_type4 *t = smbios_carve_table(*current, SMBIOS_PROCESSOR_INFORMATION,
+						    sizeof(*t), handle);
+
+	snprintf(buf, sizeof(buf), "CPU%d", cnt++);
+	t->socket_designation = smbios_add_string(t->eos, buf);
+
+	t->processor_id[0] = res.eax;
+	t->processor_id[1] = res.edx;
+	t->processor_manufacturer = smbios_cpu_vendor(t->eos);
+	t->processor_version = smbios_processor_name(t->eos);
+	t->processor_family = smbios_processor_family(res);
+	t->processor_type = 3; /* System Processor */
+	/*
+	 * If CPUID leaf 11 is available, calculate "core count" by dividing
+	 * SMT_ID (logical processors in a core) by Core_ID (number of cores).
+	 * This seems to be the way to arrive to a number of cores mentioned on
+	 * ark.intel.com.
+	 */
+	if (cpu_have_cpuid() && cpuid_get_max_func() >= 0xb) {
+		uint32_t leaf_b_cores = 0, leaf_b_threads = 0;
+		res = cpuid_ext(0xb, 1);
+		leaf_b_cores = res.ebx;
+		res = cpuid_ext(0xb, 0);
+		leaf_b_threads = res.ebx;
+		/* if hyperthreading is not available, pretend this is 1 */
+		if (leaf_b_threads == 0)
+			leaf_b_threads = 1;
+
+		t->core_count2 = leaf_b_cores / leaf_b_threads;
+		t->core_count = t->core_count2 > 0xff ? 0xff : t->core_count2;
+		t->thread_count2 = leaf_b_cores;
+		t->thread_count = t->thread_count2 > 0xff ? 0xff : t->thread_count2;
+	} else {
+		t->core_count = (res.ebx >> 16) & 0xff;
+		t->core_count2 = t->core_count;
+		t->thread_count2 = t->core_count2;
+		t->thread_count = t->thread_count2;
+	}
+	/* Assume we enable all the cores always, capped only by MAX_CPUS */
+	t->core_enabled = MIN(t->core_count, MAX_CPUS_ENABLED);
+	t->core_enabled2 = MIN(t->core_count2, CONFIG_MAX_CPUS);
+	t->l1_cache_handle = 0xffff;
+	t->l2_cache_handle = 0xffff;
+	t->l3_cache_handle = 0xffff;
+	t->serial_number = smbios_add_string(t->eos, smbios_processor_serial_number());
+	t->status = SMBIOS_PROCESSOR_STATUS_CPU_ENABLED | SMBIOS_PROCESSOR_STATUS_POPULATED;
+	t->processor_upgrade = get_socket_type();
+	if (cpu_have_cpuid() && cpuid_get_max_func() >= 0x16) {
+		t->current_speed = cpuid_eax(0x16); /* base frequency */
+		t->external_clock = cpuid_ecx(0x16);
+	} else {
+		t->current_speed = smbios_cpu_get_current_speed_mhz();
+		t->external_clock = smbios_processor_external_clock();
+	}
+
+	/* This field identifies a capability for the system, not the processor itself. */
+	t->max_speed = smbios_cpu_get_max_speed_mhz();
+
+	if (cpu_have_cpuid()) {
+		res = cpuid(1);
+
+		if ((res.ecx) & BIT(5))
+			characteristics |= BIT(6); /* BIT6: Enhanced Virtualization */
+
+		if ((res.edx) & BIT(28))
+			characteristics |= BIT(4); /* BIT4: Hardware Thread */
+
+		if (((cpuid_eax(0x80000000) - 0x80000000) + 1) > 2) {
+			res = cpuid(0x80000001);
+
+			if ((res.edx) & BIT(20))
+				characteristics |= BIT(5); /* BIT5: Execute Protection */
+		}
+	}
+	t->processor_characteristics = characteristics | smbios_processor_characteristics();
+	t->voltage = smbios_cpu_get_voltage();
+	//TODO legacy vs modern
+	// if (cpu_voltage > 0)
+		// t->voltage = 0x80 | cpu_voltage;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+/*
+ * Write SMBIOS type 7.
+ * Fill in some fields with constant values, as gathering the information
+ * from CPUID is impossible.
+ */
+static int smbios_write_type7(unsigned long *current,
+			      const int handle,
+			      const u8 level,
+			      const u8 sram_type,
+			      const enum smbios_cache_associativity associativity,
+			      const enum smbios_cache_type type,
+			      const size_t max_cache_size,
+			      const size_t cache_size)
+{
+	char buf[8];
+
+	struct smbios_type7 *t = smbios_carve_table(*current, SMBIOS_CACHE_INFORMATION,
+						    sizeof(*t), handle);
+
+	snprintf(buf, sizeof(buf), "CACHE%x", level);
+	t->socket_designation = smbios_add_string(t->eos, buf);
+
+	t->cache_configuration = SMBIOS_CACHE_CONF_LEVEL(level) |
+		SMBIOS_CACHE_CONF_LOCATION(0) | /* Internal */
+		SMBIOS_CACHE_CONF_ENABLED(1) | /* Enabled */
+		SMBIOS_CACHE_CONF_OPERATION_MODE(smbios_cache_conf_operation_mode(level));
+
+	if (max_cache_size < (SMBIOS_CACHE_SIZE_MASK * KiB)) {
+		t->max_cache_size = max_cache_size / KiB;
+		t->max_cache_size2 = t->max_cache_size;
+
+		t->max_cache_size |= SMBIOS_CACHE_SIZE_UNIT_1KB;
+		t->max_cache_size2 |= SMBIOS_CACHE_SIZE2_UNIT_1KB;
+	} else {
+		if (max_cache_size < (SMBIOS_CACHE_SIZE_MASK * 64 * KiB))
+			t->max_cache_size = max_cache_size / (64 * KiB);
+		else
+			t->max_cache_size = SMBIOS_CACHE_SIZE_OVERFLOW;
+		t->max_cache_size2 = max_cache_size / (64 * KiB);
+
+		t->max_cache_size |= SMBIOS_CACHE_SIZE_UNIT_64KB;
+		t->max_cache_size2 |= SMBIOS_CACHE_SIZE2_UNIT_64KB;
+	}
+
+	if (cache_size < (SMBIOS_CACHE_SIZE_MASK * KiB)) {
+		t->installed_size = cache_size / KiB;
+		t->installed_size2 = t->installed_size;
+
+		t->installed_size |= SMBIOS_CACHE_SIZE_UNIT_1KB;
+		t->installed_size2 |= SMBIOS_CACHE_SIZE2_UNIT_1KB;
+	} else {
+		if (cache_size < (SMBIOS_CACHE_SIZE_MASK * 64 * KiB))
+			t->installed_size = cache_size / (64 * KiB);
+		else
+			t->installed_size = SMBIOS_CACHE_SIZE_OVERFLOW;
+		t->installed_size2 = cache_size / (64 * KiB);
+
+		t->installed_size |= SMBIOS_CACHE_SIZE_UNIT_64KB;
+		t->installed_size2 |= SMBIOS_CACHE_SIZE2_UNIT_64KB;
+	}
+
+	t->associativity = associativity;
+	t->supported_sram_type = sram_type;
+	t->current_sram_type = sram_type;
+	t->cache_speed = 0; /* Unknown */
+	t->error_correction_type = smbios_cache_error_correction_type(level);
+	t->system_cache_type = type;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+/* Convert the associativity as integer to the SMBIOS enum if available */
+static enum smbios_cache_associativity smbios_cache_associativity(const u8 num)
+{
+	switch (num) {
+	case 1:
+		return SMBIOS_CACHE_ASSOCIATIVITY_DIRECT;
+	case 2:
+		return SMBIOS_CACHE_ASSOCIATIVITY_2WAY;
+	case 4:
+		return SMBIOS_CACHE_ASSOCIATIVITY_4WAY;
+	case 8:
+		return SMBIOS_CACHE_ASSOCIATIVITY_8WAY;
+	case 12:
+		return SMBIOS_CACHE_ASSOCIATIVITY_12WAY;
+	case 16:
+		return SMBIOS_CACHE_ASSOCIATIVITY_16WAY;
+	case 20:
+		return SMBIOS_CACHE_ASSOCIATIVITY_20WAY;
+	case 24:
+		return SMBIOS_CACHE_ASSOCIATIVITY_24WAY;
+	case 32:
+		return SMBIOS_CACHE_ASSOCIATIVITY_32WAY;
+	case 48:
+		return SMBIOS_CACHE_ASSOCIATIVITY_48WAY;
+	case 64:
+		return SMBIOS_CACHE_ASSOCIATIVITY_64WAY;
+	case 0xff:
+		return SMBIOS_CACHE_ASSOCIATIVITY_FULL;
+	default:
+		return SMBIOS_CACHE_ASSOCIATIVITY_UNKNOWN;
+	};
+}
+
+#if 1
+/*
+ * Parse the "Deterministic Cache Parameters" as provided by Intel in
+ * leaf 4 or AMD in extended leaf 0x8000001d.
+ *
+ * @param current Pointer to memory address to write the tables to
+ * @param handle Pointer to handle for the tables
+ * @param max_struct_size Pointer to maximum struct size
+ * @param type4 Pointer to SMBIOS type 4 structure
+ */
+static int smbios_write_type7_cache_parameters(unsigned long *current,
+					       int *handle,
+					       int *max_struct_size,
+					       struct smbios_type4 *type4)
+{
+	//unsupported on 486
+	return 0;
+
+	unsigned int cnt = CACHE_L1D;
+	int len = 0;
+
+	if (!cpu_have_cpuid())
+		return len;
+
+	enum cpu_type dcache_cpuid = cpu_check_deterministic_cache_cpuid_supported();
+	if (dcache_cpuid == CPUID_TYPE_INVALID || dcache_cpuid == CPUID_COMMAND_UNSUPPORTED) {
+		printk(BIOS_DEBUG, "SMBIOS: Unknown CPU or CPU doesn't support Deterministic "
+					"Cache CPUID leaf\n");
+		return len;
+	}
+
+	while (1) {
+		enum smbios_cache_associativity associativity;
+		enum smbios_cache_type type;
+		struct cpu_cache_info info;
+		if (!fill_cpu_cache_info(cnt++, &info))
+			continue;
+
+		const u8 cache_type = info.type;
+		const u8 level = info.level;
+		const size_t assoc = info.num_ways;
+		const size_t cache_share = info.num_cores_shared;
+		const size_t cache_size = info.size * get_number_of_caches(cache_share);
+
+		if (!cache_type)
+			/* No more caches in the system */
+			break;
+
+		switch (cache_type) {
+		case 1:
+			type = SMBIOS_CACHE_TYPE_DATA;
+			break;
+		case 2:
+			type = SMBIOS_CACHE_TYPE_INSTRUCTION;
+			break;
+		case 3:
+			type = SMBIOS_CACHE_TYPE_UNIFIED;
+			break;
+		default:
+			type = SMBIOS_CACHE_TYPE_UNKNOWN;
+			break;
+		}
+
+		if (info.fully_associative)
+			associativity = SMBIOS_CACHE_ASSOCIATIVITY_FULL;
+		else
+			associativity = smbios_cache_associativity(assoc);
+
+		const int h = (*handle)++;
+
+		update_max(len, *max_struct_size, smbios_write_type7(current, h,
+			   level, smbios_cache_sram_type(), associativity,
+			   type, cache_size, cache_size));
+
+		if (type4) {
+			switch (level) {
+			case 1:
+				type4->l1_cache_handle = h;
+				break;
+			case 2:
+				type4->l2_cache_handle = h;
+				break;
+			case 3:
+				type4->l3_cache_handle = h;
+				break;
+			}
+		}
+	};
+
+	return len;
+}
+#endif
+
+int smbios_write_type8(unsigned long *current, int *handle,
+				const struct port_information *port,
+				size_t num_ports)
+{
+	unsigned int totallen = 0, i;
+
+	for (i = 0; i < num_ports; i++, port++) {
+		struct smbios_type8 *t = smbios_carve_table(*current,
+							    SMBIOS_PORT_CONNECTOR_INFORMATION,
+							    sizeof(*t), *handle);
+		t->internal_reference_designator =
+			smbios_add_string(t->eos, port->internal_reference_designator);
+		t->internal_connector_type = port->internal_connector_type;
+		t->external_reference_designator =
+			smbios_add_string(t->eos, port->external_reference_designator);
+		t->external_connector_type = port->external_connector_type;
+		t->port_type = port->port_type;
+		*handle += 1;
+		const int len = smbios_full_table_len(&t->header, t->eos);
+		*current += len;
+		totallen += len;
+	}
+	return totallen;
+}
+
+int smbios_write_type9(unsigned long *current, int *handle,
+			const char *name, const enum misc_slot_type type,
+			const enum slot_data_bus_bandwidth bandwidth,
+			const enum misc_slot_usage usage,
+			const enum misc_slot_length length,
+			const u16 id, u8 slot_char1, u8 slot_char2, u8 bus, u8 dev_func)
+{
+	struct smbios_type9 *t = smbios_carve_table(*current, SMBIOS_SYSTEM_SLOTS,
+						    sizeof(*t), *handle);
+
+	t->slot_designation = smbios_add_string(t->eos, name ? name : "SLOT");
+	t->slot_type = type;
+	/* TODO add slot_id supoort, will be "_SUN" for ACPI devices */
+	t->slot_id = id;
+	t->slot_data_bus_width = bandwidth;
+	t->current_usage = usage;
+	t->slot_length = length;
+	t->slot_characteristics_1 = slot_char1;
+	t->slot_characteristics_2 = slot_char2;
+	t->segment_group_number = 0;
+	t->bus_number = bus;
+	t->device_function_number = dev_func;
+	t->data_bus_width = SlotDataBusWidthOther;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+static int smbios_write_type11(unsigned long *current, int *handle)
+{
+	struct device *dev;
+	struct smbios_type11 *t = smbios_carve_table(*current, SMBIOS_OEM_STRINGS,
+						     sizeof(*t), *handle);
+
+	for (dev = all_devices; dev; dev = dev->next) {
+		if (dev->ops && dev->ops->get_smbios_strings)
+			dev->ops->get_smbios_strings(dev, t);
+	}
+
+	if (t->count == 0) {
+		memset(t, 0, sizeof(*t));
+		return 0;
+	}
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	(*handle)++;
+	return len;
+}
+
+static int smbios_write_type16(unsigned long *current, int *handle)
+{
+	printk(BIOS_INFO, "Create SMBIOS type 16\n");
+
+	struct smbios_type16 *t = smbios_carve_table(
+		*current,
+		SMBIOS_PHYS_MEMORY_ARRAY,
+		sizeof(*t),
+		*handle
+	);
+
+	t->location = MEMORY_ARRAY_LOCATION_SYSTEM_BOARD;
+	t->use = MEMORY_ARRAY_USE_SYSTEM;
+	t->memory_error_correction = SMBIOS_CACHE_ERROR_CORRECTION_NONE;
+	//TODO parity .. bepends on chipset+motherboard+config
+
+
+	/* no error information handle available */
+	t->memory_error_information_handle = 0xFFFE;
+	t->maximum_capacity = 262144;
+	t->number_of_memory_devices = 4;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	(*handle)++;
+	return len;
+}
+
+static int smbios_write_type19(unsigned long *current, int *handle, int type16)
+{
+	int i;
+
+	struct smbios_type19 *t = smbios_carve_table(*current,
+						     SMBIOS_MEMORY_ARRAY_MAPPED_ADDRESS,
+						     sizeof(*t), *handle);
+
+	t->memory_array_handle = type16;
+
+	for (i = 0; i < 4; i++) {
+		t->extended_ending_address += get_bank_size_mb(i);
+		t->partition_width++;
+	}
+	t->extended_ending_address *= MiB;
+
+	/* Check if it fits into regular address */
+	if (t->extended_ending_address >= KiB &&
+	    t->extended_ending_address < 0x40000000000ULL) {
+		/*
+		 * FIXME: The starting address is SoC specific, but SMBIOS tables are only
+		 * exported on x86 where it's always 0.
+		 */
+
+		t->starting_address = 0;
+		t->ending_address = t->extended_ending_address / KiB - 1;
+		t->extended_starting_address = ~0;
+		t->extended_ending_address = ~0;
+	} else {
+		t->starting_address = ~0;
+		t->ending_address = ~0;
+		t->extended_starting_address = 0;
+		t->extended_ending_address--;
+	}
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+static int smbios_write_type20_table(
+	unsigned long *current,
+	int *handle,
+	u32 addr_start,
+	u32 addr_end,
+	int type17_handle,
+	int type19_handle
+)
+{
+	struct smbios_type20 *t = smbios_carve_table(
+		*current, SMBIOS_MEMORY_DEVICE_MAPPED_ADDRESS,sizeof(*t), *handle
+	);
+
+	t->memory_device_handle = type17_handle;
+	t->memory_array_mapped_address_handle = type19_handle;
+	t->addr_start = addr_start;
+	t->addr_end = addr_end;
+	t->partition_row_pos = 0xff;
+	t->interleave_pos = 0xff;
+	t->interleave_depth = 0xff;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+
+static int smbios_write_type17_type20(
+	unsigned long *current,
+	int *handle,
+	int type16_handle,
+	int type19_handle
+)
+{
+	u32 start_addr = 0;
+	int totallen = 0;
+
+	printk(BIOS_INFO, "Create SMBIOS type 17 and 20\n");
+	for (unsigned i = 0; i < 4; i++) {
+		/*
+		 * Windows 10 GetPhysicallyInstalledSystemMemory functions reads SMBIOS tables
+		 * type 16 and type 17. The type 17 tables need to point to a type 16 table.
+		 * Otherwise, the physical installed memory size is guessed from the system
+		 * memory map, which results in a slightly smaller value than the actual size.
+		 */
+
+		const unsigned bank_size_kb = get_bank_size_mb(i) << 10;
+
+printk(BIOS_INFO, " bank %u: %u kiB\n", i, bank_size_kb);
+
+		if (bank_size_kb == 0) {
+			//not used
+			const int len = create_smbios_type17_for_empty_slot(current, handle, type16_handle, i);
+
+			*current += len;
+			totallen += len;
+		} else {
+			//filled
+
+			//handle to use for type17
+			const int type17_handle = *handle;
+
+			const int len = create_smbios_type17_for_simm(current, handle, type16_handle, i);
+
+			*current += len;
+			totallen += len;
+
+			const u32 end_addr = start_addr + bank_size_kb - 1;
+			totallen += smbios_write_type20_table(
+				current,
+				handle,
+				start_addr,
+				end_addr,
+				type17_handle,
+				type19_handle
+			);
+			start_addr = end_addr + 1;
+		}
+	}
+	return totallen;
+}
+
+int smbios_write_type28(unsigned long *current, int *handle,
+			const char *name,
+			const enum smbios_temp_location location,
+			const enum smbios_temp_status status,
+			u16 max_value, u16 min_value,
+			u16 resolution, u16 tolerance,
+			u16 accuracy,
+			u32 oem,
+			u16 nominal_value)
+{
+	struct smbios_type28 *t = smbios_carve_table(*current, SMBIOS_TEMPERATURE_PROBE,
+						     sizeof(*t), *handle);
+
+	t->description = smbios_add_string(t->eos, name ? name : "Temperature");
+	t->location_and_status = location | (status << 5);
+	t->maximum_value = max_value;
+	t->minimum_value = min_value;
+	t->resolution = resolution;
+	t->tolerance = tolerance;
+	t->accuracy = accuracy;
+	t->oem_defined = oem;
+	t->nominal_value = nominal_value;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+static int smbios_write_type32(unsigned long *current, int handle)
+{
+	struct smbios_type32 *t = smbios_carve_table(*current, SMBIOS_SYSTEM_BOOT_INFORMATION,
+						     sizeof(*t), handle);
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+int smbios_write_type38(unsigned long *current, int *handle,
+			const enum smbios_bmc_interface_type interface_type,
+			const u8 ipmi_rev, const u8 i2c_addr, const u8 nv_addr,
+			const u64 base_addr, const u8 base_modifier,
+			const u8 irq)
+{
+	struct smbios_type38 *t = smbios_carve_table(*current, SMBIOS_IPMI_DEVICE_INFORMATION,
+						     sizeof(*t), *handle);
+
+	t->interface_type = interface_type;
+	t->ipmi_rev = ipmi_rev;
+	t->i2c_slave_addr = i2c_addr;
+	t->nv_storage_addr = nv_addr;
+	t->base_address = base_addr;
+	t->base_address_modifier = base_modifier;
+	t->irq = irq;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+int smbios_write_type39(unsigned long *current, int *handle,
+			u8 unit_group, const char *loc, const char *dev_name,
+			const char *man, const char *serial_num,
+			const char *tag_num, const char *part_num,
+			const char *rev_lvl, u16 max_pow_cap,
+			const struct power_supply_ch *ps_ch)
+{
+	struct smbios_type39 *t = smbios_carve_table(*current,
+						SMBIOS_SYSTEM_POWER_SUPPLY,
+						sizeof(*t), *handle);
+
+	uint16_t val = 0;
+	uint16_t ps_type, ps_status, vol_switch, ps_unplug, ps_present, hot_rep;
+
+	t->power_unit_group = unit_group;
+	t->location = smbios_add_string(t->eos, loc);
+	t->device_name = smbios_add_string(t->eos, dev_name);
+	t->manufacturer = smbios_add_string(t->eos, man);
+	t->serial_number = smbios_add_string(t->eos, serial_num);
+	t->asset_tag_number = smbios_add_string(t->eos, tag_num);
+	t->model_part_number = smbios_add_string(t->eos, part_num);
+	t->revision_level = smbios_add_string(t->eos, rev_lvl);
+	t->max_power_capacity = max_pow_cap;
+
+	ps_type = ps_ch->power_supply_type & 0xF;
+	ps_status = ps_ch->power_supply_status & 0x7;
+	vol_switch = ps_ch->input_voltage_range_switch & 0xF;
+	ps_unplug = ps_ch->power_supply_unplugged & 0x1;
+	ps_present = ps_ch->power_supply_present & 0x1;
+	hot_rep = ps_ch->power_supply_hot_replaceble & 0x1;
+
+	val |= (ps_type << 10);
+	val |= (ps_status << 7);
+	val |= (vol_switch << 3);
+	val |= (ps_unplug << 2);
+	val |= (ps_present << 1);
+	val |= hot_rep;
+	t->power_supply_characteristics = val;
+
+	t->input_voltage_probe_handle = 0xFFFF;
+	t->cooling_device_handle = 0xFFFF;
+	t->input_current_probe_handle = 0xFFFF;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+int smbios_write_type41(unsigned long *current, int *handle,
+			const char *name, u8 instance, u16 segment,
+			u8 bus, u8 device, u8 function, u8 device_type)
+{
+	struct smbios_type41 *t = smbios_carve_table(*current,
+						SMBIOS_ONBOARD_DEVICES_EXTENDED_INFORMATION,
+						sizeof(*t), *handle);
+
+	t->reference_designation = smbios_add_string(t->eos, name);
+	t->device_type = device_type;
+	t->device_status = 1;
+	t->device_type_instance = instance;
+	t->segment_group_number = segment;
+	t->bus_number = bus;
+	t->device_number = device;
+	t->function_number = function;
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+int smbios_write_type43(unsigned long *current, int *handle, const u32 vendor_id,
+			const u8 major_spec_ver, const u8 minor_spec_ver,
+			const u32 fw_ver1, const u32 fw_ver2, const char *description,
+			const u64 characteristics, const u32 oem_defined)
+{
+	struct smbios_type43 *t = smbios_carve_table(*current, SMBIOS_TPM_DEVICE,
+						     sizeof(*t), *handle);
+
+	t->vendor_id = vendor_id;
+	t->major_spec_ver = major_spec_ver;
+	t->minor_spec_ver = minor_spec_ver;
+	t->fw_ver1 = fw_ver1;
+	t->fw_ver2 = fw_ver2;
+	t->characteristics = characteristics;
+	t->oem_defined = oem_defined;
+	t->description = smbios_add_string(t->eos, description);
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	*handle += 1;
+	return len;
+}
+
+static int smbios_write_type127(unsigned long *current, int handle)
+{
+	struct smbios_type127 *t = smbios_carve_table(*current, SMBIOS_END_OF_TABLE,
+						      sizeof(*t), handle);
+
+	const int len = smbios_full_table_len(&t->header, t->eos);
+	*current += len;
+	return len;
+}
+
+/* Get the device type 41 from the dev struct */
+static u8 smbios_get_device_type_from_dev(struct device *dev)
+{
+	u16 pci_basesubclass = (dev->class >> 8) & 0xFFFF;
+
+	switch (pci_basesubclass) {
+	case PCI_CLASS_NOT_DEFINED:
+		return SMBIOS_DEVICE_TYPE_OTHER;
+	case PCI_CLASS_DISPLAY_VGA:
+	case PCI_CLASS_DISPLAY_XGA:
+	case PCI_CLASS_DISPLAY_3D:
+	case PCI_CLASS_DISPLAY_OTHER:
+		return SMBIOS_DEVICE_TYPE_VIDEO;
+	case PCI_CLASS_STORAGE_SCSI:
+		return SMBIOS_DEVICE_TYPE_SCSI;
+	case PCI_CLASS_NETWORK_ETHERNET:
+		return SMBIOS_DEVICE_TYPE_ETHERNET;
+	case PCI_CLASS_NETWORK_TOKEN_RING:
+		return SMBIOS_DEVICE_TYPE_TOKEN_RING;
+	case PCI_CLASS_MULTIMEDIA_VIDEO:
+	case PCI_CLASS_MULTIMEDIA_AUDIO:
+	case PCI_CLASS_MULTIMEDIA_PHONE:
+	case PCI_CLASS_MULTIMEDIA_OTHER:
+		return SMBIOS_DEVICE_TYPE_SOUND;
+	case PCI_CLASS_STORAGE_ATA:
+		return SMBIOS_DEVICE_TYPE_PATA;
+	case PCI_CLASS_STORAGE_SATA:
+		return SMBIOS_DEVICE_TYPE_SATA;
+	case PCI_CLASS_STORAGE_SAS:
+		return SMBIOS_DEVICE_TYPE_SAS;
+	default:
+		return SMBIOS_DEVICE_TYPE_UNKNOWN;
+	}
+}
+
+static bool smbios_get_type41_instance_id(struct device *dev, u8 device_type, u8 *instance_id)
+{
+#if CONFIG(SMBIOS_TYPE41_PROVIDED_BY_DEVTREE)
+	*instance_id = dev->smbios_instance_id;
+	return dev->smbios_instance_id_valid;
+#else
+	static u8 type41_inst_cnt[SMBIOS_DEVICE_TYPE_COUNT + 1] = {};
+
+	if (device_type == SMBIOS_DEVICE_TYPE_OTHER ||
+	    device_type == SMBIOS_DEVICE_TYPE_UNKNOWN)
+		return false;
+
+	if (device_type > SMBIOS_DEVICE_TYPE_COUNT)
+		return false;
+
+	*instance_id = type41_inst_cnt[device_type]++;
+	return true;
+#endif
+}
+
+static const char *smbios_get_type41_refdes(struct device *dev)
+{
+#if CONFIG(SMBIOS_TYPE41_PROVIDED_BY_DEVTREE)
+	if (dev->smbios_refdes)
+		return dev->smbios_refdes;
+#endif
+	return get_pci_subclass_name(dev);
+}
+
+static int smbios_generate_type41_from_devtree(struct device *dev, int *handle,
+					       unsigned long *current)
+{
+	if (dev->path.type != DEVICE_PATH_PCI)
+		return 0;
+	if (!dev->on_mainboard)
+		return 0;
+
+	const u8 device_type = smbios_get_device_type_from_dev(dev);
+
+	u8 instance_id;
+
+	if (!smbios_get_type41_instance_id(dev, device_type, &instance_id))
+		return 0;
+
+	const char *name = smbios_get_type41_refdes(dev);
+
+	return smbios_write_type41(current, handle,
+					name, // name
+					instance_id, // inst
+					0, // segment
+					dev->bus->secondary, //bus
+					PCI_SLOT(dev->path.pci.devfn), // device
+					PCI_FUNC(dev->path.pci.devfn), // func
+					device_type);
+}
+
+static int smbios_generate_type9_from_devtree(struct device *dev, int *handle,
+					      unsigned long *current)
+{
+	enum misc_slot_usage usage;
+	enum slot_data_bus_bandwidth bandwidth;
+	enum misc_slot_type type;
+	enum misc_slot_length length;
+
+	if (dev->path.type != DEVICE_PATH_PCI)
+		return 0;
+
+	if (!dev->smbios_slot_type && !dev->smbios_slot_data_width &&
+	    !dev->smbios_slot_designation && !dev->smbios_slot_length)
+		return 0;
+
+	if (dev_is_active_bridge(dev))
+		usage = SlotUsageInUse;
+	else if (dev->enabled)
+		usage = SlotUsageAvailable;
+	else
+		usage = SlotUsageUnknown;
+
+	if (dev->smbios_slot_data_width)
+		bandwidth = dev->smbios_slot_data_width;
+	else
+		bandwidth = SlotDataBusWidthUnknown;
+
+	if (dev->smbios_slot_type)
+		type = dev->smbios_slot_type;
+	else
+		type = SlotTypeUnknown;
+
+	if (dev->smbios_slot_length)
+		length = dev->smbios_slot_length;
+	else
+		length = SlotLengthUnknown;
+
+	return smbios_write_type9(current, handle,
+				  dev->smbios_slot_designation,
+				  type,
+				  bandwidth,
+				  usage,
+				  length,
+				  0,
+				  1,
+				  0,
+				  dev->bus->secondary,
+				  dev->path.pci.devfn);
+}
+
+int get_smbios_data(struct device *dev, int *handle, unsigned long *current)
+{
+	int len = 0;
+
+	len += smbios_generate_type9_from_devtree(dev, handle, current);
+	len += smbios_generate_type41_from_devtree(dev, handle, current);
+
+	return len;
+}
+
+static int smbios_walk_device_tree(struct device *tree, int *handle, unsigned long *current)
+{
+	struct device *dev;
+	int len = 0;
+
+	for (dev = tree; dev; dev = dev->next) {
+		if (!dev->enabled)
+			continue;
+
+		if (dev->ops && dev->ops->get_smbios_data) {
+			printk(BIOS_INFO, "%s (%s)\n", dev_path(dev), dev_name(dev));
+			len += dev->ops->get_smbios_data(dev, handle, current);
+		} else {
+			len += get_smbios_data(dev, handle, current);
+		}
+	}
+	return len;
+}
+
+unsigned long smbios_write_tables(unsigned long current)
+{
+	struct smbios_entry *se;
+	struct smbios_entry30 *se3;
+	unsigned long tables;
+	int len = 0;
+	int max_struct_size = 0;
+	int handle = 0;
+
+	current = ALIGN_UP(current, 16);
+	printk(BIOS_DEBUG, "%s: %08lx\n", __func__, current);
+
+	se = (struct smbios_entry *)current;
+	current += sizeof(*se);
+	current = ALIGN_UP(current, 16);
+
+	se3 = (struct smbios_entry30 *)current;
+	current += sizeof(*se3);
+	current = ALIGN_UP(current, 16);
+
+	tables = current;
+	update_max(len, max_struct_size, smbios_write_type0(&current, handle++));
+	update_max(len, max_struct_size, smbios_write_type1(&current, handle++));
+
+	/* The chassis handle is the next one */
+	update_max(len, max_struct_size, smbios_write_type2(&current, handle, handle + 1));
+	handle++;
+	update_max(len, max_struct_size, smbios_write_type3(&current, handle++));
+
+	struct smbios_type4 *type4 = (struct smbios_type4 *)current;
+	update_max(len, max_struct_size, smbios_write_type4(&current, handle++));
+
+#if 1
+	//not supported on 486
+	len += smbios_write_type7_cache_parameters(&current, &handle, &max_struct_size, type4);
+#endif
+
+	update_max(len, max_struct_size, smbios_write_type11(&current, &handle));
+	if (CONFIG(ELOG))
+		update_max(len, max_struct_size,
+			elog_smbios_write_type15(&current, handle++));
+
+	const int type16 = handle;
+	update_max(len, max_struct_size, smbios_write_type16(&current, &handle));
+
+	const int type19 = handle;
+	update_max(len, max_struct_size, smbios_write_type19(&current, &handle, type16));
+
+	// const int type17_type20 = handle;
+	update_max(len, max_struct_size, smbios_write_type17_type20(&current, &handle, type16, type19));
+
+	update_max(len, max_struct_size, smbios_write_type32(&current, handle++));
+
+	update_max(len, max_struct_size, smbios_walk_device_tree(all_devices,
+								 &handle, &current));
+
+	update_max(len, max_struct_size, smbios_write_type127(&current, handle++));
+
+	/* Install SMBIOS 2.1 entry point */
+	memset(se, 0, sizeof(*se));
+	memcpy(se->anchor, "_SM_", 4);
+	se->length = sizeof(*se);
+	se->major_version = 3;
+	se->minor_version = 0;
+	se->max_struct_size = max_struct_size;
+	se->struct_count = handle;
+	memcpy(se->intermediate_anchor_string, "_DMI_", 5);
+
+	se->struct_table_address = (u32)tables;
+	se->struct_table_length = len;
+
+	se->intermediate_checksum = smbios_checksum((u8 *)se + 0x10, sizeof(*se) - 0x10);
+	se->checksum = smbios_checksum((u8 *)se, sizeof(*se));
+
+	/* Install SMBIOS 3.0 entry point */
+	memset(se3, 0, sizeof(*se3));
+	memcpy(se3->anchor, "_SM3_", 5);
+	se3->length = sizeof(*se3);
+	se3->major_version = 3;
+	se3->minor_version = 0;
+
+	se3->struct_table_address = (u64)tables;
+	se3->struct_table_length = len;
+
+	se3->checksum = smbios_checksum((u8 *)se3, sizeof(*se3));
+
+	return current;
+}
diff --git a/src/arch/486/smbios_defaults.c b/src/arch/486/smbios_defaults.c
new file mode 100644
index 0000000000..8b62ebba14
--- /dev/null
+++ b/src/arch/486/smbios_defaults.c
@@ -0,0 +1,164 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <memory_info.h>
+#include <smbios.h>
+#include <stdint.h>
+#include <string.h>
+
+/* this function will fill the corresponding locator */
+__weak void smbios_fill_dimm_locator(const struct dimm_info *dimm, struct smbios_type17 *t)
+{
+	char locator[40];
+
+	snprintf(locator, sizeof(locator), "Channel-%d-DIMM-%d",
+		dimm->channel_num, dimm->dimm_num);
+	t->device_locator = smbios_add_string(t->eos, locator);
+
+	snprintf(locator, sizeof(locator), "BANK %d", dimm->bank_locator);
+	t->bank_locator = smbios_add_string(t->eos, locator);
+}
+
+__weak void smbios_fill_dimm_asset_tag(const struct dimm_info *dimm, struct smbios_type17 *t)
+{
+	char buf[40];
+
+	snprintf(buf, sizeof(buf), "Channel-%d-DIMM-%d-AssetTag",
+		dimm->channel_num, dimm->dimm_num);
+	t->asset_tag = smbios_add_string(t->eos, buf);
+}
+
+__weak smbios_wakeup_type smbios_system_wakeup_type(void)
+{
+	return SMBIOS_WAKEUP_TYPE_RESERVED;
+}
+
+__weak const char *smbios_mainboard_bios_version(void)
+{
+	return NULL;
+}
+
+__weak const char *smbios_mainboard_serial_number(void)
+{
+	return CONFIG_MAINBOARD_SERIAL_NUMBER;
+}
+
+__weak const char *smbios_mainboard_version(void)
+{
+	return CONFIG_MAINBOARD_VERSION;
+}
+
+__weak const char *smbios_mainboard_manufacturer(void)
+{
+	return CONFIG_MAINBOARD_SMBIOS_MANUFACTURER;
+}
+
+__weak const char *smbios_mainboard_product_name(void)
+{
+	return CONFIG_MAINBOARD_SMBIOS_PRODUCT_NAME;
+}
+
+__weak const char *smbios_mainboard_asset_tag(void)
+{
+	return "";
+}
+
+__weak u8 smbios_mainboard_feature_flags(void)
+{
+	return 0;
+}
+
+__weak const char *smbios_mainboard_location_in_chassis(void)
+{
+	return "";
+}
+
+__weak smbios_board_type smbios_mainboard_board_type(void)
+{
+	return SMBIOS_BOARD_TYPE_MOTHERBOARD;
+}
+
+__weak void smbios_ec_revision(uint8_t *ec_major_revision, uint8_t *ec_minor_revision)
+{
+	*ec_major_revision = 0x0;
+	*ec_minor_revision = 0x0;
+}
+
+/*
+ * System Enclosure or Chassis Types as defined in SMBIOS specification.
+ * The default value is SMBIOS_ENCLOSURE_DESKTOP (0x03) but laptop,
+ * convertible, or tablet enclosure will be used if the appropriate
+ * system type is selected.
+ */
+__weak smbios_enclosure_type smbios_mainboard_enclosure_type(void)
+{
+	if (CONFIG(SYSTEM_TYPE_LAPTOP))
+		return SMBIOS_ENCLOSURE_LAPTOP;
+	else if (CONFIG(SYSTEM_TYPE_TABLET))
+		return SMBIOS_ENCLOSURE_TABLET;
+	else if (CONFIG(SYSTEM_TYPE_CONVERTIBLE))
+		return SMBIOS_ENCLOSURE_CONVERTIBLE;
+	else if (CONFIG(SYSTEM_TYPE_DETACHABLE))
+		return SMBIOS_ENCLOSURE_DETACHABLE;
+	else
+		return SMBIOS_ENCLOSURE_DESKTOP;
+}
+
+__weak const char *smbios_system_serial_number(void)
+{
+	return smbios_mainboard_serial_number();
+}
+
+__weak const char *smbios_system_version(void)
+{
+	return smbios_mainboard_version();
+}
+
+__weak const char *smbios_system_manufacturer(void)
+{
+	return smbios_mainboard_manufacturer();
+}
+
+__weak const char *smbios_system_product_name(void)
+{
+	return smbios_mainboard_product_name();
+}
+
+__weak void smbios_system_set_uuid(u8 *uuid)
+{
+	/* leave all zero */
+}
+
+__weak unsigned int smbios_cpu_get_max_speed_mhz(void)
+{
+	return 0; /* Unknown */
+}
+
+__weak unsigned int smbios_cpu_get_current_speed_mhz(void)
+{
+	return 0; /* Unknown */
+}
+
+__weak const char *smbios_system_sku(void)
+{
+	return "";
+}
+
+__weak const char *smbios_chassis_version(void)
+{
+	return "";
+}
+
+__weak const char *smbios_chassis_serial_number(void)
+{
+	return "";
+}
+
+__weak const char *smbios_processor_serial_number(void)
+{
+	return "";
+}
+
+__weak u8 smbios_chassis_power_cords(void)
+{
+	return 1;
+}
diff --git a/src/arch/486/tables.c b/src/arch/486/tables.c
new file mode 100644
index 0000000000..c40d22dad2
--- /dev/null
+++ b/src/arch/486/tables.c
@@ -0,0 +1,226 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <console/console.h>
+#include <bootmem.h>
+#include <boot/tables.h>
+#include <boot/coreboot_tables.h>
+#include <arch/pirq_routing.h>
+#include <arch/smp/mpspec.h>
+#include <acpi/acpi.h>
+#include <commonlib/helpers.h>
+#include <string.h>
+#include <cbmem.h>
+#include <smbios.h>
+
+static unsigned long write_pirq_table(unsigned long rom_table_end)
+{
+	unsigned long high_table_pointer;
+
+#define MAX_PIRQ_TABLE_SIZE (4 * 1024)
+	post_code(POST_X86_WRITE_PIRQ_TABLE);
+
+	/* This table must be between 0x0f0000 and 0x100000 */
+	rom_table_end = write_pirq_routing_table(rom_table_end);
+	rom_table_end = ALIGN_UP(rom_table_end, 1024);
+
+	/* And add a high table version for those payloads that
+	 * want to live in the F segment
+	 */
+	high_table_pointer = (unsigned long)cbmem_add(CBMEM_ID_PIRQ,
+		MAX_PIRQ_TABLE_SIZE);
+	if (high_table_pointer) {
+		unsigned long new_high_table_pointer;
+		new_high_table_pointer =
+			write_pirq_routing_table(high_table_pointer);
+		// FIXME make pirq table code intelligent enough to know how
+		// much space it's going to need.
+		if (new_high_table_pointer > (high_table_pointer
+			+ MAX_PIRQ_TABLE_SIZE))
+			printk(BIOS_ERR, "Increase PIRQ size.\n");
+
+		printk(BIOS_DEBUG, "PIRQ table: %ld bytes.\n",
+				new_high_table_pointer - high_table_pointer);
+	}
+
+	return rom_table_end;
+}
+
+static unsigned long write_mptable(unsigned long rom_table_end)
+{
+	unsigned long high_table_pointer;
+
+#define MAX_MP_TABLE_SIZE (4 * 1024)
+	post_code(POST_X86_WRITE_MPTABLE);
+
+	/* The smp table must be in 0-1K, 639K-640K, or 960K-1M */
+	rom_table_end = write_smp_table(rom_table_end);
+	rom_table_end = ALIGN_UP(rom_table_end, 1024);
+
+	high_table_pointer = (unsigned long)cbmem_add(CBMEM_ID_MPTABLE,
+		MAX_MP_TABLE_SIZE);
+	if (high_table_pointer) {
+		unsigned long new_high_table_pointer;
+		new_high_table_pointer = write_smp_table(high_table_pointer);
+		// FIXME make mp table code intelligent enough to know how
+		// much space it's going to need.
+		if (new_high_table_pointer > (high_table_pointer
+			+ MAX_MP_TABLE_SIZE))
+			printk(BIOS_ERR, "Increase MP table size.\n");
+
+		printk(BIOS_DEBUG, "MP table: %ld bytes.\n",
+				new_high_table_pointer - high_table_pointer);
+	}
+
+	return rom_table_end;
+}
+
+static unsigned long write_acpi_table(unsigned long rom_table_end)
+{
+	unsigned long high_table_pointer;
+	const size_t max_acpi_size = CONFIG_MAX_ACPI_TABLE_SIZE_KB * KiB;
+
+	post_code(POST_X86_WRITE_ACPITABLE);
+
+	/* Write ACPI tables to F segment and high tables area */
+
+	/* Ok, this is a bit hacky still, because some day we want to have this
+	 * completely dynamic. But right now we are setting fixed sizes.
+	 * It's probably still better than the old high_table_base code because
+	 * now at least we know when we have an overflow in the area.
+	 *
+	 * We want to use 1MB - 64K for Resume backup. We use 512B for TOC and
+	 * 512 byte for GDT, 4K for PIRQ and 4K for MP table and 8KB for the
+	 * coreboot table. This leaves us with 47KB for all of ACPI. Let's see
+	 * how far we get.
+	 */
+	high_table_pointer = (unsigned long)cbmem_add(CBMEM_ID_ACPI,
+		max_acpi_size);
+	if (high_table_pointer) {
+		unsigned long acpi_start = high_table_pointer;
+		unsigned long new_high_table_pointer;
+
+		rom_table_end = ALIGN_UP(rom_table_end, 16);
+		new_high_table_pointer = write_acpi_tables(high_table_pointer);
+		if (new_high_table_pointer > (high_table_pointer
+			+ max_acpi_size))
+			printk(BIOS_ERR, "Increase ACPI size\n");
+		printk(BIOS_DEBUG, "ACPI tables: %ld bytes.\n",
+				new_high_table_pointer - high_table_pointer);
+
+		/* Now we need to create a low table copy of the RSDP. */
+
+		/* First we look for the high table RSDP */
+		while (acpi_start < new_high_table_pointer) {
+			if (memcmp(((acpi_rsdp_t *)acpi_start)->signature,
+				RSDP_SIG, 8) == 0)
+				break;
+			acpi_start++;
+		}
+
+		/* Now, if we found the RSDP, we take the RSDT and XSDT pointer
+		 * from it in order to write the low RSDP
+		 */
+		if (acpi_start < new_high_table_pointer) {
+			acpi_rsdp_t *low_rsdp = (acpi_rsdp_t *)rom_table_end,
+				    *high_rsdp = (acpi_rsdp_t *)acpi_start;
+
+			/* Technically rsdp length varies but coreboot always
+			   writes longest size available.  */
+			memcpy(low_rsdp, high_rsdp, sizeof(acpi_rsdp_t));
+		} else {
+			printk(BIOS_ERR, "Didn't find RSDP in high table.\n");
+		}
+		rom_table_end = ALIGN_UP(rom_table_end + sizeof(acpi_rsdp_t), 16);
+	} else {
+		rom_table_end = write_acpi_tables(rom_table_end);
+		rom_table_end = ALIGN_UP(rom_table_end, 1024);
+	}
+
+	return rom_table_end;
+}
+
+static unsigned long write_smbios_table(unsigned long rom_table_end)
+{
+	unsigned long high_table_pointer;
+
+#define MAX_SMBIOS_SIZE (32 * KiB)
+
+	high_table_pointer = (unsigned long)cbmem_add(CBMEM_ID_SMBIOS,
+		MAX_SMBIOS_SIZE);
+	if (high_table_pointer) {
+		unsigned long new_high_table_pointer;
+
+		/*
+		 * Clear the entire region to ensure the unused space doesn't
+		 * contain garbage from a previous boot, like stale table
+		 * signatures that could be found by the OS.
+		 */
+		memset((void *)high_table_pointer, 0, MAX_SMBIOS_SIZE);
+
+		new_high_table_pointer =
+			smbios_write_tables(high_table_pointer);
+		rom_table_end = ALIGN_UP(rom_table_end, 16);
+		memcpy((void *)rom_table_end, (void *)high_table_pointer,
+			sizeof(struct smbios_entry));
+		rom_table_end += sizeof(struct smbios_entry);
+
+		if (new_high_table_pointer > (high_table_pointer
+			+ MAX_SMBIOS_SIZE))
+			printk(BIOS_ERR, "Increase SMBIOS size\n");
+		printk(BIOS_DEBUG, "SMBIOS tables: %ld bytes.\n",
+				new_high_table_pointer - high_table_pointer);
+	} else {
+		unsigned long new_rom_table_end;
+
+		new_rom_table_end = smbios_write_tables(rom_table_end);
+		printk(BIOS_DEBUG, "SMBIOS size %ld bytes\n", new_rom_table_end
+			- rom_table_end);
+		rom_table_end = ALIGN_UP(new_rom_table_end, 16);
+	}
+
+	return rom_table_end;
+}
+
+/* Start forwarding table at 0x500, so we don't run into conflicts with the BDA
+ * in case our data structures grow beyond 0x400. Only GDT
+ * and the coreboot table use low_tables.
+ */
+#define FORWARDING_TABLE_ADDR ((uintptr_t)0x500)
+static uintptr_t forwarding_table = FORWARDING_TABLE_ADDR;
+
+void arch_write_tables(uintptr_t coreboot_table)
+{
+	size_t sz;
+	unsigned long rom_table_end = 0xf0000;	//pc2005
+
+	/* This table must be between 0x0f0000 and 0x100000 */
+	if (CONFIG(GENERATE_PIRQ_TABLE))
+		rom_table_end = write_pirq_table(rom_table_end);
+
+	/* The smp table must be in 0-1K, 639K-640K, or 960K-1M */
+	if (CONFIG(GENERATE_MP_TABLE))
+		rom_table_end = write_mptable(rom_table_end);
+
+	if (CONFIG(HAVE_ACPI_TABLES))
+		rom_table_end = write_acpi_table(rom_table_end);
+
+	if (CONFIG(GENERATE_SMBIOS_TABLES))
+		rom_table_end = write_smbios_table(rom_table_end);
+
+	sz = write_coreboot_forwarding_table(forwarding_table, coreboot_table);
+
+	forwarding_table += sz;
+	/* Align up to page boundary for historical consistency. */
+	forwarding_table = ALIGN_UP(forwarding_table, 4*KiB);
+
+	/* Tell static analysis we know value is left unused. */
+	(void)rom_table_end;
+}
+
+void bootmem_arch_add_ranges(void)
+{
+	/* Memory from 0 through the forwarding_table is reserved. */
+	const uintptr_t base = 0;
+
+	bootmem_add_range(base, forwarding_table - base, BM_MEM_TABLE);
+}
diff --git a/src/arch/486/thread.c b/src/arch/486/thread.c
new file mode 100644
index 0000000000..fa6096161b
--- /dev/null
+++ b/src/arch/486/thread.c
@@ -0,0 +1,45 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <thread.h>
+
+#if ENV_X86_64
+#error COOP_MULTITASKING does not currently support x86_64
+#endif
+
+/* The stack frame looks like the following after a pushad instruction. */
+struct pushad_regs {
+	uint32_t edi; /* Offset 0x00 */
+	uint32_t esi; /* Offset 0x04 */
+	uint32_t ebp; /* Offset 0x08 */
+	uint32_t esp; /* Offset 0x0c */
+	uint32_t ebx; /* Offset 0x10 */
+	uint32_t edx; /* Offset 0x14 */
+	uint32_t ecx; /* Offset 0x18 */
+	uint32_t eax; /* Offset 0x1c */
+};
+
+static inline uintptr_t push_stack(uintptr_t cur_stack, uintptr_t value)
+{
+	uintptr_t *addr;
+
+	cur_stack -= sizeof(value);
+	addr = (uintptr_t *)cur_stack;
+	*addr = value;
+	return cur_stack;
+}
+
+void arch_prepare_thread(struct thread *t,
+			asmlinkage void (*thread_entry)(void *), void *arg)
+{
+	uintptr_t stack = t->stack_current;
+
+	/* Imitate thread_entry(t) with return address of 0. thread_entry()
+	 * is assumed to never return. */
+	stack = push_stack(stack, (uintptr_t)arg);
+	stack = push_stack(stack, (uintptr_t)0);
+	stack = push_stack(stack, (uintptr_t)thread_entry);
+	/* Make room for the registers. Ignore initial values. */
+	stack -= sizeof(struct pushad_regs);
+
+	t->stack_current = stack;
+}
diff --git a/src/arch/486/thread_switch.S b/src/arch/486/thread_switch.S
new file mode 100644
index 0000000000..3c6a34dd13
--- /dev/null
+++ b/src/arch/486/thread_switch.S
@@ -0,0 +1,46 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#if ENV_X86_64
+#error COOP_MULTITASKING does not currently support x86_64
+#endif
+
+.code32
+.text
+
+/*
+ * stack layout after pushad:
+ * +------------+
+ * | save stack | <-- esp + 0x28
+ * +------------+
+ * |  new stack | <-- esp + 0x24
+ * +------------+
+ * |  ret addr  | <-- esp + 0x20
+ * +------------+
+ * |    eax     | <-- esp + 0x1c
+ * +------------+
+ * |    ecx     | <-- esp + 0x18
+ * +------------+
+ * |    edx     | <-- esp + 0x14
+ * +------------+
+ * |    ebx     | <-- esp + 0x10
+ * +------------+
+ * |  orig esp  | <-- esp + 0x0c
+ * +------------+
+ * |    ebp     | <-- esp + 0x08
+ * +------------+
+ * |    esi     | <-- esp + 0x04
+ * +------------+
+ * |    edi     | <-- esp + 0x00
+ * +------------+
+ */
+.globl switch_to_thread
+switch_to_thread:
+	pusha
+	/* Save the current stack */
+	movl	0x28(%esp), %ebx
+	movl	%esp, (%ebx)
+	/* Switch to the new stack. */
+	movl	0x24(%esp), %eax
+	movl	%eax, %esp
+	popa
+	ret
diff --git a/src/arch/486/timestamp.c b/src/arch/486/timestamp.c
new file mode 100644
index 0000000000..0696f1462e
--- /dev/null
+++ b/src/arch/486/timestamp.c
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <stdint.h>
+#include <timestamp.h>
+
+uint64_t timestamp_get(void)
+{
+return 1000000000;
+}
+
+int timestamp_tick_freq_mhz(void)
+{
+	/* Chipsets that have a constant TSC provide this value correctly. */
+	if (tsc_constant_rate())
+		return tsc_freq_mhz();
+
+	/* Filling tick_freq_mhz = 0 in timestamps-table will trigger
+	 * userspace utility to try deduce it from the running system.
+	 */
+	return 0;
+}
diff --git a/src/arch/486/verstage.c b/src/arch/486/verstage.c
new file mode 100644
index 0000000000..633fd8c877
--- /dev/null
+++ b/src/arch/486/verstage.c
@@ -0,0 +1,10 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/cpu.h>
+#include <main_decl.h>
+
+/* Provide an entry point for verstage when it's a separate stage. */
+asmlinkage void car_stage_entry(void)
+{
+	main();
+}
diff --git a/src/arch/486/wakeup.S b/src/arch/486/wakeup.S
new file mode 100644
index 0000000000..7462dadbe8
--- /dev/null
+++ b/src/arch/486/wakeup.S
@@ -0,0 +1,106 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#define WAKEUP_BASE		0x600
+#define RELOCATED(x)	(x - __wakeup + WAKEUP_BASE)
+
+/* CR0 bits */
+#define PE		(1 << 0)
+
+#if ENV_X86_64
+	.code64
+#else
+	.code32
+#endif
+
+	.globl __wakeup
+__wakeup:
+#if ENV_X86_64
+	/* When called in x86_64 mode, the resume vector is in %rdi
+	 * instead of the stack, save it in 4(%rsp) for the 32-bit code.
+	 * It's OK to overwrite the return address at (%rsp) because this
+	 * function doesn't return.
+	 */
+	mov	%edi, 4(%rsp)
+
+	xor	%rax,%rax
+	mov	%ss, %ax
+	push	%rax
+	mov	%rsp, %rax
+	add	$8, %rax
+	push	%rax
+	pushfq
+	push	$0x10
+	lea	3(%rip), %rax
+	push	%rax
+	iretq
+
+	.code32
+
+	/* disable paging */
+	mov	%cr0, %eax
+	btc	$31, %eax
+	mov	%eax, %cr0
+
+	/* disable long mode */
+	mov	$0xC0000080, %ecx
+	rdmsr
+	btc	$8, %eax
+	wrmsr
+#endif
+	/* First prepare the jmp to the resume vector */
+	mov	0x4(%esp), %eax	/* vector */
+	/* last 4 bits of linear addr are taken as offset */
+	andw	$0x0f, %ax
+	movw	%ax, (__wakeup_offset)
+	mov	0x4(%esp), %eax
+	/* the rest is taken as segment */
+	shr	$4, %eax
+	movw	%ax, (__wakeup_segment)
+
+	/* Activate the right segment descriptor real mode. */
+	ljmp	$0x28, $RELOCATED(1f)
+1:
+.code16
+	/* 16 bit code from here on... */
+
+	/* Load the segment registers w/ properly configured
+	 * segment descriptors. They will retain these
+	 * configurations (limits, writability, etc.) once
+	 * protected mode is turned off.
+	 */
+	mov	$0x30, %ax
+	mov	%ax, %ds
+	mov	%ax, %es
+	mov	%ax, %fs
+	mov	%ax, %gs
+	mov	%ax, %ss
+
+	/* Turn off protection */
+	movl	%cr0, %eax
+	andl	$~PE, %eax
+	movl	%eax, %cr0
+
+	/* Now really going into real mode */
+	ljmp	$0, $RELOCATED(1f)
+1:
+	movw	$0x0, %ax
+	movw	%ax, %ds
+	movw	%ax, %es
+	movw	%ax, %ss
+	movw	%ax, %fs
+	movw	%ax, %gs
+
+	/* This is a FAR JMP to the OS waking vector. The C code changed
+	 * the address to be correct.
+	 */
+	.byte 0xea
+
+__wakeup_offset = RELOCATED(.)
+	.word 0x0000
+
+__wakeup_segment = RELOCATED(.)
+	.word 0x0000
+
+	.globl __wakeup_size
+__wakeup_size:
+	.long . - __wakeup
diff --git a/src/arch/486/walkcbfs.S b/src/arch/486/walkcbfs.S
new file mode 100644
index 0000000000..2c77276d54
--- /dev/null
+++ b/src/arch/486/walkcbfs.S
@@ -0,0 +1,121 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+# #include <fmap_config.h>
+
+/* we use this instead of CBFS_HEADER_ALIGN because the latter is retired. */
+#define CBFS_ALIGNMENT 32
+
+#define CBFS_FILE_MAGIC 0
+#define CBFS_FILE_LEN (CBFS_FILE_MAGIC + 8)
+#define CBFS_FILE_TYPE (CBFS_FILE_LEN + 4)
+#define CBFS_FILE_CHECKSUM (CBFS_FILE_TYPE + 4)
+#define CBFS_FILE_OFFSET (CBFS_FILE_CHECKSUM + 4)
+
+#define CBFS_FILE_STRUCTSIZE (CBFS_FILE_OFFSET + 4)
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+
+#if 0 < (0x000fffff - CONFIG_ROM_SIZE + 1)
+#define COREBOOT_CBFS_START (0x000fffff - CONFIG_ROM_SIZE + 1 + 0)
+#else
+#define COREBOOT_CBFS_START 0
+#endif
+
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+
+#if 0 < (0xffffffff - CONFIG_ROM_SIZE + 1)
+#define COREBOOT_CBFS_START (0xffffffff - CONFIG_ROM_SIZE + 1 + 0)
+#else
+#define COREBOOT_CBFS_START 0
+#endif
+
+#endif
+
+.code32
+.section .init
+.global walkcbfs_asm
+
+/*
+ * input %esi: filename
+ * input %esp: return address (not pointer to return address!)
+ * output %eax: pointer to CBFS header
+ * clobbers %ebx, %ecx, %edi
+ */
+walkcbfs_asm:
+	cld
+
+	movl $COREBOOT_CBFS_START, %ebx
+
+	/* determine filename length */
+	mov $0, %eax
+1:
+	cmpb $0, (%eax,%esi)
+	jz 2f
+	add $1, %eax
+	jmp 1b
+2:
+	add $1, %eax
+walker:
+	mov 0(%ebx), %edi /* Check for LARCHIVE header */
+	cmp %edi, filemagic
+	jne searchfile
+	mov 4(%ebx), %edi
+	cmp %edi, filemagic+4
+	jne searchfile
+
+	/* LARCHIVE header found */
+	mov %ebx, %edi
+	add $CBFS_FILE_STRUCTSIZE, %edi /* edi = address of first byte after
+					 * struct cbfs_file
+					 */
+	mov %eax, %ecx
+	repe cmpsb
+	/* zero flag set if strings are equal */
+	jnz tryharder
+
+	/* we found it! */
+	mov %ebx, %eax
+	jmp *%esp
+
+tryharder:
+	sub %ebx, %edi
+	sub $CBFS_FILE_STRUCTSIZE, %edi /* edi = # of walked bytes */
+	sub %edi, %esi /* esi = start of filename */
+
+	/* ebx = ecx = (current+offset+len+ALIGN-1) & ~(ALIGN-1) */
+	mov CBFS_FILE_OFFSET(%ebx), %ecx
+	bswap %ecx
+	add %ebx, %ecx
+	mov CBFS_FILE_LEN(%ebx), %edi
+	bswap %edi
+	add %edi, %ecx
+	/* round by 64 bytes */
+	add $(CBFS_ALIGNMENT - 1), %ecx
+	and $~(CBFS_ALIGNMENT - 1), %ecx
+
+	/* if oldaddr >= addr, leave */
+	cmp %ebx, %ecx
+	jbe out
+
+	mov %ecx, %ebx
+
+check_for_exit:
+	/* if addr <= COREBOOT_END - 1, continue */
+#define FMAP_SECTION_COREBOOT_END (FMAP_SECTION_COREBOOT_START - 1 + FMAP_SECTION_COREBOOT_SIZE)
+
+	movl $FMAP_SECTION_COREBOOT_END, %ecx
+	cmp %ecx, %ebx
+	jbe walker
+
+out:
+	mov $0, %eax
+	jmp *%esp
+
+
+searchfile:
+	/* if filemagic isn't found, move forward 64 bytes */
+	add $CBFS_ALIGNMENT, %ebx
+	jmp check_for_exit
+
+filemagic:
+	.ascii "LARCHIVE"
diff --git a/src/cpu/486/486.c b/src/cpu/486/486.c
new file mode 100644
index 0000000000..bf5e73d31e
--- /dev/null
+++ b/src/cpu/486/486.c
@@ -0,0 +1,59 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+/*
+https://elixir.bootlin.com/coreboot/4.19/source/src/arch/x86/assembly_entry.S#L66
+https://elixir.bootlin.com/coreboot/4.19/source/src/arch/x86/romstage.c#L8
+	car_stage_entry
+https://elixir.bootlin.com/coreboot/4.19/source/src/cpu/intel/car/romstage.c#L18
+	romstage_main
+	mainboard_romstage_entry
+*/
+
+#include <console/console.h>
+#include <cpu/cpu.h>
+#include <cpu/486/cache.h>
+#include <cpu/486/name.h>
+#include <device/device.h>
+#include <string.h>
+
+unsigned long tsc_freq_mhz(void);
+
+unsigned long tsc_freq_mhz(void) {
+	return 133333333;
+}
+
+static void cpu_486_init(struct device *dev)
+{
+	char processor_name[49];
+
+	/* Turn on caching if we haven't already */
+	enable_cache();
+
+	/* Print processor name */
+	if (cpu_have_cpuid()) {
+		fill_processor_name(processor_name);
+	} else {
+		//TODO pre cpuid 486 from DX? 0x400+revision ID
+		strncpy(processor_name, "pre-CPUID", 48);
+	}
+
+	printk(BIOS_INFO, "CPU: %s.\n", processor_name);
+}
+
+static struct device_operations cpu_dev_ops = {
+	.init = cpu_486_init,
+};
+
+static const struct cpu_device_id cpu_table[] = {
+	{ X86_VENDOR_ANY, 0, 0 },
+	CPU_TABLE_END
+};
+
+static const struct cpu_driver driver __cpu_driver = {
+	.ops      = &cpu_dev_ops,
+	.id_table = cpu_table,
+};
+
+struct chip_operations cpu_486_ops = {
+	CHIP_NAME("486 CPU")
+};
diff --git a/src/cpu/486/Kconfig b/src/cpu/486/Kconfig
new file mode 100644
index 0000000000..d451691308
--- /dev/null
+++ b/src/cpu/486/Kconfig
@@ -0,0 +1,53 @@
+## SPDX-License-Identifier: GPL-2.0-only
+
+config CPU_486
+	bool
+	select ARCH_486
+	select USE_MARCH_486
+
+if CPU_486
+
+choice
+	prompt "SMM support"
+	default CPU_486_ASEG_SMM
+
+config CPU_486_NO_SMM
+	bool "No SMM"
+	select NO_SMM
+
+config CPU_486_ASEG_SMM
+	bool "SMM in ASEG"
+	select SMM_ASEG
+
+config CPU_486_TSEG_SMM
+	bool "SMM in TSEG"
+	select SMM_TSEG
+
+endchoice
+
+
+#TODO move into ali northbridge, right above max RAM for CPU, for chipset it is 0 due to aliasing
+#shouldn't be at start of the block (could be overridden by DRAM/L2 check)
+
+#TODO NOTICE, for DRAM detection it must be above maximal single bank size or not at single "1" bit boundary
+
+config DCACHE_RAM_BASE
+	hex
+#	default 0x01000000
+#	default 0x04560000
+#	default 0x00200000
+#	default 0x08000000
+	default 0x001a0000
+
+config DCACHE_RAM_SIZE
+	hex
+	default 0x02000
+
+config DCACHE_BSP_STACK_SIZE
+	hex
+	default 0x1000
+
+config HEAP_SIZE
+	default 0x8000
+
+endif
diff --git a/src/cpu/486/Makefile.inc b/src/cpu/486/Makefile.inc
new file mode 100644
index 0000000000..8ba8b17a68
--- /dev/null
+++ b/src/cpu/486/Makefile.inc
@@ -0,0 +1,32 @@
+## SPDX-License-Identifier: GPL-2.0-or-later
+
+bootblock-y += cache_as_ram.S
+
+#TODO maybe add https://elixir.bootlin.com/coreboot/4.19/source/src/cpu/intel/model_206ax/bootblock.c#L70
+#void bootblock_early_cpu_init(void) ?
+
+#done https://elixir.bootlin.com/coreboot/4.19/source/src/cpu/intel/car/bootblock.c#L10
+
+bootblock-y += bootblock.c
+
+romstage-y += romstage.c
+
+ramstage-y += 486.c
+
+#TODO are unused functions automatically removed?
+bootblock-y += delay_pit.c
+ramstage-y += delay_pit.c
+romstage-y += delay_pit.c
+verstage_x86-y += delay_pit.c
+postcar-y += delay_pit.c
+smm-y += delay_pit.c
+
+postcar-y += exit_car.S
+
+ramstage-y += name.c
+
+bootblock-y += entry32.S
+bootblock-y += entry16.S
+bootblock-y += reset16.S
+
+ramstage-y += sp_init.c
diff --git a/src/cpu/486/bootblock.c b/src/cpu/486/bootblock.c
new file mode 100644
index 0000000000..f6f29a6c4e
--- /dev/null
+++ b/src/cpu/486/bootblock.c
@@ -0,0 +1,69 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/bootblock.h>
+#include <arch/io.h>
+#include <cpu/cpu.h>
+#include <halt.h>
+#include <stdint.h>
+#include <bootblock_common.h>
+#include <console/console.h>
+#include <cpu/486/bist.h>
+
+void __weak bootblock_early_northbridge_init(void) { }
+void __weak bootblock_early_southbridge_init(void) { }
+
+
+void bootblock_early_cpu_init(void)
+{
+	//detect cpu type
+	//detect cpuid exists
+}
+
+
+void bootblock_soc_early_init(void)
+{
+	post_code('E');
+	bootblock_early_northbridge_init();
+	post_code('F');
+	bootblock_early_southbridge_init();
+	post_code('G');
+	bootblock_early_cpu_init();
+	post_code('H');
+}
+
+
+asmlinkage void bootblock_c_entry_bist(uint64_t base_timestamp, uint32_t bist)
+{
+#if 0
+	asm volatile(
+		"movb $0x39, %%al\n\t"     // Move the character to AL register
+		"movw $0x3F8, %%dx\n\t" // Load 0x3F8 (COM1 port) into DX register
+		"outb %%al, %%dx"       // Send the character to COM1 port
+		:::
+	);
+#endif
+
+	post_code('C');
+
+	/* Halt if there was a built in self test failure */
+	if (bist) {
+		//NOTICE only error console init
+		console_init();
+		report_bist_failure(bist);
+	}
+
+	post_code('I');
+
+	// asm volatile(
+	// 	"mov %0, %%al\n\t"     // Move the character to AL register
+	// 	"mov $0x3F8, %%dx\n\t" // Load 0x3F8 (COM1 port) into DX register
+	// 	"out %%al, %%dx"       // Send the character to COM1 port
+	// 	:
+	// 	: "r" (xxx)	//output constraint r = readonly
+	// 	: "%al", "%dx"	//clobbered registers
+	// );
+
+
+	/* Call lib/bootblock.c main() */
+	bootblock_main_with_basetime(base_timestamp);
+}
diff --git a/src/cpu/486/cache_as_ram.S b/src/cpu/486/cache_as_ram.S
new file mode 100644
index 0000000000..66a1ab6ede
--- /dev/null
+++ b/src/cpu/486/cache_as_ram.S
@@ -0,0 +1,684 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cpu/486/post_code.h>
+#include <cpu/486/cache.h>
+
+#define UMC_PCI_BDFR(BUS, DEV, FN, REG) ( \
+	(1 << 31) | \
+	(((BUS) & 0xff) << 16) | \
+	(((DEV) & 0x1f) << 11) | \
+	(((FN)  & 0x07) << 8) | \
+	(((REG)  & 0xff) << 0) \
+)
+
+#define pci_write(BDFR, REG_IMM)	\
+	movw	$0xcf8, %dx;	\
+	movl	$ BDFR, %eax;	\
+	outl	%eax, %dx;	\
+	movw	$0xcfc, %dx;	\
+	and	$0x3, %al;	\
+	add	%al, %dl;	\
+	movb	REG_IMM, %al;	\
+	outb	%al, %dx
+
+//value returned in AL
+#define pci_read(BDFR)		\
+	movw	$0xcf8, %dx;	\
+	movl	$ BDFR, %eax;	\
+	outl	%eax, %dx;	\
+	movw	$0xcfc, %dx;	\
+	and	$0x3, %al;	\
+	add	%al, %dl;	\
+	inb	%dx, %al
+
+#define UART_BASE	0x3f8
+
+#define send_uart(base)		\
+	movw	$(base+0), %dx;	\
+	outb	%al, %dx;	\
+1:	movw	$(base+5), %dx;	\
+	inb	%dx, %al;	\
+	testb	$0x20, %al;	\
+	jz	1b
+
+
+
+/* TODO use only vanilla
+
+https://elixir.bootlin.com/coreboot/4.20.1/source/src/commonlib/include/commonlib/console/post_codes.h
+*/
+#include <cpu/intel/post_codes.h>
+
+#define CBFS_FILE_MAGIC 0
+#define CBFS_FILE_LEN (CBFS_FILE_MAGIC + 8)
+#define CBFS_FILE_TYPE (CBFS_FILE_LEN + 4)
+#define CBFS_FILE_CHECKSUM (CBFS_FILE_TYPE + 4)
+#define CBFS_FILE_OFFSET (CBFS_FILE_CHECKSUM + 4)
+
+.section .init, "ax", @progbits
+.code32
+
+.global bootblock_pre_c_entry
+bootblock_pre_c_entry:
+
+cache_as_ram:
+	post_code(/*POST_BOOTBLOCK_CAR*/ '4')
+
+
+#if 0
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+
+/*
+NOTICE
+command sequence (bytes)
+	OP VALUE MSB3 mSB2 lSB1 LSB0
+return
+	1 byte, either read value, or dummy/ack 0x42
+OP:
+	q	quit
+	r/w	read/write memory
+	i/o	read/write port
+	C/c	enable/disable L1 cache
+	!	invalidate L1
+	?	writeback invalidate L1
+	p/P	read/write PCI
+	l/L	loop (N*65536) write 0/0xffffffff to specified memory
+*/
+
+
+#if 1
+	/* init uart */
+	movw	$(UART_BASE+1), %dx
+	movb	$0x0, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+3), %dx
+	movb	$0x80, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+0), %dx
+	movb	$1, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+1), %dx
+	movb	$0x0, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+3), %dx
+	inb	%dx, %al
+	andb	$0x7f, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+1), %dx
+	movb	$0x00, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+2), %dx
+	movb	$0xc7, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+3), %dx
+	movb	$0x03, %al
+	outb	%al, %dx
+	movw	$(UART_BASE+4), %dx
+	movb	$0x01, %al
+	outb	%al, %dx
+#endif
+
+#if 0
+	movw	$(UART_BASE+5), %dx
+	inb	%dx, %al
+	test	$0x10, %al	# break indicated
+	jz	exit_poker
+#elif 0
+	movw	$(UART_BASE+6), %dx
+	inb	%dx, %al
+	test	$0x80, %al	# activated carrier detect
+	# test	$0x20, %al	# activated DSR
+	# test	$0x10, %al	# activated CTS
+	jz	exit_poker
+#endif
+
+	mov	$'P', %al
+	send_uart(UART_BASE)
+	mov	$'O', %al
+	send_uart(UART_BASE)
+	mov	$'K', %al
+	send_uart(UART_BASE)
+	mov	$'E', %al
+	send_uart(UART_BASE)
+	mov	$'R', %al
+	send_uart(UART_BASE)
+	mov	$'>', %al
+	send_uart(UART_BASE)
+
+poker:
+	xor	%edi, %edi	#command
+	xor	%esi, %esi	#parameter
+	#edi .. esi
+	# op value .. a3 a2 a1 a0
+
+	mov	$6, %ecx
+
+	# wait until rx
+wait_rx:
+	mov	$(UART_BASE+5), %dx
+	in	%dx, %al
+	test	$1, %al
+	jz	wait_rx
+
+	# read byte
+	mov	$(UART_BASE+0), %dx
+	in	%dx, %al
+
+	mov	%esi, %ebx
+	mov 	%al, %bl
+	mov	%ebx, %esi
+
+	dec	%ecx
+	jcxz	process
+
+	#count src dst
+	# src >> dst
+
+	shld	$8, %esi, %edi
+	shl	$8, %esi
+
+	jmp	wait_rx
+
+process:
+
+	#BX command (BH op, BL value)
+	#EBP parameter
+
+	mov	%edi, %ebx
+
+	# quit
+	cmp	$'q', %bh
+	je	exit_poker
+
+	# read/write memory
+	cmp	$'r', %bh
+	je	cmd_read_addr
+	cmp	$'w', %bh
+	je	cmd_write_addr
+
+	# read/write port
+	cmp	$'i', %bh
+	je	cmd_read_port
+	cmp	$'o', %bh
+	je	cmd_write_port
+
+	# cache
+	cmp	$'C', %bh
+	je	cmd_l1_enable
+	cmp	$'c', %bh
+	je	cmd_l1_disable
+	cmp	$'!', %bh
+	je	cmd_l1_invalidate
+	cmp	$'?', %bh
+	je	cmd_l1_writebackinvalidate
+
+	# pci
+	cmp	$'p', %bh
+	je	cmd_read_pci
+	cmp	$'P', %bh
+	je	cmd_write_pci
+
+	# loop write memory
+	cmp	$'l', %bh
+	je	cmd_loop_write_0
+	cmp	$'L', %bh
+	je	cmd_loop_write_ffffffff
+
+	jmp	poker
+
+send_reply:
+	# data in al, waits automatically
+	send_uart(UART_BASE)
+	jmp	poker
+
+cmd_read_addr:
+	mov	%ds:(%esi), %al
+	jmp	send_reply
+
+cmd_write_addr:
+	mov	%bl, %ds:(%esi)
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_read_port:
+	mov	%esi, %edx
+	in	%dx, %al
+	jmp	send_reply
+
+cmd_write_port:
+	mov	%bl, %al
+	mov	%esi, %edx
+	out	%al, %dx
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_l1_enable:
+	movl	%cr0, %eax
+	andl	$(~(CR0_CacheDisable | CR0_NoWriteThrough)), %eax
+	movl	%eax, %cr0
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_l1_disable:
+	movl	%cr0, %eax
+	orl	$(CR0_CacheDisable | CR0_NoWriteThrough), %eax
+	movl	%eax, %cr0
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_l1_invalidate:
+	invd
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_l1_writebackinvalidate:
+	wbinvd			#NOTICE will crash on WT-only 486
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_read_pci:
+	movw	$0xcf8, %dx
+	movl	%esi, %eax
+	outl	%eax, %dx
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	inb	%dx, %al
+
+	jmp	send_reply
+
+cmd_write_pci:
+	movw	$0xcf8, %dx
+	movl	%esi, %eax
+	outl	%eax, %dx
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	mov	%bl, %al	#write the value
+	outb	%al, %dx
+
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_loop_write_0:
+	xor	%ecx, %ecx
+	mov	%bl, %cl
+	shl	$16, %ecx
+1:
+	movl	$0, %ds:(%esi)
+	loop	1b
+
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+cmd_loop_write_ffffffff:
+	xor	%ecx, %ecx
+	mov	%bl, %cl
+	shl	$16, %ecx
+1:
+	movl	$0xffffffff, %ds:(%esi)
+	loop	1b
+
+	mov	$0x42, %al	#dummy/ack reply
+	jmp	send_reply
+
+# # # # # # # # # # # # # # #
+
+exit_poker:
+
+#endif
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+# POKER POKER POKER POKER POKER POKER POKER POKER POKER
+
+
+# set up L1 cacheable range (usually it means to define fake RAM area)
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	/* ALI specific, NB will not generate /KEN in noncacheable regions, probably everything outside RAM */
+
+	/*unlock chipset*/
+	movb	$3, %al
+	outb	%al, $0x22
+	movb	$0xc5, %al
+	outb	%al, $0x23
+
+	/*enable /KEN generation for L1*/
+	movb	$0x16, %al
+	outb	%al, $0x22
+	movb	$(0x1 | 0x30), %al
+	outb	%al, $0x23
+
+	/* FAKE max RAM, so KEN gets generated ... TODO check */
+	/* when 486 chipset resets the RAM is lost anyway? */
+	movb	$0x10, %al
+	outb	%al, $0x22
+	movb	$0x44, %al
+	outb	%al, $0x23
+
+	movb	$0x11, %al
+	outb	%al, $0x22
+	movb	$0x44, %al
+	outb	%al, $0x23
+
+	/* TODO ?? enable 0xe0000 seems to be used before northbridge init */
+	/* bootblock_soc_early_init which sets northbridge is called from e0000 region*/
+	/* nevermind fffe0000 is not decoded in ALI and e0000 is not used in CB*/
+	movb	$0x12, %al
+	outb	%al, $0x22
+	movb	$0x81, %al
+	outb	%al, $0x23
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+
+
+#if 0	/* ========================= PCI DUMP ================ */
+	movb	$0x0, %cl
+pci_dump_loop:
+	movw	$0xcf8, %dx
+	movl	$ UMC_PCI_BDFR(0, 0x12, 1, 0), %eax
+	movb	%cl, %al
+	outl	%eax, %dx
+
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	inb	%dx, %al
+
+	send_uart(UART_BASE)
+
+	inc	%cl
+
+	//overflow
+	cmp	$0x00, %cl
+//	cmp	$0xb0, %cl
+	jne	pci_dump_loop
+#endif	/* ========================= PCI DUMP ================ */
+
+	/*
+	expects from poweron/reset:
+		L2 disabled
+		no forced L2 hit
+		disabled ROM shadow, ROM cacheable
+	*/
+
+	/* define fake RAM 4x 32MB */
+	/* CONFIG_DCACHE_RAM_BASE must be in range to L1 able to work as CAR */
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x52), $0x77)
+
+	/* 2 double sided banks in both */
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x53), $0x0f)
+
+	/* TODO EXPERIMENTAL set L1 bit ??? */
+	# # # pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x51), $0x02)
+
+#endif
+
+#if 0
+	post_code(/*POST_SOC_ENABLE_CACHE*/ '5')
+#endif
+
+	/*
+	https://en.wikipedia.org/wiki/Control_register#CR0
+	intel 486 pdf page 53
+	*/
+
+	/* Enable cache (CR0.CD = 0, CR0.NW = 0) */
+	movl	%cr0, %eax
+	andl	$(~(CR0_CacheDisable | CR0_NoWriteThrough)), %eax
+	invd
+	movl	%eax, %cr0
+
+	/*
+		p19 i486
+		every mem write now goes outside CPU
+		read will fill L1
+	*/
+
+	post_code(/*POST_SOC_FILL_CACHE*/ '6')
+
+	/*
+	address is defined in CONFIG_DCACHE_RAM_BASE
+	must be in a defined RAM range to be captured in L1
+	shouldn't be in first 1MB so it won't interfere with ROMs
+	*/
+
+	/* Fill cache lines */
+	movl	$_car_region_start, %esi
+	movl	$_car_region_end, %ecx
+	sub	%esi, %ecx
+	shr	$2, %ecx
+	cld
+	rep	lodsl	/* cld? DF=0 */
+
+	post_code(POST_SOC_DISABLE_CACHE)	/* '-' */
+
+	/* Enable Cache-as-RAM mode by disabling cache. */
+	movl	%cr0, %eax
+	orl	$(CR0_CacheDisable | CR0_NoWriteThrough), %eax
+	movl	%eax, %cr0
+
+	/* NOW in cache as RAM */
+
+	post_code('A')
+
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	/* disable L1 /ken generation in chipset */
+	movb	$0x16, %al
+	outb	%al, $0x22
+	movb	$0x30, %al
+	outb	%al, $0x23
+
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	/* disable RAM (L1 CAR is now filled) */
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x52), $0x00)
+	pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x53), $0x00)
+#endif
+
+
+
+#if 0
+/*
+FORCE table
+
+linux
+50: fb a4 e6 8f 03 c1 ff 0f ff 0f 0d 2c e0 30 00 ff
+after this
+50: fb a4 e6 8f 01 00 ff 0f ff 0f 0d 00 e0 30 00 ff
+*/
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x04), $0x0f)
+# pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x50), $0xfb)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x51), $0xa4)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x52), $0xe6)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x53), $0x8f)
+//pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x54), $0x03)
+//pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x55), $0xc1)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x56), $0xff)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x57), $0x0f)
+//pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x58), $0xff)
+//pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x59), $0x0f)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x5a), $(0x0d /*| 0x40*/))	//?force L2 hit
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x5b), $0x2c)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x5c), $0xe0)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x5d), $0x30)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x60), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x61), $0xf4)
+pci_write(UMC_PCI_BDFR(0, 0x10, 0, 0x62), $0x01)
+////////////////////////////
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x04), $0x07)	//0xf with special cycle
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x40), $0x04)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x41), $0x42)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x42), $0x08)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x43), $0x9a)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x44), $0xbc)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x45), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x46), $0x1f)	//disabled INTC
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x47), $0x7f)
+# pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x50), $0x80 /*| 1*/)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x51), $0x40 /*| 1*/)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x56), $0x01)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x57), $0x30)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x70), $0x6f)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x71), $0xff)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x72), $0x01)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x90), $0x02)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x91), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0x92), $0x1f)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa0), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa1), $0x80)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa2), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa3), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa4), $0x81)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa5), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa6), $0x00)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa7), $0xef)
+pci_write(UMC_PCI_BDFR(0, 0x12, 0, 0xa8), $0x28)
+#endif
+
+
+post_code('D')
+
+
+#if 0	/* ========================= PCI DUMP ================ */
+	movb	$0x0, %cl
+pci_dump_loop2:
+	movw	$0xcf8, %dx
+	movl	$ UMC_PCI_BDFR(0, 0x10, 0, 0), %eax
+	movb	%cl, %al
+	outl	%eax, %dx
+
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	inb	%dx, %al
+
+	send_uart(UART_BASE)
+
+	inc	%cl
+
+	cmp	$0x80, %cl
+	jne	pci_dump_loop2
+#endif /* PCI DUMP */
+
+	/*
+		now no write goes outside (to RAM) if in hit region
+		cache lines will not fill
+		NW must be 1, or else CPU will keeps writing to RAM even on hits
+	*/
+
+	/* Clear the cache memory region. There should not be any traffic to RAM */
+	movl	$_car_region_start, %edi
+	movl	$_car_region_end, %ecx
+	sub	%edi, %ecx
+	shr	$2, %ecx
+
+	xorl	%eax, %eax
+	/* movl	$0x12345678, %eax */
+
+	cld
+	rep	stosl	/* cld? DF=0 */
+
+	post_code(/*POST_BOOTBLOCK_BEFORE_C_ENTRY*/ 'X')
+
+	//NOTICE _ecar_stack moved lower in linker script
+	movl	$_ecar_stack, %esp
+
+	/* Align the stack and keep aligned for call to bootblock_c_entry() */
+	and	$0xfffffff0, %esp	/*lower 4 bits always 0*/
+	sub	$4, %esp		/*== push 4 bytes*/
+
+	/*
+		Restore the BIST result, should be still in EBP
+		set in entry32 bootblock_protected_mode_entry
+
+		no DX stored, could be still intact? unless outb/inb with dx
+		can be compressed to eax (BIST != 0 failed -> halt)
+	*/
+
+	pushl	%ebp
+
+	/* Dummy timestamp - not implemented on 486 */
+	pushl	$0
+	pushl	$0
+
+
+	//10:08000ff0
+	post_code('{')
+
+#if 0
+	mov	%ss,%ax
+	send_uart(UART_BASE)
+	mov	%ah,%al
+	send_uart(UART_BASE)
+
+	mov	%esp,%eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+
+
+	pushl	$0x42434445
+	pop	%eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+#endif
+
+//////
+
+#if 0
+	call	test
+test:
+	pop	%eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+	shr $0x8, %eax
+	send_uart(UART_BASE)
+#endif
+
+
+	post_code('}')
+
+#if 0
+	//quick search debug block
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	rdtsc
+#endif
+
+
+	#if 0
+	post_code(/*POST_BOOTBLOCK_BEFORE_C_ENTRY*/ '8')
+	#endif
+
+/* before_c_entry: */
+	call	bootblock_c_entry_bist
+	/* Never returns */
+.Lhlt:
+	post_code(/*POST_DEAD_CODE*/ 'H')
+	hlt
+	jmp	.Lhlt
+
+pagetables_name:
+	.string "pagetables"
diff --git a/src/cpu/486/delay_pit.c b/src/cpu/486/delay_pit.c
new file mode 100644
index 0000000000..69c57cce3e
--- /dev/null
+++ b/src/cpu/486/delay_pit.c
@@ -0,0 +1,85 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <arch/io.h>
+#include <cpu/cpu.h>
+#include <delay.h>
+#include <stdint.h>
+#include <thread.h>
+
+#define CLOCK_TICK_RATE	1193180U /* Underlying HZ */
+
+
+void init_timer(void)
+{
+	printk(BIOS_DEBUG, "Init PIT timer\n");
+}
+
+
+void udelay(unsigned int us)
+{
+	if (!thread_yield_microseconds(us))
+		return;
+
+	if (us ==0 ) return;
+
+	/* Set the Gate high, disable speaker */
+	outb((inb(0x61) & ~0x02) | 0x01, 0x61);
+
+	outb(0xb0, 0x43);	/* binary, mode 0, LSB/MSB, Ch 2 */
+
+	do {
+		unsigned int current_us = (us > 60000) ? 60000 : us;
+
+		outb(current_us & 0xff, 0x42);	/* LSB of count */
+		outb(current_us	>> 8, 0x42);	/* MSB of count */
+
+		while (!(inb(0x61) & (1<<5))) {
+			cpu_relax();
+		}
+
+		us -= current_us;
+	} while (us > 0);
+}
+
+#if CONFIG(PIT_MONOTONIC_TIMER)
+#include <timer.h>
+
+static struct monotonic_counter {
+	int initialized;
+	struct mono_time time;
+	uint64_t last_value;
+} mono_counter;
+
+void timer_monotonic_get(struct mono_time *mt)
+{
+
+	*mt = 0;
+#if 0
+	uint64_t current_tick;
+	uint64_t ticks_elapsed;
+	unsigned long ticks_per_usec;
+
+	if (!mono_counter.initialized) {
+		init_timer();
+		mono_counter.last_value = rdtscll();
+		mono_counter.initialized = 1;
+	}
+
+	current_tick = rdtscll();
+	ticks_elapsed = current_tick - mono_counter.last_value;
+	ticks_per_usec = tsc_freq_mhz();
+
+	/* Update current time and tick values only if a full tick occurred. */
+	if (ticks_elapsed >= ticks_per_usec) {
+		uint64_t usecs_elapsed;
+
+		usecs_elapsed = ticks_elapsed / ticks_per_usec;
+		mono_time_add_usecs(&mono_counter.time, (long)usecs_elapsed);
+		mono_counter.last_value = current_tick;
+	}
+
+	/* Save result. */
+	*mt = mono_counter.time;
+#endif
+}
+#endif
diff --git a/src/cpu/486/entry16.S b/src/cpu/486/entry16.S
new file mode 100644
index 0000000000..071693b4aa
--- /dev/null
+++ b/src/cpu/486/entry16.S
@@ -0,0 +1,267 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+
+/*
+ * This software and ancillary information (herein called SOFTWARE)
+ * called LinuxBIOS is made available under the terms described here.
+ *
+ * The SOFTWARE has been approved for release with associated
+ * LA-CC Number 00-34. Unless otherwise indicated, this SOFTWARE has
+ * been authored by an employee or employees of the University of
+ * California, operator of the Los Alamos National Laboratory under
+ * Contract No. W-7405-ENG-36 with the U.S. Department of Energy.
+ *
+ * The U.S. Government has rights to use, reproduce, and distribute this
+ * SOFTWARE. The public may copy, distribute, prepare derivative works
+ * and publicly display this SOFTWARE without charge, provided that this
+ * Notice and any statement of authorship are reproduced on all copies.
+ *
+ * Neither the Government nor the University makes any warranty, express
+ * or implied, or assumes any liability or responsibility for the use of
+ * this SOFTWARE.  If SOFTWARE is modified to produce derivative works,
+ * such modified SOFTWARE should be clearly marked, so as not to confuse
+ * it with the version available from LANL.
+ *
+ */
+
+
+/* Start code to put an i386 or later processor into 32-bit protected mode.
+ */
+
+#include <arch/rom_segs.h>
+#include <cpu/486/post_code.h>
+
+
+#define send_uart		\
+	movw	$0x3f8, %dx;	\
+	outb	%al, %dx;	\
+1:	movw	$0x3fd, %dx;	\
+	inb	%dx, %al;	\
+	testb	$0x20, %al;	\
+	jz	1b
+
+
+
+.section .init._start, "ax", @progbits
+
+/* Symbol _start16bit must reachable from the reset vector, and be aligned to
+ * 4kB to start AP CPUs with Startup IPI message without RAM.
+ */
+.code16
+.globl _start16bit
+.type _start16bit, @function
+
+_start16bit:
+	cli
+	/* Save the BIST result */
+	movl	%eax, %ebp
+
+	post_init
+	post_code(/*POST_RESET_VECTOR_CORRECT*/ 's')
+
+	/* IMMEDIATELY invalidate the translation lookaside buffer (TLB) before
+	 * executing any further code. Even though paging is disabled we
+	 * could still get false address translations due to the TLB if we
+	 * didn't invalidate it. Thanks to kmliu@sis.com.tw for this TLB fix.
+	 */
+
+	xorl	%eax, %eax
+	movl	%eax, %cr3    /* Invalidate TLB*/
+
+	/* Invalidating the cache here seems to be a bad idea on
+	 * modern processors.  Don't.
+	 * If we are hyperthreaded or we have multiple cores it is bad,
+	 * for SMP startup.  On Opterons it causes a 5 second delay.
+	 * Invalidating the cache was pure paranoia in any event.
+	 * If your CPU needs it you can write a CPU dependent version of
+	 * entry16.inc.
+	 */
+
+	 //486 is not a modern processor :-D
+	 invd
+
+	/* check if chipset is configured
+	 * = segment E/F is shadowed in RAM -> contains seabios -> jump there
+	 */
+#if CONFIG(NORTHBRIDGE_ALI_M1489)
+	//TODO
+#elif CONFIG(NORTHBRIDGE_UMC_UM8881)
+	//if 0x54 and 0x55 has shadow set -> guess the chipset is configured
+	//NOTICE cannot check ram size register, minimum RAM is defined at power on
+
+	movw	$0xcf8, %dx
+	movl	$0x80008054, %eax	//BDFR: 0:0x10:0
+	outl	%eax, %dx
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	inb	%dx, %al
+
+	test	$0x01, %al
+	jz	no_soft_reset	/* segment E not shadowed */
+
+	movw	$0xcf8, %dx
+	movl	$0x80008055, %eax	//BDFR: 0:0x10:0
+	outl	%eax, %dx
+	movw	$0xcfc, %dx
+	and	$0x3, %al
+	add	%al, %dl
+	inb	%dx, %al
+
+	test	$0x80, %al
+	jz	no_soft_reset	/* segment F not shadowed, global shadow disabled */
+
+
+#if 1
+	//read register 0xf of RTC
+	inb	$0x70, %al
+	and	$0x80, %al
+	or	$0xf, %al
+	outb	%al, $0x70
+	inb	$0x71, %al
+	cmp	$0, %al
+	jz	no_soft_reset
+#endif
+
+
+
+	//also if no cmos/resume != 0 -> hard reset
+
+#if 0
+	jmp	no_soft_reset	//TEMP
+#endif
+
+	//chipset is configured -> soft reset (CPU only reset)
+	//jump to shadow (seabios or other payload??)
+
+	post_code(/*POST_RESET_VECTOR_CORRECT*/ 'W')
+
+#if 0
+	mov	%cr2, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+#endif
+
+
+	/* Restore BIST to %eax */
+	movl	%ebp, %eax
+
+	//TODO restore EDX?
+
+	ljmpl	$0xf000, $0xfff0
+
+no_soft_reset:
+#endif
+
+	/* Note: gas handles memory addresses in 16 bit code very poorly.
+	 * In particular it doesn't appear to have a directive allowing you
+	 * associate a section or even an absolute offset with a segment register.
+	 *
+	 * This means that anything except cs:ip relative offsets are
+	 * a real pain in 16 bit mode.  And explains why it is almost
+	 * impossible to get gas to do lgdt correctly.
+	 *
+	 * One way to work around this is to have the linker do the
+	 * math instead of the assembler.  This solves the very
+	 * practical problem of being able to write code that can
+	 * be relocated.
+	 *
+	 * An lgdt call before we have memory enabled cannot be
+	 * position independent, as we cannot execute a call
+	 * instruction to get our current instruction pointer.
+	 * So while this code is relocatable it isn't arbitrarily
+	 * relocatable.
+	 *
+	 * The criteria for relocation have been relaxed to their
+	 * utmost, so that we can use the same code for both
+	 * our initial entry point and startup of the second CPU.
+	 * The code assumes when executing at _start16bit that:
+	 * (((cs & 0xfff) == 0) and (ip == _start16bit & 0xffff))
+	 * or
+	 * ((cs == anything) and (ip == 0)).
+	 *
+	 * The restrictions in reset16.inc mean that _start16bit initially
+	 * must be loaded at or above 0xffff0000 or below 0x100000.
+	 *
+	 * The linker scripts computes gdtptr16_offset by simply returning
+	 * the low 16 bits.  This means that the initial segment used
+	 * when start is called must be 64K aligned.  This should not
+	 * restrict the address as the ip address can be anything.
+	 *
+	 * Also load an IDT with NULL limit to prevent the 16bit IDT being used
+	 * in protected mode before c_start.S sets up a 32bit IDT when entering
+	 * RAM stage. In practise: CPU will shutdown on any exception.
+	 * See IA32 manual Vol 3A 19.26 Interrupts.
+	 */
+
+	movw	%cs, %ax
+	shlw	$4, %ax
+	movw	$nullidt_offset, %bx
+	subw	%ax, %bx
+	lidt	%cs:(%bx)
+	movw	$gdtptr_offset, %bx
+	subw	%ax, %bx
+	lgdtl	%cs:(%bx)
+
+	post_code('T')
+
+	movl	%cr0, %eax
+	andl	$0x7FFAFFD1, %eax /* PG,AM,WP,NE,TS,EM,MP = 0 */
+	orl	$0x60000001, %eax /* CD, NW, PE = 1 */
+	movl	%eax, %cr0
+
+	//pc2005 test CS
+	post_code('A')
+	post_code('{')
+
+	mov	%cs, %bx
+
+	movb	%bl, %al
+	movw	$0x3f8, %dx
+	outb	%al, %dx
+1:	movw	$0x3fd, %dx
+	inb	%dx, %al
+	testb	$0x20, %al
+	jz	1b
+
+	movb	%bh, %al
+	movw	$0x3f8, %dx
+	outb	%al, %dx
+1:	movw	$0x3fd, %dx
+	inb	%dx, %al
+	testb	$0x20, %al
+	jz	1b
+
+	post_code('}')
+
+	/* Restore BIST to %eax */
+	movl	%ebp, %eax
+
+/*
+	nop
+	nop
+	nop
+	nop
+	rdtsc*/
+
+
+	/* Now that we are in protected mode jump to a 32 bit code segment. */
+	ljmpl	$ROM_CODE_SEG, $bootblock_protected_mode_entry
+
+	/**
+	 * The gdt is defined in gdt_init.S, it has a 4 Gb code segment
+	 * at 0x08, and a 4 GB data segment at 0x10;
+	 */
+__gdtptr:
+	.long	gdtptr
+
+.align	4
+.globl nullidt
+nullidt:
+	.word	0	/* limit */
+	.long	0
+	.word	0
diff --git a/src/cpu/486/entry32.S b/src/cpu/486/entry32.S
new file mode 100644
index 0000000000..40595df05e
--- /dev/null
+++ b/src/cpu/486/entry32.S
@@ -0,0 +1,75 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+
+/* For starting coreboot in protected mode */
+
+/*
+ * This is the modern bootblock. It prepares the system for C environment runtime
+ * setup. The actual setup is done by hardware-specific code.
+ *
+ * It provides a bootflow similar to other architectures, and thus is considered
+ * to be the modern approach.
+ *
+ */
+
+#include <arch/rom_segs.h>
+#include <cpu/486/cr.h>
+#include <cpu/486/post_code.h>
+
+.section .init, "ax", @progbits
+
+	.code32
+/*
+ *	When we come here we are in protected mode.
+ *	NOTE aligned to 4 so that we are sure that the prefetch
+ *	cache will be reloaded.
+ */
+	.align	4
+
+.globl bootblock_protected_mode_entry
+bootblock_protected_mode_entry:
+
+	/* Save the BIST value */
+	movl	%eax, %ebp
+
+	post_code(/*POST_ENTER_PROTECTED_MODE*/ '3')
+
+	movw	$ROM_DATA_SEG, %ax
+	movw	%ax, %ds
+	movw	%ax, %es
+	movw	%ax, %ss
+	xor	%ax, %ax /* zero out the gs and fs segment index */
+	movw	%ax, %fs
+	movw	%ax, %gs /* Will be used for cpu_info */
+
+	/* Restore the BIST value to %eax */
+	movl	%ebp, %eax
+
+#if CONFIG(BOOTBLOCK_DEBUG_SPINLOOP)
+
+	/* Wait for a JTAG debugger to break in and set EBX non-zero */
+	xor	%ebx, %ebx
+
+debug_spinloop:
+	cmp	$0, %ebx
+	jz	debug_spinloop
+#endif
+
+
+#if 0
+#if !CONFIG(USE_MARCH_586 || USE_MARCH_486)
+	/* MMX registers required here */
+
+	/* BIST result in eax */
+	movd	%eax, %mm0
+
+__timestamp:
+
+	/* Get an early timestamp */
+	rdtsc
+	movd	%eax, %mm1
+	movd	%edx, %mm2
+#endif
+#endif
+
+	/* We're done. Now it's up to platform-specific code */
+	jmp	bootblock_pre_c_entry
diff --git a/src/cpu/486/exit_car.S b/src/cpu/486/exit_car.S
new file mode 100644
index 0000000000..1233b4985d
--- /dev/null
+++ b/src/cpu/486/exit_car.S
@@ -0,0 +1,105 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cpu/486/cache.h>
+#include <cpu/486/post_code.h>
+#include <cpu/intel/post_codes.h>
+
+/* pc2005 TODO */
+#define send_uart		\
+	movw	$0x3f8, %dx;	\
+	outb	%al, %dx;	\
+1:	movw	$0x3fd, %dx;	\
+	inb	%dx, %al;	\
+	testb	$0x20, %al;	\
+	jz	1b
+
+
+.global chipset_teardown_car
+
+.code32
+chipset_teardown_car:
+#if 0
+
+	# [esp] = 00ff213f
+	mov	(%esp), %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+#endif
+
+
+	pop %esp
+
+	post_code(POST_POSTCAR_DISABLE_CACHE)	/*'0'*/
+
+	/* Disable cache. */
+	movl	%cr0, %eax
+	orl	$CR0_CacheDisable, %eax
+	movl	%eax, %cr0
+
+	post_code(POST_POSTCAR_TEARDOWN_DONE)	/*'2'*/
+
+	////////////
+
+	# movl	$0x3, %eax
+	# movl	%eax, %tr5
+
+	# invd
+
+#if 0
+	# 0x00ff213f
+	mov	%esp, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+	shr	$0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart
+
+	////////////
+
+/*	# 0x00ff2380
+	call	test
+test:
+	pop	%eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+	shr $0x8, %eax
+	send_uart
+
+	mov	$0xd, %al	//pc2005
+	send_uart*/
+
+
+	post_code('}')
+#endif
+
+#if 0
+	# //quick search debug block
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	rdtsc
+#endif
+
+
+	/* Return to caller. */
+	jmp	*%esp
diff --git a/src/cpu/486/name.c b/src/cpu/486/name.c
new file mode 100644
index 0000000000..eb8aa2c25c
--- /dev/null
+++ b/src/cpu/486/name.c
@@ -0,0 +1,33 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <cpu/cpu.h>
+#include <cpu/486/name.h>
+#include <stdint.h>
+#include <string.h>
+
+void fill_processor_name(char *processor_name)
+{
+	// struct cpuid_result regs;
+
+	const char *processor_name_start = "Am5x86 TODO";
+
+	// uint32_t name_as_ints[13] = "Am5x86 TODO";
+	// int i;
+/*
+	for (i = 0; i < 3; i++) {
+		regs = cpuid(0x80000002 + i);
+		name_as_ints[i * 4 + 0] = regs.eax;
+		name_as_ints[i * 4 + 1] = regs.ebx;
+		name_as_ints[i * 4 + 2] = regs.ecx;
+		name_as_ints[i * 4 + 3] = regs.edx;
+	}
+
+	name_as_ints[12] = 0;*/
+
+	/* Skip leading spaces. */
+	// processor_name_start = (char *)name_as_ints;
+	// while (*processor_name_start == ' ')
+	// 	processor_name_start++;
+
+	strcpy(processor_name, processor_name_start);
+}
diff --git a/src/cpu/486/reset16.S b/src/cpu/486/reset16.S
new file mode 100644
index 0000000000..38580146b4
--- /dev/null
+++ b/src/cpu/486/reset16.S
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+	.section ".reset", "ax", %progbits
+	.code16
+.globl	_start
+_start:
+	.byte  0xe9
+	.int   _start16bit - ( . + 2 )
+	/* Note: The above jump is hand coded to work around bugs in binutils.
+	 * 5 byte are used for a 3 byte instruction.  This works because x86
+	 * is little endian and allows us to use supported 32bit relocations
+	 * instead of the weird 16 bit relocations that binutils does not
+	 * handle consistently between versions because they are used so rarely.
+	 */
diff --git a/src/cpu/486/romstage.c b/src/cpu/486/romstage.c
new file mode 100644
index 0000000000..7a95fffee4
--- /dev/null
+++ b/src/cpu/486/romstage.c
@@ -0,0 +1,69 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <adainit.h>
+#include <arch/romstage.h>
+#include <arch/symbols.h>
+#include <commonlib/helpers.h>
+#include <console/console.h>
+// #include <cpu/486/smm.h>
+#include <program_loading.h>
+#include <romstage_common.h>
+#include <types.h>
+
+/* If we do not have a constrained _car_stack region size, use the
+ *   following as a guideline for acceptable stack usage. */
+#define DCACHE_RAM_ROMSTAGE_STACK_SIZE 0x2000
+
+void __noreturn romstage_main(void)
+{
+	int i;
+	const int num_guards = 64;
+	const u32 stack_guard = 0xdeadbeef;
+	u32 *stack_base;
+	u32 size;
+	const size_t stack_size = MAX(CONFIG_DCACHE_BSP_STACK_SIZE,
+				      DCACHE_RAM_ROMSTAGE_STACK_SIZE);
+
+	/* Size of unallocated CAR. */
+	size = ALIGN_DOWN(_car_stack_size, 16);
+
+	size = MIN(size, stack_size);
+	if (size < stack_size) {
+		printk(BIOS_DEBUG, "Romstage stack size limited to 0x%x!\n",
+		       size);
+	}
+
+	stack_base = (u32 *)(_ecar_stack - size);
+
+	for (i = 0; i < num_guards; i++)
+		stack_base[i] = stack_guard;
+
+	/*
+	 * We can generally jump between C and Ada code back and forth
+	 * without trouble. But since we don't have an Ada main() we
+	 * have to do some Ada package initializations that GNAT would
+	 * do there. This has to be done before calling any Ada code.
+	 *
+	 * The package initializations should not have any dependen-
+	 * cies on C code. So we can call them here early, and don't
+	 * have to worry at which point we can start to use Ada.
+	 */
+	romstage_adainit();
+
+	mainboard_romstage_entry();
+
+	/* Check the stack. */
+	for (i = 0; i < num_guards; i++) {
+		if (stack_base[i] == stack_guard)
+			continue;
+		printk(BIOS_DEBUG, "Smashed stack detected in romstage!\n");
+	}
+
+	printk(BIOS_DEBUG, "bef prepare postcar\n");
+
+	// if (CONFIG(SMM_TSEG))
+		// smm_list_regions();
+
+	prepare_and_run_postcar();
+	/* We do not return here. */
+}
diff --git a/src/cpu/486/sp_init.c b/src/cpu/486/sp_init.c
new file mode 100644
index 0000000000..e21ad7cb04
--- /dev/null
+++ b/src/cpu/486/sp_init.c
@@ -0,0 +1,1040 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#include <console/console.h>
+#include <string.h>
+#include <rmodule.h>
+#include <commonlib/helpers.h>
+#include <cpu/cpu.h>
+#include <cpu/486/cache.h>
+#include <cpu/486/gdt.h>
+#include <cpu/486/name.h>
+//#include <cpu/486/smm.h>
+#include <delay.h>
+#include <device/device.h>
+#include <device/path.h>
+#include <smp/atomic.h>
+#include <smp/spinlock.h>
+#include <symbols.h>
+#include <timer.h>
+#include <thread.h>
+#include <types.h>
+
+#if 0
+
+struct mp_callback {
+	void (*func)(void *);
+	void *arg;
+	int logical_cpu_number;
+};
+
+static char processor_name[49];
+
+/*
+ * A mp_flight_record details a sequence of calls for the APs to perform
+ * along with the BSP to coordinate sequencing. Each flight record either
+ * provides a barrier for each AP before calling the callback or the APs
+ * are allowed to perform the callback without waiting. Regardless, each
+ * record has the cpus_entered field incremented for each record. When
+ * the BSP observes that the cpus_entered matches the number of APs
+ * the bsp_call is called with bsp_arg and upon returning releases the
+ * barrier allowing the APs to make further progress.
+ *
+ * Note that ap_call() and bsp_call() can be NULL. In the NULL case the
+ * callback will just not be called.
+ */
+struct mp_flight_record {
+	atomic_t barrier;
+	atomic_t cpus_entered;
+	void (*ap_call)(void);
+	void (*bsp_call)(void);
+} __aligned(CACHELINE_SIZE);
+
+#define _MP_FLIGHT_RECORD(barrier_, ap_func_, bsp_func_) \
+	{							\
+		.barrier = ATOMIC_INIT(barrier_),		\
+		.cpus_entered = ATOMIC_INIT(0),			\
+		.ap_call = ap_func_,				\
+		.bsp_call = bsp_func_,				\
+	}
+
+#define MP_FR_BLOCK_APS(ap_func_, bsp_func_) \
+	_MP_FLIGHT_RECORD(0, ap_func_, bsp_func_)
+
+#define MP_FR_NOBLOCK_APS(ap_func_, bsp_func_) \
+	_MP_FLIGHT_RECORD(1, ap_func_, bsp_func_)
+
+/* The mp_params structure provides the arguments to the mp subsystem
+ * for bringing up APs. */
+struct mp_params {
+	int parallel_microcode_load;
+	const void *microcode_pointer;
+	/* Flight plan  for APs and BSP. */
+	struct mp_flight_record *flight_plan;
+	int num_records;
+};
+
+/* This needs to match the layout in the .module_parametrs section. */
+struct sipi_params {
+	uint16_t gdtlimit;
+	uint32_t gdt;
+	uint16_t unused;
+	uint32_t idt_ptr;
+	uint32_t per_cpu_segment_descriptors;
+	uint32_t per_cpu_segment_selector;
+	uint32_t stack_top;
+	uint32_t stack_size;
+	uint32_t microcode_lock; /* 0xffffffff means parallel loading. */
+	uint32_t microcode_ptr;
+	uint32_t msr_table_ptr;
+	uint32_t msr_count;
+	uint32_t c_handler;
+	atomic_t ap_count;
+} __packed;
+
+/* This also needs to match the assembly code for saved MSR encoding. */
+struct saved_msr {
+	uint32_t index;
+	uint32_t lo;
+	uint32_t hi;
+} __packed;
+
+/* The sipi vector rmodule is included in the ramstage using 'objdump -B'. */
+extern char _binary_sipi_vector_start[];
+
+/* The SIPI vector is loaded at the SMM_DEFAULT_BASE. The reason is that the
+ * memory range is already reserved so the OS cannot use it. That region is
+ * free to use for AP bringup before SMM is initialized. */
+static const uintptr_t sipi_vector_location = SMM_DEFAULT_BASE;
+static const int sipi_vector_location_size = SMM_DEFAULT_SIZE;
+
+struct mp_flight_plan {
+	int num_records;
+	struct mp_flight_record *records;
+};
+
+static int global_num_aps;
+static struct mp_flight_plan mp_info;
+
+static inline void barrier_wait(atomic_t *b)
+{
+	while (atomic_read(b) == 0)
+		asm ("pause");
+	mfence();
+}
+
+static inline void release_barrier(atomic_t *b)
+{
+	mfence();
+	atomic_set(b, 1);
+}
+
+static enum cb_err wait_for_aps(atomic_t *val, int target, int total_delay,
+			int delay_step)
+{
+	int delayed = 0;
+	while (atomic_read(val) != target) {
+		udelay(delay_step);
+		delayed += delay_step;
+		if (delayed >= total_delay) {
+			/* Not all APs ready before timeout */
+			return CB_ERR;
+		}
+	}
+
+	/* APs ready before timeout */
+	printk(BIOS_SPEW, "APs are ready after %dus\n", delayed);
+	return CB_SUCCESS;
+}
+
+static void ap_do_flight_plan(void)
+{
+	int i;
+
+	for (i = 0; i < mp_info.num_records; i++) {
+		struct mp_flight_record *rec = &mp_info.records[i];
+
+		atomic_inc(&rec->cpus_entered);
+		barrier_wait(&rec->barrier);
+
+		if (rec->ap_call != NULL)
+			rec->ap_call();
+	}
+}
+
+static void park_this_cpu(void *unused)
+{
+	stop_this_cpu();
+}
+
+static struct bus *g_cpu_bus;
+
+/* By the time APs call ap_init() caching has been setup, and microcode has
+ * been loaded. */
+static asmlinkage void ap_init(unsigned int index)
+{
+	/* Ensure the local APIC is enabled */
+	enable_lapic();
+	setup_lapic_interrupts();
+
+	struct device *dev;
+	int i = 0;
+	for (dev = g_cpu_bus->children; dev; dev = dev->sibling)
+		if (i++ == index)
+			break;
+
+	if (!dev) {
+		printk(BIOS_ERR, "Could not find allocated device for index %u\n", index);
+		return;
+	}
+
+	set_cpu_info(index, dev);
+
+	struct cpu_info *info = cpu_info();
+	cpu_add_map_entry(info->index);
+
+	/* Fix up APIC id with reality. */
+	info->cpu->path.apic.apic_id = lapicid();
+
+	if (cpu_is_intel())
+		printk(BIOS_INFO, "AP: slot %zu apic_id %x, MCU rev: 0x%08x\n", info->index,
+		       info->cpu->path.apic.apic_id, get_current_microcode_rev());
+	else
+		printk(BIOS_INFO, "AP: slot %zu apic_id %x\n", info->index,
+		       info->cpu->path.apic.apic_id);
+
+	/* Walk the flight plan */
+	ap_do_flight_plan();
+
+	/* Park the AP. */
+	park_this_cpu(NULL);
+}
+
+static __aligned(16) uint8_t ap_stack[CONFIG_AP_STACK_SIZE * CONFIG_MAX_CPUS];
+
+static void setup_default_sipi_vector_params(struct sipi_params *sp)
+{
+	sp->gdt = (uintptr_t)&gdt;
+	sp->gdtlimit = (uintptr_t)&gdt_end - (uintptr_t)&gdt - 1;
+	sp->idt_ptr = (uintptr_t)&idtarg;
+	sp->per_cpu_segment_descriptors = (uintptr_t)&per_cpu_segment_descriptors;
+	sp->per_cpu_segment_selector = per_cpu_segment_selector;
+	sp->stack_size = CONFIG_AP_STACK_SIZE;
+	sp->stack_top = (uintptr_t)ap_stack + ARRAY_SIZE(ap_stack);
+}
+
+static const unsigned int fixed_mtrrs[NUM_FIXED_MTRRS] = {
+	MTRR_FIX_64K_00000, MTRR_FIX_16K_80000, MTRR_FIX_16K_A0000,
+	MTRR_FIX_4K_C0000, MTRR_FIX_4K_C8000, MTRR_FIX_4K_D0000,
+	MTRR_FIX_4K_D8000, MTRR_FIX_4K_E0000, MTRR_FIX_4K_E8000,
+	MTRR_FIX_4K_F0000, MTRR_FIX_4K_F8000,
+};
+
+static inline struct saved_msr *save_msr(int index, struct saved_msr *entry)
+{
+	msr_t msr;
+
+	msr = rdmsr(index);
+	entry->index = index;
+	entry->lo = msr.lo;
+	entry->hi = msr.hi;
+
+	/* Return the next entry. */
+	entry++;
+	return entry;
+}
+
+static int save_bsp_msrs(char *start, int size)
+{
+	int msr_count;
+	int num_var_mtrrs;
+	struct saved_msr *msr_entry;
+	int i;
+
+	/* Determine number of MTRRs need to be saved. */
+	num_var_mtrrs = get_var_mtrr_count();
+
+	/* 2 * num_var_mtrrs for base and mask. +1 for IA32_MTRR_DEF_TYPE. */
+	msr_count = 2 * num_var_mtrrs + NUM_FIXED_MTRRS + 1;
+
+	if ((msr_count * sizeof(struct saved_msr)) > size) {
+		printk(BIOS_CRIT, "Cannot mirror all %d msrs.\n", msr_count);
+		return -1;
+	}
+
+	fixed_mtrrs_expose_amd_rwdram();
+
+	msr_entry = (void *)start;
+	for (i = 0; i < NUM_FIXED_MTRRS; i++)
+		msr_entry = save_msr(fixed_mtrrs[i], msr_entry);
+
+	for (i = 0; i < num_var_mtrrs; i++) {
+		msr_entry = save_msr(MTRR_PHYS_BASE(i), msr_entry);
+		msr_entry = save_msr(MTRR_PHYS_MASK(i), msr_entry);
+	}
+
+	msr_entry = save_msr(MTRR_DEF_TYPE_MSR, msr_entry);
+
+	fixed_mtrrs_hide_amd_rwdram();
+
+	/* Tell static analysis we know value is left unused. */
+	(void)msr_entry;
+
+	return msr_count;
+}
+
+static atomic_t *load_sipi_vector(struct mp_params *mp_params)
+{
+	struct rmodule sipi_mod;
+	int module_size;
+	int num_msrs;
+	struct sipi_params *sp;
+	char *mod_loc = (void *)sipi_vector_location;
+	const int loc_size = sipi_vector_location_size;
+	atomic_t *ap_count = NULL;
+
+	if (rmodule_parse(&_binary_sipi_vector_start, &sipi_mod)) {
+		printk(BIOS_CRIT, "Unable to parse sipi module.\n");
+		return ap_count;
+	}
+
+	if (rmodule_entry_offset(&sipi_mod) != 0) {
+		printk(BIOS_CRIT, "SIPI module entry offset is not 0!\n");
+		return ap_count;
+	}
+
+	if (rmodule_load_alignment(&sipi_mod) != 4096) {
+		printk(BIOS_CRIT, "SIPI module load alignment(%d) != 4096.\n",
+		       rmodule_load_alignment(&sipi_mod));
+		return ap_count;
+	}
+
+	module_size = rmodule_memory_size(&sipi_mod);
+
+	/* Align to 4 bytes. */
+	module_size = ALIGN_UP(module_size, 4);
+
+	if (module_size > loc_size) {
+		printk(BIOS_CRIT, "SIPI module size (%d) > region size (%d).\n",
+		       module_size, loc_size);
+		return ap_count;
+	}
+
+	num_msrs = save_bsp_msrs(&mod_loc[module_size], loc_size - module_size);
+
+	if (num_msrs < 0) {
+		printk(BIOS_CRIT, "Error mirroring BSP's msrs.\n");
+		return ap_count;
+	}
+
+	if (rmodule_load(mod_loc, &sipi_mod)) {
+		printk(BIOS_CRIT, "Unable to load SIPI module.\n");
+		return ap_count;
+	}
+
+	sp = rmodule_parameters(&sipi_mod);
+
+	if (sp == NULL) {
+		printk(BIOS_CRIT, "SIPI module has no parameters.\n");
+		return ap_count;
+	}
+
+	setup_default_sipi_vector_params(sp);
+	/* Setup MSR table. */
+	sp->msr_table_ptr = (uintptr_t)&mod_loc[module_size];
+	sp->msr_count = num_msrs;
+	/* Provide pointer to microcode patch. */
+	sp->microcode_ptr = (uintptr_t)mp_params->microcode_pointer;
+	/* Pass on ability to load microcode in parallel. */
+	if (mp_params->parallel_microcode_load)
+		sp->microcode_lock = ~0;
+	else
+		sp->microcode_lock = 0;
+	sp->c_handler = (uintptr_t)&ap_init;
+	ap_count = &sp->ap_count;
+	atomic_set(ap_count, 0);
+
+	return ap_count;
+}
+
+static int allocate_cpu_devices(struct bus *cpu_bus, struct mp_params *p)
+{
+	int i;
+	struct cpu_info *info;
+
+	info = cpu_info();
+	/* Assuming linear APIC space allocation. AP will set its own
+		APIC id in the ap_init() path above. */
+	struct device *new = add_cpu_device(cpu_bus, info->cpu->path.apic.apic_id, 1);
+	if (new == NULL) {
+		printk(BIOS_CRIT, "Could not allocate CPU device\n");
+		return 0;
+	}
+	new->name = processor_name;
+
+	return 1;
+}
+
+static enum cb_err apic_wait_timeout(int total_delay, int delay_step)
+{
+	int total = 0;
+
+	while (lapic_busy()) {
+		udelay(delay_step);
+		total += delay_step;
+		if (total >= total_delay) {
+			/* LAPIC not ready before the timeout */
+			return CB_ERR;
+		}
+	}
+
+	/* LAPIC ready before the timeout */
+	return CB_SUCCESS;
+}
+
+/* Send Startup IPI to APs */
+static enum cb_err send_sipi_to_aps(int ap_count, atomic_t *num_aps, int sipi_vector)
+{
+	if (lapic_busy()) {
+		printk(BIOS_DEBUG, "Waiting for ICR not to be busy...\n");
+		if (apic_wait_timeout(1000 /* 1 ms */, 50) != CB_SUCCESS) {
+			printk(BIOS_ERR, "timed out. Aborting.\n");
+			return CB_ERR;
+		}
+		printk(BIOS_DEBUG, "done.\n");
+	}
+
+	lapic_send_ipi_others(LAPIC_INT_ASSERT | LAPIC_DM_STARTUP | sipi_vector);
+	printk(BIOS_DEBUG, "Waiting for SIPI to complete...\n");
+	if (apic_wait_timeout(10000 /* 10 ms */, 50 /* us */) != CB_SUCCESS) {
+		printk(BIOS_ERR, "timed out.\n");
+		return CB_ERR;
+	}
+	printk(BIOS_DEBUG, "done.\n");
+	return CB_SUCCESS;
+}
+
+static enum cb_err start_aps(struct bus *cpu_bus, int ap_count, atomic_t *num_aps)
+{
+	int sipi_vector;
+	/* Max location is 4KiB below 1MiB */
+	const int max_vector_loc = ((1 << 20) - (1 << 12)) >> 12;
+
+	if (ap_count == 0)
+		return CB_SUCCESS;
+
+	/* The vector is sent as a 4k aligned address in one byte. */
+	sipi_vector = sipi_vector_location >> 12;
+
+	if (sipi_vector > max_vector_loc) {
+		printk(BIOS_CRIT, "SIPI vector too large! 0x%08x\n",
+		       sipi_vector);
+		return CB_ERR;
+	}
+
+	printk(BIOS_DEBUG, "Attempting to start %d APs\n", ap_count);
+
+	if (lapic_busy()) {
+		printk(BIOS_DEBUG, "Waiting for ICR not to be busy...\n");
+		if (apic_wait_timeout(1000 /* 1 ms */, 50) != CB_SUCCESS) {
+			printk(BIOS_ERR, "timed out. Aborting.\n");
+			return CB_ERR;
+		}
+		printk(BIOS_DEBUG, "done.\n");
+	}
+
+	/* Send INIT IPI to all but self. */
+	lapic_send_ipi_others(LAPIC_INT_ASSERT | LAPIC_DM_INIT);
+
+	if (!CONFIG(X86_INIT_NEED_1_SIPI)) {
+		printk(BIOS_DEBUG, "Waiting for 10ms after sending INIT.\n");
+		mdelay(10);
+
+		/* Send 1st Startup IPI (SIPI) */
+		if (send_sipi_to_aps(ap_count, num_aps, sipi_vector) != CB_SUCCESS)
+			return CB_ERR;
+
+		/* Wait for CPUs to check in. */
+		wait_for_aps(num_aps, ap_count, 200 /* us */, 15 /* us */);
+	}
+
+	/* Send final SIPI */
+	if (send_sipi_to_aps(ap_count, num_aps, sipi_vector) != CB_SUCCESS)
+		return CB_ERR;
+
+	/* Wait for CPUs to check in. */
+	if (wait_for_aps(num_aps, ap_count, 400000 /* 400 ms */, 50 /* us */) != CB_SUCCESS) {
+		printk(BIOS_ERR, "Not all APs checked in: %d/%d.\n",
+		       atomic_read(num_aps), ap_count);
+		return CB_ERR;
+	}
+
+	return CB_SUCCESS;
+}
+
+static enum cb_err bsp_do_flight_plan(struct mp_params *mp_params)
+{
+	int i;
+	enum cb_err ret = CB_SUCCESS;
+	/*
+	 * Set time out for flight plan to a huge minimum value (>=1 second).
+	 * CPUs with many APs may take longer if there is contention for
+	 * resources such as UART, so scale the time out up by increments of
+	 * 100ms if needed.
+	 */
+	const int timeout_us = MAX(1000000, 100000 * 1);
+	const int step_us = 100;
+	struct stopwatch sw;
+
+	stopwatch_init(&sw);
+
+	for (i = 0; i < mp_params->num_records; i++) {
+		struct mp_flight_record *rec = &mp_params->flight_plan[i];
+
+		/* Wait for APs if the record is not released. */
+		if (atomic_read(&rec->barrier) == 0) {
+			/* Wait for the APs to check in. */
+			if (wait_for_aps(&rec->cpus_entered, 0,
+					 timeout_us, step_us) != CB_SUCCESS) {
+				printk(BIOS_ERR, "MP record %d timeout.\n", i);
+				ret = CB_ERR;
+			}
+		}
+
+		if (rec->bsp_call != NULL)
+			rec->bsp_call();
+
+		release_barrier(&rec->barrier);
+	}
+
+	printk(BIOS_INFO, "%s done after %lld msecs.\n", __func__,
+	       stopwatch_duration_msecs(&sw));
+	return ret;
+}
+
+static enum cb_err init_bsp(struct bus *cpu_bus)
+{
+	struct cpu_info *info;
+
+	/* Print processor name */
+	fill_processor_name(processor_name);
+	printk(BIOS_INFO, "CPU: %s.\n", processor_name);
+
+	/* Ensure the local APIC is enabled */
+	enable_lapic();
+	setup_lapic_interrupts();
+
+	struct device *bsp = add_cpu_device(cpu_bus, lapicid(), 1);
+	if (bsp == NULL) {
+		printk(BIOS_CRIT, "Failed to find or allocate BSP struct device\n");
+		return CB_ERR;
+	}
+
+	/* Find the device structure for the boot CPU. */
+	set_cpu_info(0, bsp);
+	info = cpu_info();
+	info->cpu = bsp;
+	info->cpu->name = processor_name;
+
+	if (info->index != 0) {
+		printk(BIOS_CRIT, "BSP index(%zd) != 0!\n", info->index);
+		return CB_ERR;
+	}
+
+	/* Track BSP in cpu_map structures. */
+	cpu_add_map_entry(info->index);
+	return CB_SUCCESS;
+}
+
+/*
+ * mp_init() will set up the SIPI vector and bring up the APs according to
+ * mp_params. Each flight record will be executed according to the plan. Note
+ * that the MP infrastructure uses SMM default area without saving it. It's
+ * up to the chipset or mainboard to either e820 reserve this area or save this
+ * region prior to calling mp_init() and restoring it after mp_init returns.
+ *
+ * At the time mp_init() is called the MTRR MSRs are mirrored into APs then
+ * caching is enabled before running the flight plan.
+ *
+ * The MP initialization has the following properties:
+ * 1. APs are brought up in parallel.
+ * 2. The ordering of coreboot CPU number and APIC ids is not deterministic.
+ *    Therefore, one cannot rely on this property or the order of devices in
+ *    the device tree unless the chipset or mainboard know the APIC ids
+ *    a priori.
+ */
+static enum cb_err mp_init(struct bus *cpu_bus, struct mp_params *p)
+{
+	atomic_t *ap_count;
+
+	g_cpu_bus = cpu_bus;
+
+	if (init_bsp(cpu_bus) != CB_SUCCESS) {
+		printk(BIOS_CRIT, "Setting up BSP failed\n");
+		return CB_ERR;
+	}
+
+	if (p == NULL || p->flight_plan == NULL || p->num_records < 1) {
+		printk(BIOS_CRIT, "Invalid MP parameters\n");
+		return CB_ERR;
+	}
+
+	/* We just need to run things on the BSP */
+	if (!CONFIG(SMP))
+		return bsp_do_flight_plan(p);
+
+	/* Default to currently running CPU. */
+	num_cpus = allocate_cpu_devices(cpu_bus, p);
+
+	if (num_cpus < p->num_cpus) {
+		printk(BIOS_CRIT,
+		       "ERROR: More cpus requested (%d) than supported (%d).\n",
+		       p->num_cpus, num_cpus);
+		return CB_ERR;
+	}
+
+	/* Copy needed parameters so that APs have a reference to the plan. */
+	mp_info.num_records = p->num_records;
+	mp_info.records = p->flight_plan;
+
+	/* Load the SIPI vector. */
+	ap_count = load_sipi_vector(p);
+	if (ap_count == NULL)
+		return CB_ERR;
+
+	/* Make sure SIPI data hits RAM so the APs that come up will see
+	 * the startup code even if the caches are disabled.  */
+	wbinvd();
+
+	/* Start the APs providing number of APs and the cpus_entered field. */
+	global_num_aps = p->num_cpus - 1;
+	if (start_aps(cpu_bus, global_num_aps, ap_count) != CB_SUCCESS) {
+		mdelay(1000);
+		printk(BIOS_DEBUG, "%d/%d eventually checked in?\n",
+		       atomic_read(ap_count), global_num_aps);
+		return CB_ERR;
+	}
+
+	/* Walk the flight plan for the BSP. */
+	return bsp_do_flight_plan(p);
+}
+
+void smm_initiate_relocation_parallel(void)
+{
+	if (lapic_busy()) {
+		printk(BIOS_DEBUG, "Waiting for ICR not to be busy...");
+		if (apic_wait_timeout(1000 /* 1 ms */, 50) != CB_SUCCESS) {
+			printk(BIOS_DEBUG, "timed out. Aborting.\n");
+			return;
+		}
+		printk(BIOS_DEBUG, "done.\n");
+	}
+
+	lapic_send_ipi_self(LAPIC_INT_ASSERT | LAPIC_DM_SMI);
+
+	if (lapic_busy()) {
+		if (apic_wait_timeout(1000 /* 1 ms */, 100 /* us */) != CB_SUCCESS) {
+			printk(BIOS_DEBUG, "SMI Relocation timed out.\n");
+			return;
+		}
+	}
+	printk(BIOS_DEBUG, "Relocation complete.\n");
+}
+
+DECLARE_SPIN_LOCK(smm_relocation_lock);
+
+/* Send SMI to self with single user serialization. */
+void smm_initiate_relocation(void)
+{
+	spin_lock(&smm_relocation_lock);
+	smm_initiate_relocation_parallel();
+	spin_unlock(&smm_relocation_lock);
+}
+
+struct mp_state {
+	struct mp_ops ops;
+	int cpu_count;
+	uintptr_t perm_smbase;
+	size_t perm_smsize;
+	size_t smm_save_state_size;
+	uintptr_t reloc_start32_offset;
+	bool do_smm;
+} mp_state;
+
+static bool is_smm_enabled(void)
+{
+	return CONFIG(HAVE_SMI_HANDLER) && mp_state.do_smm;
+}
+
+static void smm_disable(void)
+{
+	mp_state.do_smm = false;
+}
+
+static void smm_enable(void)
+{
+	if (CONFIG(HAVE_SMI_HANDLER))
+		mp_state.do_smm = true;
+}
+
+/*
+ * This code is built as part of ramstage, but it actually runs in SMM. This
+ * means that ENV_SMM is 0, but we are actually executing in the environment
+ * setup by the smm_stub.
+ */
+static asmlinkage void smm_do_relocation(void *arg)
+{
+	const struct smm_module_params *p;
+	int cpu;
+	const uintptr_t curr_smbase = SMM_DEFAULT_BASE;
+	uintptr_t perm_smbase;
+
+	p = arg;
+	cpu = p->cpu;
+
+	if (cpu >= CONFIG_MAX_CPUS) {
+		printk(BIOS_CRIT,
+		       "Invalid CPU number assigned in SMM stub: %d\n", cpu);
+		return;
+	}
+
+	/*
+	 * The permanent handler runs with all cpus concurrently. Precalculate
+	 * the location of the new SMBASE. If using SMM modules then this
+	 * calculation needs to match that of the module loader.
+	 */
+	perm_smbase = smm_get_cpu_smbase(cpu);
+	if (!perm_smbase) {
+		printk(BIOS_ERR, "%s: bad SMBASE for CPU %d\n", __func__, cpu);
+		return;
+	}
+
+	/* Setup code checks this callback for validity. */
+	printk(BIOS_INFO, "%s : curr_smbase 0x%x perm_smbase 0x%x, cpu = %d\n",
+		__func__, (int)curr_smbase, (int)perm_smbase, cpu);
+	mp_state.ops.relocation_handler(cpu, curr_smbase, perm_smbase);
+
+	if (CONFIG(STM)) {
+		uintptr_t mseg;
+
+		mseg = mp_state.perm_smbase +
+			(mp_state.perm_smsize - CONFIG_MSEG_SIZE);
+
+		stm_setup(mseg, p->cpu,
+				perm_smbase,
+				mp_state.perm_smbase,
+				mp_state.reloc_start32_offset);
+	}
+}
+
+static void adjust_smm_apic_id_map(struct smm_loader_params *smm_params)
+{
+	int i;
+	struct smm_stub_params *stub_params = smm_params->stub_params;
+
+	for (i = 0; i < CONFIG_MAX_CPUS; i++)
+		stub_params->apic_id_to_cpu[i] = cpu_get_apic_id(i);
+}
+
+static enum cb_err install_relocation_handler(int num_cpus, size_t save_state_size)
+{
+	if (CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER))
+		return CB_SUCCESS;
+
+	struct smm_loader_params smm_params = {
+		.num_cpus = 1,
+		.cpu_save_state_size = save_state_size,
+		.num_concurrent_save_states = 1,
+		.handler = smm_do_relocation,
+	};
+
+	if (smm_setup_relocation_handler(&smm_params)) {
+		printk(BIOS_ERR, "%s: smm setup failed\n", __func__);
+		return CB_ERR;
+	}
+	adjust_smm_apic_id_map(&smm_params);
+
+	mp_state.reloc_start32_offset = smm_params.stub_params->start32_offset;
+
+	return CB_SUCCESS;
+}
+
+static enum cb_err install_permanent_handler(int num_cpus, uintptr_t smbase,
+				     size_t smsize, size_t save_state_size)
+{
+	/*
+	 * All the CPUs will relocate to permanaent handler now. Set parameters
+	 * needed for all CPUs. The placement of each CPUs entry point is
+	 * determined by the loader. This code simply provides the beginning of
+	 * SMRAM region, the number of CPUs who will use the handler, the stack
+	 * size and save state size for each CPU.
+	 */
+	struct smm_loader_params smm_params = {
+		.num_cpus = 1,
+		.cpu_save_state_size = save_state_size,
+		.num_concurrent_save_states = 1,
+	};
+
+	printk(BIOS_DEBUG, "Installing permanent SMM handler to 0x%08lx\n", smbase);
+
+	if (smm_load_module(smbase, smsize, &smm_params))
+		return CB_ERR;
+
+	adjust_smm_apic_id_map(&smm_params);
+
+	return CB_SUCCESS;
+}
+
+/* Load SMM handlers as part of MP flight record. */
+static void load_smm_handlers(void)
+{
+	const size_t save_state_size = mp_state.smm_save_state_size;
+
+	/* Do nothing if SMM is disabled.*/
+	if (!is_smm_enabled())
+		return;
+
+	if (smm_setup_stack(mp_state.perm_smbase, mp_state.perm_smsize, mp_state.cpu_count,
+			    CONFIG_SMM_MODULE_STACK_SIZE)) {
+		printk(BIOS_ERR, "Unable to install SMM relocation handler.\n");
+		smm_disable();
+	}
+
+	/* Install handlers. */
+	if (install_relocation_handler(mp_state.cpu_count, save_state_size) != CB_SUCCESS) {
+		printk(BIOS_ERR, "Unable to install SMM relocation handler.\n");
+		smm_disable();
+	}
+
+	if (install_permanent_handler(mp_state.cpu_count, mp_state.perm_smbase,
+				      mp_state.perm_smsize, save_state_size) != CB_SUCCESS) {
+		printk(BIOS_ERR, "Unable to install SMM permanent handler.\n");
+		smm_disable();
+	}
+
+	/* Ensure the SMM handlers hit DRAM before performing first SMI. */
+	wbinvd();
+
+	/*
+	 * Indicate that the SMM handlers have been loaded and MP
+	 * initialization is about to start.
+	 */
+	if (is_smm_enabled() && mp_state.ops.pre_mp_smm_init != NULL)
+		mp_state.ops.pre_mp_smm_init();
+}
+
+/* Trigger SMM as part of MP flight record. */
+static void trigger_smm_relocation(void)
+{
+	/* Do nothing if SMM is disabled.*/
+	if (!is_smm_enabled() || mp_state.ops.per_cpu_smm_trigger == NULL)
+		return;
+	/* Trigger SMM mode for the currently running processor. */
+	mp_state.ops.per_cpu_smm_trigger();
+}
+
+static struct mp_callback *ap_callbacks[CONFIG_MAX_CPUS];
+
+enum AP_STATUS {
+	/* AP takes the task but not yet finishes */
+	AP_BUSY = 1,
+	/* AP finishes the task or no task to run yet */
+	AP_NOT_BUSY
+};
+
+static atomic_t ap_status[CONFIG_MAX_CPUS];
+
+static struct mp_callback *read_callback(struct mp_callback **slot)
+{
+	struct mp_callback *ret;
+
+	asm volatile ("mov	%1, %0\n"
+		: "=r" (ret)
+		: "m" (*slot)
+		: "memory"
+	);
+	return ret;
+}
+
+static void store_callback(struct mp_callback **slot, struct mp_callback *val)
+{
+	asm volatile ("mov	%1, %0\n"
+		: "=m" (*slot)
+		: "r" (val)
+		: "memory"
+	);
+}
+
+static enum cb_err run_ap_work(struct mp_callback *val, long expire_us, bool wait_ap_finish)
+{
+	int i;
+	int cpus_accepted, cpus_finish;
+	struct stopwatch sw;
+	int cur_cpu;
+
+	if (!CONFIG(PARALLEL_MP_AP_WORK)) {
+		printk(BIOS_ERR, "APs already parked. PARALLEL_MP_AP_WORK not selected.\n");
+		return CB_ERR;
+	}
+
+	cur_cpu = cpu_index();
+
+	if (cur_cpu < 0) {
+		printk(BIOS_ERR, "Invalid CPU index.\n");
+		return CB_ERR;
+	}
+
+	/* Signal to all the APs to run the func. */
+	for (i = 0; i < ARRAY_SIZE(ap_callbacks); i++) {
+		if (cur_cpu == i)
+			continue;
+		store_callback(&ap_callbacks[i], val);
+	}
+	mfence();
+
+	/* Wait for all the APs to signal back that call has been accepted. */
+	if (expire_us > 0)
+		stopwatch_init_usecs_expire(&sw, expire_us);
+
+	do {
+		cpus_accepted = 0;
+		cpus_finish = 0;
+
+		for (i = 0; i < ARRAY_SIZE(ap_callbacks); i++) {
+			if (cur_cpu == i)
+				continue;
+
+			if (read_callback(&ap_callbacks[i]) == NULL) {
+				cpus_accepted++;
+				/* Only increase cpus_finish if AP took the task and not busy */
+				if (atomic_read(&ap_status[i]) == AP_NOT_BUSY)
+					cpus_finish++;
+			}
+		}
+
+		/*
+		 * if wait_ap_finish is true, need to make sure all CPUs finish task and return
+		 * else just need to make sure all CPUs take task
+		 */
+		if (cpus_accepted == global_num_aps)
+			if (!wait_ap_finish || (cpus_finish == global_num_aps))
+				return CB_SUCCESS;
+
+	} while (expire_us <= 0 || !stopwatch_expired(&sw));
+
+	printk(BIOS_CRIT, "CRITICAL ERROR: AP call expired. %d/%d CPUs accepted.\n",
+		cpus_accepted, global_num_aps);
+	return CB_ERR;
+}
+
+
+enum cb_err mp_park_aps(void)
+{
+	return CB_SUCCESS;
+}
+
+static struct mp_flight_record mp_steps[] = {
+	/* Once the APs are up load the SMM handlers. */
+	MP_FR_BLOCK_APS(NULL, load_smm_handlers),
+	/* Perform SMM relocation. */
+	MP_FR_NOBLOCK_APS(trigger_smm_relocation, trigger_smm_relocation),
+	/* Initialize each CPU through the driver framework. */
+	MP_FR_BLOCK_APS(cpu_initialize, cpu_initialize),
+};
+
+static void fill_mp_state_smm(struct mp_state *state, const struct mp_ops *ops)
+{
+	if (ops->get_smm_info != NULL)
+		ops->get_smm_info(&state->perm_smbase, &state->perm_smsize,
+				  &state->smm_save_state_size);
+
+	/*
+	 * Make sure there is enough room for the SMM descriptor
+	 */
+	if (CONFIG(STM)) {
+		state->smm_save_state_size +=
+			ALIGN_UP(sizeof(TXT_PROCESSOR_SMM_DESCRIPTOR), 0x100);
+	}
+
+	/*
+	 * Default to smm_initiate_relocation() if trigger callback isn't
+	 * provided.
+	 */
+	if (ops->per_cpu_smm_trigger == NULL)
+		mp_state.ops.per_cpu_smm_trigger = smm_initiate_relocation;
+}
+
+static void fill_mp_state(struct mp_state *state, const struct mp_ops *ops)
+{
+	/*
+	 * Make copy of the ops so that defaults can be set in the non-const
+	 * structure if needed.
+	 */
+	memcpy(&state->ops, ops, sizeof(*ops));
+
+	if (CONFIG(HAVE_SMI_HANDLER))
+		fill_mp_state_smm(state, ops);
+}
+
+static enum cb_err do_init_with_smm(struct bus *cpu_bus, const struct mp_ops *mp_ops)
+{
+	enum cb_err ret;
+	void *default_smm_area;
+	struct mp_params mp_params;
+
+	if (mp_ops->pre_mp_init != NULL)
+		mp_ops->pre_mp_init();
+
+	fill_mp_state(&mp_state, mp_ops);
+
+	memset(&mp_params, 0, sizeof(mp_params));
+
+	if (mp_state.cpu_count <= 0) {
+		printk(BIOS_ERR, "Invalid cpu_count: %d\n", mp_state.cpu_count);
+		return CB_ERR;
+	}
+
+	/* Sanity check SMM state. */
+	smm_enable();
+	if (mp_state.perm_smsize == 0)
+		smm_disable();
+	if (mp_state.smm_save_state_size == 0)
+		smm_disable();
+	if (!CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER) && mp_state.ops.relocation_handler == NULL)
+		smm_disable();
+
+	if (is_smm_enabled())
+		printk(BIOS_INFO, "Will perform SMM setup.\n");
+
+	mp_params.num_cpus = 1;
+	mp_params.flight_plan = &mp_steps[0];
+	mp_params.num_records = ARRAY_SIZE(mp_steps);
+
+	/* Perform backup of default SMM area when using SMM relocation handler. */
+	if (!CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER))
+		default_smm_area = backup_default_smm_area();
+
+	ret = mp_init(cpu_bus, &mp_params);
+
+	if (!CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER))
+		restore_default_smm_area(default_smm_area);
+
+	/* Signal callback on success if it's provided. */
+	if (ret == CB_SUCCESS && mp_state.ops.post_mp_init != NULL)
+		mp_state.ops.post_mp_init();
+
+	return ret;
+}
+
+#endif
+/*
+enum cb_err sp_init_with_smm(struct bus *cpu_bus, struct mp_ops *mp_ops)
+{
+	// enum cb_err ret = do_init_with_smm(cpu_bus, mp_ops);
+
+	// if (ret != CB_SUCCESS)
+		// printk(BIOS_ERR, "SP initialization failure.\n");
+
+	// return ret;
+
+	return CB_SUCCESS;
+}*/
diff --git a/src/include/cpu/486/bist.h b/src/include/cpu/486/bist.h
new file mode 100644
index 0000000000..247e78cd19
--- /dev/null
+++ b/src/include/cpu/486/bist.h
@@ -0,0 +1,17 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_BIST_H
+#define CPU_X86_BIST_H
+
+#include <console/console.h>
+#include <stdint.h>
+
+static inline void report_bist_failure(u32 bist)
+{
+	if (bist != 0) {
+		printk(BIOS_EMERG, "BIST failed: %08x", bist);
+		die("\n");
+	}
+}
+
+#endif /* CPU_X86_BIST_H */
diff --git a/src/include/cpu/486/cache.h b/src/include/cpu/486/cache.h
new file mode 100644
index 0000000000..43fba5efe3
--- /dev/null
+++ b/src/include/cpu/486/cache.h
@@ -0,0 +1,60 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_CACHE
+#define CPU_X86_CACHE
+
+#include <cpu/486/cr.h>
+
+#define CR0_CacheDisable	(CR0_CD)
+#define CR0_NoWriteThrough	(CR0_NW)
+
+#define CPUID_FEATURE_CLFLUSH_BIT 19
+
+#if !defined(__ASSEMBLER__)
+
+static inline void wbinvd(void)
+{
+	asm volatile ("wbinvd" ::: "memory");
+}
+
+static inline void invd(void)
+{
+	asm volatile("invd" ::: "memory");
+}
+
+static inline void clflush(void *addr)
+{
+	// asm volatile ("clflush (%0)"::"r" (addr));
+}
+
+/* The following functions require the __always_inline due to AMD
+ * function STOP_CAR_AND_CPU that disables cache as
+ * RAM, the cache as RAM stack can no longer be used. Called
+ * functions must be inlined to avoid stack usage. Also, the
+ * compiler must keep local variables register based and not
+ * allocated them from the stack. With gcc 4.5.0, some functions
+ * declared as inline are not being inlined. This patch forces
+ * these functions to always be inlined by adding the qualifier
+ * __always_inline to their declaration.
+ */
+static __always_inline void enable_cache(void)
+{
+	CRx_TYPE cr0;
+	cr0 = read_cr0();
+	cr0 &= ~(CR0_CD | CR0_NW);
+	write_cr0(cr0);
+}
+
+static __always_inline void disable_cache(void)
+{
+	/* Disable and write back the cache */
+	CRx_TYPE cr0;
+	cr0 = read_cr0();
+	cr0 |= CR0_CD;
+	wbinvd();
+	write_cr0(cr0);
+	wbinvd();
+}
+
+#endif /* !__ASSEMBLER__ */
+#endif /* CPU_X86_CACHE */
diff --git a/src/include/cpu/486/cr.h b/src/include/cpu/486/cr.h
new file mode 100644
index 0000000000..c70f35c103
--- /dev/null
+++ b/src/include/cpu/486/cr.h
@@ -0,0 +1,132 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_CR_H
+#define CPU_X86_CR_H
+
+#if !defined(__ASSEMBLER__)
+
+#include <stdint.h>
+
+#define COMPILER_BARRIER "memory"
+
+#if ENV_X86_64
+#define CRx_TYPE uint64_t
+#define CRx_IN   "q"
+#define CRx_RET  "=q"
+#else
+#define CRx_TYPE uint32_t
+#define CRx_IN   "r"
+#define CRx_RET  "=r"
+#endif
+static __always_inline CRx_TYPE read_cr0(void)
+{
+	CRx_TYPE value;
+	__asm__ __volatile__ (
+		"mov %%cr0, %0"
+		: CRx_RET(value)
+		:
+		: COMPILER_BARRIER
+	);
+	return value;
+}
+
+static __always_inline void write_cr0(CRx_TYPE data)
+{
+	__asm__ __volatile__ (
+		"mov %0, %%cr0"
+		:
+		: CRx_IN(data)
+		: COMPILER_BARRIER
+	);
+}
+
+static __always_inline CRx_TYPE read_cr2(void)
+{
+	CRx_TYPE value;
+	__asm__ __volatile__ (
+		"mov %%cr2, %0"
+		: CRx_RET(value)
+		:
+		: COMPILER_BARRIER
+	);
+	return value;
+}
+
+static __always_inline CRx_TYPE read_cr3(void)
+{
+	CRx_TYPE value;
+	__asm__ __volatile__ (
+		"mov %%cr3, %0"
+		: CRx_RET(value)
+		:
+		: COMPILER_BARRIER
+	);
+	return value;
+}
+
+static __always_inline void write_cr3(CRx_TYPE data)
+{
+	__asm__ __volatile__ (
+		"mov %0, %%cr3"
+		:
+		: CRx_IN(data)
+		: COMPILER_BARRIER
+	);
+}
+static __always_inline CRx_TYPE read_cr4(void)
+{
+	CRx_TYPE value;
+	__asm__ __volatile__ (
+		"mov %%cr4, %0"
+		: CRx_RET(value)
+		:
+		: COMPILER_BARRIER
+	);
+	return value;
+}
+
+static __always_inline void write_cr4(CRx_TYPE data)
+{
+	__asm__ __volatile__ (
+		"mov %0, %%cr4"
+		:
+		: CRx_IN(data)
+		: COMPILER_BARRIER
+	);
+}
+
+#endif /* !defined(__ASSEMBLER__) */
+
+/* CR0 flags */
+#define CR0_PE		(1 <<  0)
+#define CR0_MP		(1 <<  1)
+#define CR0_EM		(1 <<  2)
+#define CR0_TS		(1 <<  3)
+#define CR0_ET		(1 <<  4)
+#define CR0_NE		(1 <<  5)
+#define CR0_WP		(1 << 16)
+#define CR0_AM		(1 << 18)
+#define CR0_NW		(1 << 29)
+#define CR0_CD		(1 << 30)
+#define CR0_PG		(1 << 31)
+
+/* CR4 flags */
+#define CR4_VME		(1 <<  0)
+#define CR4_PVI		(1 <<  1)
+#define CR4_TSD		(1 <<  2)
+#define CR4_DE		(1 <<  3)
+#define CR4_PSE		(1 <<  4)
+#define CR4_PAE		(1 <<  5)
+#define CR4_MCE		(1 <<  6)
+#define CR4_PGE		(1 <<  7)
+#define CR4_PCE		(1 <<  8)
+#define CR4_OSFXSR	(1 <<  9)
+#define CR4_OSXMMEXCPT	(1 << 10)
+#define CR4_VMXE	(1 << 13)
+#define CR4_SMXE	(1 << 14)
+#define CR4_FSGSBASE	(1 << 16)
+#define CR4_PCIDE	(1 << 17)
+#define CR4_OSXSAVE	(1 << 18)
+#define CR4_SMEP	(1 << 20)
+
+#endif /* CPU_X86_CR_H */
diff --git a/src/include/cpu/486/gdt.h b/src/include/cpu/486/gdt.h
new file mode 100644
index 0000000000..27a863ee33
--- /dev/null
+++ b/src/include/cpu/486/gdt.h
@@ -0,0 +1,18 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_GDT
+#define CPU_X86_GDT
+
+/* These symbols are defined in c_start.S. */
+extern char gdt[];
+extern char per_cpu_segment_descriptors[];
+extern uint32_t per_cpu_segment_selector;
+extern char gdt_end[];
+extern char idtarg[];
+
+/* These symbols are defined in secondary.S. */
+extern char _secondary_gdt_addr[];
+extern char _secondary_start[];
+extern char _secondary_start_end[];
+
+#endif /* CPU_X86_GDT */
diff --git a/src/include/cpu/486/legacy_save_state.h b/src/include/cpu/486/legacy_save_state.h
new file mode 100644
index 0000000000..4c9923c82c
--- /dev/null
+++ b/src/include/cpu/486/legacy_save_state.h
@@ -0,0 +1,48 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __X86_LEGACY_SAVE_STATE_H__
+#define __X86_LEGACY_SAVE_STATE_H__
+
+#include <types.h>
+
+/* Legacy x86 SMM State-Save Area
+ * starts @ 0x7e00
+ */
+#define SMM_LEGACY_ARCH_OFFSET 0x7e00
+
+typedef struct {
+	u8	reserved0[248];
+	u32	smbase;
+	u32	smm_revision;
+	u16	io_restart;
+	u16	autohalt_restart;
+	u8	reserved1[132];
+	u32	gdtbase;
+	u8	reserved2[8];
+	u32	idtbase;
+	u8	reserved3[16];
+	u32	es;
+	u32	cs;
+	u32	ss;
+	u32	ds;
+	u32	fs;
+	u32	gs;
+	u32	ldtbase;
+	u32	tr;
+	u32	dr7;
+	u32	dr6;
+	u32	eax;
+	u32	ecx;
+	u32	edx;
+	u32	ebx;
+	u32	esp;
+	u32	ebp;
+	u32	esi;
+	u32	edi;
+	u32	eip;
+	u32	eflags;
+	u32	cr3;
+	u32	cr0;
+} __packed legacy_smm_state_save_area_t;
+
+#endif
diff --git a/src/include/cpu/486/name.h b/src/include/cpu/486/name.h
new file mode 100644
index 0000000000..8ac2f9648c
--- /dev/null
+++ b/src/include/cpu/486/name.h
@@ -0,0 +1,8 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_NAME_H
+#define CPU_X86_NAME_H
+
+void fill_processor_name(char *processor_name);
+
+#endif
diff --git a/src/include/cpu/486/post_code.h b/src/include/cpu/486/post_code.h
new file mode 100644
index 0000000000..4cb6e14b27
--- /dev/null
+++ b/src/include/cpu/486/post_code.h
@@ -0,0 +1,60 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __X86_POST_CODE_H__
+#define __X86_POST_CODE_H__
+
+#include <commonlib/console/post_codes.h>
+
+#if CONFIG(POST_IO) && !(ENV_BOOTBLOCK && CONFIG(NO_EARLY_BOOTBLOCK_POSTCODES))
+
+#define post_init		\
+	movw	$0x3f9, %dx;	\
+	movb	$0x0, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3fb, %dx;	\
+	movb	$0x80, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3f8, %dx;	\
+	movb	$1, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3f9, %dx;	\
+	movb	$0x0, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3fb, %dx;	\
+	inb	%dx, %al;	\
+	andb	$0x7f, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3f9, %dx;	\
+	movb	$0x00, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3fa, %dx;	\
+	movb	$0xc7, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3fb, %dx;	\
+	movb	$0x03, %al;	\
+	outb	%al, %dx;	\
+	movw	$0x3fc, %dx;	\
+	movb	$0x01, %al;	\
+	outb	%al, %dx
+
+/*
+#define post_code(value)	\
+	movb    $value, %al;    \
+	outb    %al, $CONFIG_POST_IO_PORT
+*/
+
+#define post_code(value)	\
+	movb	$value, %al;    \
+	movw	$0x3f8, %dx;	\
+	outb	%al, %dx;	\
+1:	movw	$0x3fd, %dx;	\
+	inb	%dx, %al;	\
+	testb	$0x20, %al;	\
+	jz	1b
+
+#else
+#define post_init
+#define post_code(value)
+#endif
+
+#endif /* __X86_POST_CODE_H__ */
diff --git a/src/include/cpu/486/save_state.h b/src/include/cpu/486/save_state.h
new file mode 100644
index 0000000000..139a5fa750
--- /dev/null
+++ b/src/include/cpu/486/save_state.h
@@ -0,0 +1,34 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __CPU_X86_SAVE_STATE_H__
+#define __CPU_X86_SAVE_STATE_H__
+
+#include <stdint.h>
+
+enum cpu_reg {
+	RAX,
+	RBX,
+	RCX,
+	RDX
+};
+
+#define SMM_REV_INVALID 0xffffffff
+
+struct smm_save_state_ops {
+	const uint32_t *revision_table;
+	/* Accessors for CPU registers in the SMM save state
+	   Returns -1 on failure, 0 on success */
+	int (*get_reg)(const enum cpu_reg reg, const int node, void *out, const uint8_t length);
+	int (*set_reg)(const enum cpu_reg reg, const int node, void *in, const uint8_t length);
+	/* Returns -1 on failure, the node on which the 'cmd' was send on success */
+	int (*apmc_node)(u8 cmd);
+};
+
+/* Return -1 on failure, otherwise returns which CPU node issued an APMC IO write */
+int get_apmc_node(u8 cmd);
+/* Return -1 on failure, 0 on success.
+   Accessors for the SMM save state CPU registers RAX, RBX, RCX and RDX */
+int get_save_state_reg(const enum cpu_reg reg, const int node, void *out, const uint8_t length);
+int set_save_state_reg(const enum cpu_reg reg, const int node, void *in, const uint8_t length);
+
+#endif /* __CPU_X86_SAVE_STATE_H__ */
diff --git a/src/include/cpu/486/smi_deprecated.h b/src/include/cpu/486/smi_deprecated.h
new file mode 100644
index 0000000000..262aa0b695
--- /dev/null
+++ b/src/include/cpu/486/smi_deprecated.h
@@ -0,0 +1,12 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef __X86_SMI_DEPRECATED_H__
+#define __X86_SMI_DEPRECATED_H__
+
+void smm_init(void);
+void smm_init_completion(void);
+
+/* Entry from smmhandler.S. */
+void smi_handler(void);
+
+#endif
diff --git a/src/include/cpu/486/smm.h b/src/include/cpu/486/smm.h
new file mode 100644
index 0000000000..4ab9f213f4
--- /dev/null
+++ b/src/include/cpu/486/smm.h
@@ -0,0 +1,201 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef CPU_X86_SMM_H
+#define CPU_X86_SMM_H
+
+#include <arch/cpu.h>
+#include <commonlib/region.h>
+#include <types.h>
+
+#define SMM_DEFAULT_BASE 0x30000
+#define SMM_DEFAULT_SIZE 0x10000
+
+/* used only by C programs so far */
+#define SMM_BASE 0xa0000
+
+#define SMM_ENTRY_OFFSET 0x8000
+#define SMM_SAVE_STATE_BEGIN(x) (SMM_ENTRY_OFFSET + (x))
+
+#define APM_CNT		0xb2
+#define APM_CNT_NOOP_SMI	0x00
+#define APM_CNT_ACPI_DISABLE	0x1e
+#define APM_CNT_ACPI_ENABLE	0xe1
+#define APM_CNT_ROUTE_ALL_XHCI	0xca
+#define APM_CNT_FINALIZE	0xcb
+#define APM_CNT_LEGACY		0xcc
+#define APM_CNT_MBI_UPDATE	0xeb
+#define APM_CNT_SMMINFO		0xec
+#define APM_CNT_SMMSTORE	0xed
+#define APM_CNT_ELOG_GSMI	0xef
+#define APM_STS		0xb3
+
+/* Send cmd to APM_CNT with HAVE_SMI_HANDLER checking. */
+int apm_control(u8 cmd);
+u8 apm_get_apmc(void);
+
+void io_trap_handler(int smif);
+int mainboard_io_trap_handler(int smif);
+
+void southbridge_smi_set_eos(void);
+
+void global_smi_enable(void);
+void global_smi_enable_no_pwrbtn(void);
+
+void cpu_smi_handler(void);
+void northbridge_smi_handler(void);
+void southbridge_smi_handler(void);
+
+void mainboard_smi_gpi(u32 gpi_sts);
+int  mainboard_smi_apmc(u8 data);
+void mainboard_smi_sleep(u8 slp_typ);
+void mainboard_smi_finalize(void);
+int mainboard_set_smm_log_level(void);
+
+void smm_soc_early_init(void);
+void smm_soc_exit(void);
+
+/* This is the SMM handler. */
+extern unsigned char _binary_smm_start[];
+extern unsigned char _binary_smm_end[];
+
+struct smm_runtime {
+	u32 smbase;
+	u32 smm_size;
+	u32 save_state_size;
+	u32 num_cpus;
+	u32 gnvs_ptr;
+	u32 cbmemc_size;
+	void *cbmemc;
+	uintptr_t save_state_top[CONFIG_MAX_CPUS];
+	int smm_log_level;
+} __packed;
+
+struct smm_module_params {
+	size_t cpu;
+	/* A canary value that has been placed at the end of the stack.
+	 * If (uintptr_t)canary != *canary then a stack overflow has occurred.
+	 */
+	const uintptr_t *canary;
+};
+
+/* These parameters are used by the SMM stub code. A pointer to the params
+ * is also passed to the C-base handler. */
+struct smm_stub_params {
+	u32 stack_size;
+	u32 stack_top;
+	u32 c_handler;
+	u32 fxsave_area;
+	u32 fxsave_area_size;
+	/* The apic_id_to_cpu provides a mapping from APIC id to CPU number.
+	 * The CPU number is indicated by the index into the array by matching
+	 * the default APIC id and value at the index. The stub loader
+	 * initializes this array with a 1:1 mapping. If the APIC ids are not
+	 * contiguous like the 1:1 mapping it is up to the caller of the stub
+	 * loader to adjust this mapping. */
+	u16 apic_id_to_cpu[CONFIG_MAX_CPUS];
+	/* STM's 32bit entry into SMI handler */
+	u32 start32_offset;
+} __packed;
+
+/* smm_handler_t is called with arg of smm_module_params pointer. */
+typedef asmlinkage void (*smm_handler_t)(void *);
+
+/* SMM Runtime helpers. */
+#if ENV_SMM
+extern struct global_nvs *gnvs;
+#endif
+
+/* Entry point for SMM modules. */
+asmlinkage void smm_handler_start(void *params);
+
+/* Retrieve SMM save state for a given CPU. WARNING: This does not take into
+ * account CPUs which are configured to not save their state to RAM. */
+void *smm_get_save_state(int cpu);
+
+/* Returns true if the region overlaps with the SMM */
+bool smm_region_overlaps_handler(const struct region *r);
+
+/* Returns true if the memory pointed to overlaps with SMM reserved memory. */
+static inline bool smm_points_to_smram(const void *ptr, const size_t len)
+{
+	const struct region r = {(uintptr_t)ptr, len};
+
+	return smm_region_overlaps_handler(&r);
+}
+
+/* SMM Module Loading API */
+
+/* The smm_loader_params structure provides direction to the SMM loader:
+ * - num_cpus - number of concurrent cpus in handler needing stack
+ *                           optional for setting up relocation handler.
+ * - cpu_save_state_size - the SMM save state size per cpu
+ * - num_concurrent_save_states - number of concurrent cpus needing save state
+ *                                space
+ * - handler - optional handler to call. Only used during SMM relocation setup.
+ * - runtime - this field is a result only. The SMM runtime location is filled
+ *             into this field so the code doing the loading can manipulate the
+ *             runtime's assumptions. e.g. updating the APIC id to CPU map to
+ *             handle sparse APIC id space.
+ */
+struct smm_loader_params {
+	size_t num_cpus;
+
+	size_t cpu_save_state_size;
+	size_t num_concurrent_save_states;
+
+	smm_handler_t handler;
+
+	struct smm_stub_params *stub_params;
+};
+
+/* All of these return 0 on success, < 0 on failure. */
+int smm_setup_stack(const uintptr_t perm_smbase, const size_t perm_smram_size,
+		    const unsigned int total_cpus, const size_t stack_size);
+int smm_setup_relocation_handler(struct smm_loader_params *params);
+int smm_load_module(uintptr_t smram_base, size_t smram_size, struct smm_loader_params *params);
+
+u32 smm_get_cpu_smbase(unsigned int cpu_num);
+
+/* Backup and restore default SMM region. */
+void *backup_default_smm_area(void);
+void restore_default_smm_area(void *smm_save_area);
+
+/*
+ * Fills in the arguments for the entire SMM region covered by chipset
+ * protections. e.g. TSEG.
+ */
+void smm_region(uintptr_t *start, size_t *size);
+
+static inline void aseg_region(uintptr_t *start, size_t *size)
+{
+	*start = SMM_BASE;
+	*size = SMM_DEFAULT_SIZE; /* SMM_CODE_SEGMENT_SIZE ? */
+}
+
+enum {
+	/* SMM handler area. */
+	SMM_SUBREGION_HANDLER,
+	/* SMM cache region. */
+	SMM_SUBREGION_CACHE,
+	/* Chipset specific area. */
+	SMM_SUBREGION_CHIPSET,
+	/* Total sub regions supported. */
+	SMM_SUBREGION_NUM,
+};
+
+/* Fills in the start and size for the requested SMM subregion. Returns
+ * 0 on success, < 0 on failure. */
+int smm_subregion(int sub, uintptr_t *start, size_t *size);
+
+/* Print the SMM memory layout on console. */
+void smm_list_regions(void);
+
+#define SMM_REVISION_OFFSET_FROM_TOP (0x8000 - 0x7efc)
+/* Return the SMM save state revision. The revision can be fetched from the smm savestate
+   which is always at the same offset downward from the top of the save state. */
+uint32_t smm_revision(void);
+/* Returns the PM ACPI SMI port. On Intel systems this typically not configurable (APM_CNT, 0xb2).
+   On AMD systems it is sometimes configurable. */
+uint16_t pm_acpi_smi_cmd_port(void);
+
+#endif /* CPU_X86_SMM_H */
diff --git a/src/include/cpu/486/sp_init.h b/src/include/cpu/486/sp_init.h
new file mode 100644
index 0000000000..2f20f67774
--- /dev/null
+++ b/src/include/cpu/486/sp_init.h
@@ -0,0 +1,94 @@
+/* SPDX-License-Identifier: GPL-2.0-only */
+
+#ifndef _486_SP_INIT_H_
+#define _486_SP_INIT_H_
+
+// #include <cpu/x86/smm.h>
+#include <types.h>
+
+struct cpu_info;
+struct bus;
+
+static inline void mfence(void)
+{
+	__asm__ __volatile__("lock; addl $0,0(%%esp)": : : "memory");
+}
+
+/* The sequence of the callbacks are in calling order. */
+struct mp_ops {
+	/*
+	 * Optionally provide a callback prior to kicking off MP
+	 * startup. This callback is done prior to loading the SIPI
+	 * vector but after gathering the MP state information. Please
+	 * see the sequence below.
+	 */
+	void (*pre_mp_init)(void);
+	/*
+	 * Return the number of logical x86 execution contexts that
+	 * need to be brought out of SIPI state as well as have SMM
+	 * handlers installed.
+	 */
+	int (*get_cpu_count)(void);
+	/*
+	 * Optionally fill in permanent SMM region and save state size. If
+	 * this callback is not present no SMM handlers will be installed.
+	 * The perm_smsize is the size available to house the permanent SMM
+	 * handler.
+	 */
+	void (*get_smm_info)(uintptr_t *perm_smbase, size_t *perm_smsize,
+				size_t *smm_save_state_size);
+	/*
+	 * Optionally fill in pointer to microcode and indicate if the APs
+	 * can load the microcode in parallel.
+	 */
+	void (*get_microcode_info)(const void **microcode, int *parallel);
+	/*
+	 * Optionally provide a callback prior to the APs starting SMM
+	 * relocation or CPU driver initialization. However, note that
+	 * this callback is called after SMM handlers have been loaded.
+	 */
+	void (*pre_mp_smm_init)(void);
+	/*
+	 * Optional function to use to trigger SMM to perform relocation. If
+	 * not provided, smm_initiate_relocation() is used.
+	 * This function is called on each CPU.
+	 * On platforms that select CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER) to
+	 * not relocate in SMM, this function can be used to relocate CPUs.
+	 */
+	void (*per_cpu_smm_trigger)(void);
+	/*
+	 * This function is called while each CPU is in the SMM relocation
+	 * handler. Its primary purpose is to adjust the SMBASE for the
+	 * permanent handler. The parameters passed are the current cpu
+	 * running the relocation handler, current SMBASE of relocation handler,
+	 * and the pre-calculated staggered CPU SMBASE address of the permanent
+	 * SMM handler.
+	 * This function is only called with !CONFIG(X86_SMM_SKIP_RELOCATION_HANDLER) set.
+	 */
+	void (*relocation_handler)(int cpu, uintptr_t curr_smbase,
+		uintptr_t staggered_smbase);
+	/*
+	 * Optionally provide a callback that is called after the APs
+	 * and the BSP have gone through the initialion sequence.
+	 */
+	void (*post_mp_init)(void);
+};
+
+/*
+ * The mp_ops argument is used to drive the multiprocess initialization. Unless
+ * otherwise stated each callback is called on the BSP only. The sequence of
+ * operations is the following:
+ * 1. pre_mp_init()
+ * 2. get_cpu_count()
+ * 3. get_smm_info()
+ * 4. get_microcode_info()
+ * 5. adjust_cpu_apic_entry() for each number of get_cpu_count()
+ * 6. pre_mp_smm_init()
+ * 7. per_cpu_smm_trigger() in parallel for all cpus which calls
+ *    relocation_handler() in SMM.
+ * 8. mp_initialize_cpu() for each cpu
+ * 9. post_mp_init()
+ */
+// enum cb_err sp_init_with_smm(struct bus *cpu_bus, struct mp_ops *mp_ops);
+
+#endif /* _486_SP_INIT_H_ */
-- 
2.46.1

